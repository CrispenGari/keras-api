{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "electrical-transmission",
   "metadata": {},
   "source": [
    "## EarlyStopping\n",
    "\n",
    "Stop training when a monitored metric has stopped improving.\n",
    "\n",
    "Assuming the goal of a training is to minimize the loss. With this, the metric to be monitored would be 'loss', and mode would be 'min'. A model.fit() training loop will check at end of every epoch whether the loss is no longer decreasing, considering the min_delta and patience if applicable. Once it's found no longer decreasing, model.stop_training is marked True and the training terminates.\n",
    "\n",
    "```python\n",
    "tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=0,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    ")\n",
    "```\n",
    "\n",
    "* **monitor**: Quantity to be monitored.\n",
    "* **patience**: Number of epochs with no improvement after which training will be stopped.\n",
    "* **verbose**: verbosity mode.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-radical",
   "metadata": {},
   "source": [
    "### Example:\n",
    "\n",
    "> The `tfds` `bean` dataset image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "seeing-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "amazing-lambda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstract_reasoning', 'accentdb']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfds.list_builders()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "blank-practitioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tfds.load('beans', split='train')\n",
    "validation = tfds.load('beans', split='validation')\n",
    "test = tfds.load('beans', split='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-dutch",
   "metadata": {},
   "source": [
    "> Class Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "armed-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.array(['angular_leaf_spot', \"bean_rust\", 'health'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-omega",
   "metadata": {},
   "source": [
    "> Splitting `labels` and `features`: For this dataset we are going to have 100 images of trainning to keep it simple and 30 images for validation and 10 for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "occupied-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [i for i in train]\n",
    "X_test = [i for i in test]\n",
    "X_valid = [i for i in validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "equipped-validity",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.array([i['image'].numpy().astype('float32')/255 for i in X_train[:100]])\n",
    "train_labels = np.array([np.eye(3)[i['label'].numpy().astype('int32')] for i in X_train[:100]])\n",
    "\n",
    "valid_images = np.array([i['image'].numpy().astype('float32')/255 for i in X_valid[:30]])\n",
    "valid_labels = np.array([np.eye(3)[i['label'].numpy().astype('int32')] for i in X_valid[:30]])\n",
    "\n",
    "test_images = np.array([i['image'].numpy().astype('float32')/255 for i in X_test[:10]])\n",
    "test_labels = np.array([np.eye(3)[i['label'].numpy().astype('int32')] for i in X_test[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-arena",
   "metadata": {},
   "source": [
    "> Creating a simple model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "changing-cooler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = train_images[0].shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "departmental-midwest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"bean_classsifier\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 499, 499, 64)      832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 249, 249, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 248, 248, 32)      8224      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 124, 124, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 123, 123, 64)      8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 60, 60, 32)        8224      \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 115200)            0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                3686432   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 3,712,547\n",
      "Trainable params: 3,712,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=input_shape),\n",
    "    keras.layers.Conv2D(64, (2,2), activation='relu'),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Conv2D(32, (2,2), activation='relu'),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Conv2D(64, (2,2), activation='relu'),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Conv2D(32, (2,2), activation='relu'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    keras.layers.Dense(3, activation='softmax'),\n",
    "], name=\"bean_classsifier\")\n",
    "model.compile(\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=False), # because we applied softmax\n",
    "    metrics = ['acc'],\n",
    "    optimizer = 'adam'\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "careful-judgment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/13 [==============================] - 99s 6s/step - loss: 1.5258 - acc: 0.3674 - val_loss: 1.0720 - val_acc: 0.4000\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 47s 4s/step - loss: 1.0835 - acc: 0.4204 - val_loss: 1.0626 - val_acc: 0.4000\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 46s 4s/step - loss: 1.0512 - acc: 0.5285 - val_loss: 1.0750 - val_acc: 0.3333\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 46s 4s/step - loss: 0.9965 - acc: 0.4979 - val_loss: 0.9661 - val_acc: 0.5667\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 47s 4s/step - loss: 0.7554 - acc: 0.7089 - val_loss: 0.9041 - val_acc: 0.6333\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 46s 4s/step - loss: 0.6476 - acc: 0.6925 - val_loss: 1.0351 - val_acc: 0.6000\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 46s 4s/step - loss: 0.6282 - acc: 0.6711 - val_loss: 0.9277 - val_acc: 0.6000\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 46s 4s/step - loss: 0.5671 - acc: 0.6859 - val_loss: 1.1033 - val_acc: 0.4000\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    ")\n",
    "history = model.fit(train_images, train_labels, epochs=10, verbose=1, batch_size=8, \n",
    "                   validation_data=(valid_images, valid_labels),\n",
    "                   callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-toolbox",
   "metadata": {},
   "source": [
    "> So basically, the `early stopping` call back will be called, when the `val_loss` stops falling for 3 times in a row."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
