{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_ReduceLROnPlateau.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsWZU7NMi2vJ"
      },
      "source": [
        "### ReduceLROnPlateau.\n",
        "Reduce learning rate when a metric has stopped improving.\n",
        "\n",
        "```py\n",
        "tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss', factor=0.1, patience=10, verbose=0,\n",
        "    mode='auto', min_delta=0.0001, cooldown=0, min_lr=0, **kwargs\n",
        ")\n",
        "```\n",
        "Models often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. This callback monitors a quantity and if no improvement is seen for a 'patience' number of epochs, the learning rate is reduced.\n",
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7InLgJZzivXz"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vocIXDXRnldb"
      },
      "source": [
        "### Configuring the ``device`` for the environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Albz4LFHnkve"
      },
      "source": [
        "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deJx0d64nPlS"
      },
      "source": [
        "### Let's create a model that will train on the `MNIST` dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9ZTB1WtjadF",
        "outputId": "e0ea99b3-2f1d-44e3-c1fa-ae9786f27342"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
        "X_train.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgsWuJXLlYdB"
      },
      "source": [
        "def normalize(image):\n",
        "  image = tf.convert_to_tensor(image.astype('float32'))/255\n",
        "  return image"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRo-bFwtlJIn"
      },
      "source": [
        "X_train_tensors =tf.convert_to_tensor(list(map(normalize, X_train)))\n",
        "X_test_tensors = tf.convert_to_tensor(list(map(normalize, X_test)))\n",
        "\n",
        "y_test_tensors = tf.convert_to_tensor(y_test)\n",
        "y_train_tensors = tf.convert_to_tensor(y_train)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XgJ-wjHlI_W",
        "outputId": "2e34bde1-e78a-4478-ea84-6322cbc28cf3"
      },
      "source": [
        "y_test_tensors[:2]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=uint8, numpy=array([7, 2], dtype=uint8)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX8ftKQiHIqt"
      },
      "source": [
        "### Creating a `ReduceLROnPlateau` callback."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdPfEESOlI1B"
      },
      "source": [
        "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss', factor=0.1, patience=10, verbose=1,\n",
        "    mode='auto', min_delta=0.0001, cooldown=0, min_lr=0\n",
        ")"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsWfwQMKjq7q",
        "outputId": "f38a1b02-6e78-4625-f20f-21bf1fb1efc1"
      },
      "source": [
        "model = keras.Sequential([\n",
        "      keras.layers.Input(shape=(28, 28,)),\n",
        "      keras.layers.Flatten(),\n",
        "      keras.layers.Dense(64, activation=\"relu\"),\n",
        "      keras.layers.Dense(128, activation=\"relu\"),\n",
        "      keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "              optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"]\n",
        "              )\n",
        "history =  model.fit(X_train_tensors, y_train_tensors, epochs=10, \n",
        "          verbose=1, batch_size=32, \n",
        "          validation_data=(X_test_tensors, y_test_tensors),\n",
        "          callbacks=[lr_scheduler]\n",
        "          )"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2683 - accuracy: 0.9229 - val_loss: 0.1460 - val_accuracy: 0.9535\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1184 - accuracy: 0.9639 - val_loss: 0.1081 - val_accuracy: 0.9661\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0855 - accuracy: 0.9740 - val_loss: 0.1108 - val_accuracy: 0.9660\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0695 - accuracy: 0.9782 - val_loss: 0.0887 - val_accuracy: 0.9737\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0548 - accuracy: 0.9826 - val_loss: 0.1002 - val_accuracy: 0.9691\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0461 - accuracy: 0.9851 - val_loss: 0.0763 - val_accuracy: 0.9766\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0397 - accuracy: 0.9870 - val_loss: 0.0921 - val_accuracy: 0.9740\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0335 - accuracy: 0.9894 - val_loss: 0.0926 - val_accuracy: 0.9757\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0287 - accuracy: 0.9904 - val_loss: 0.1151 - val_accuracy: 0.9724\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0261 - accuracy: 0.9918 - val_loss: 0.0836 - val_accuracy: 0.9764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "truuUdfIHyV8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}