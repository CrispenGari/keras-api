{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_Subclassing_Examples.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47Mlvq6lt4CQ"
      },
      "source": [
        "### Practical Examples\n",
        "\n",
        "In this notebook we are going to do some practicals based on the subclassing api in keras just to cement the concept of subclassing by building larger models like `ResNet`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_mZvCClv3m7"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCIbxkW_uh24"
      },
      "source": [
        "Let's say we have the following achitecture which is repeatedly used during creation of our model.\n",
        "\n",
        "```\n",
        "Conv2D -> BatchNormalization -> ReLU (the common structure for our model.)\n",
        "```\n",
        "Let's subclass this achitecture block.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9VndteVuhzy"
      },
      "source": [
        "class ConvBlock(keras.layers.Layer):\n",
        "  def __init__(self, output_features, kernel_size=3):\n",
        "    super().__init__()\n",
        "    self.conv = keras.layers.Conv2D(output_features, kernel_size)\n",
        "    self.bn = keras.layers.BatchNormalization()\n",
        "  \n",
        "  def call(self, x, training=False):\n",
        "    x = self.conv(x)\n",
        "    x = self.bn(x , training=training)\n",
        "    return keras.activations.relu(x)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRrlHPiguhwn"
      },
      "source": [
        "Let's now build a sequential model with 3 of these layers, just like what we did from the prevoius notebook and add an output layer to our model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At8mzrlKuht-",
        "outputId": "74abadc3-0aee-4cec-8005-460b4d01839e"
      },
      "source": [
        "model_1 = keras.Sequential([\n",
        "    ConvBlock(64),\n",
        "    ConvBlock(128),\n",
        "    ConvBlock(256),\n",
        "\n",
        "    # Output blocks\n",
        "    keras.layers.GlobalMaxPool2D(),\n",
        "    keras.layers.Dense(64, keras.activations.relu),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model_1.build((None, 32, 32, 3))\n",
        "model_1.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_block_6 (ConvBlock)     (None, 30, 30, 64)        2048      \n",
            "_________________________________________________________________\n",
            "conv_block_7 (ConvBlock)     (None, 28, 28, 128)       74368     \n",
            "_________________________________________________________________\n",
            "conv_block_8 (ConvBlock)     (None, 26, 26, 256)       296192    \n",
            "_________________________________________________________________\n",
            "global_max_pooling2d_2 (Glob (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 389,706\n",
            "Trainable params: 388,810\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELDwOMFyuhrI"
      },
      "source": [
        "### Residual Block (`ResBlock`)\n",
        "At the end of the theory we want to build the `ResBlock` using the subclassing `API`.4\n",
        "\n",
        "#### Theory\n",
        "In deep learning, it’s common that the deeper network has stronger ability, and performance is better. However, the deeper network also brings out some problems, such as **gradient disappearance** and gradient explosion. There’s had many optimizing method, like **Batchnormlization** layer, **RelU** activations. Although it’s still limitedly optimized not until **skip connection** is widespread use.\n",
        "\n",
        "<p align=\"center\"><img src=\"https://miro.medium.com/max/472/1*Cc3o7Hq7aMb0JPb9UuuxzA.png\" /></p>\n",
        "\n",
        "Skip connection is usually used in resnet. It’s a way to avoid gradient diffusion. It’s like the differential coefficient plus 1, even if the original one is small, the error can still be backpropagated.\n",
        "\n",
        "**ResBlock in code:**\n",
        "\n",
        "````python\n",
        "Output = x + Conv2(Conv1(x))\n",
        "````\n",
        "\n",
        "### The `ResNet`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXTn9dNDuhog"
      },
      "source": [
        "class ResBlock(keras.layers.Layer):\n",
        "  def __init__(self, channels):\n",
        "    super().__init__()\n",
        "    self.conv1 = ConvBlock(channels[0])\n",
        "    self.conv2 = ConvBlock(channels[1])\n",
        "    self.conv3 = ConvBlock(channels[2])\n",
        "    self.pooling = keras.layers.MaxPool2D()\n",
        "    self.identity_mapping = keras.layers.Conv2D(channels[1], 3, padding=\"same\")\n",
        "\n",
        "  def call(self, x, training=False):\n",
        "    input_tensor = x\n",
        "    x = self.conv1(x, training=training)\n",
        "    x = self.conv2(x, training=training)\n",
        "    x = self.conv3(x + self.identity_mapping(input_tensor), training=training)\n",
        "    return self.pooling(x)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUjiUYFO0R9N"
      },
      "source": [
        "### Create a ``ResNet`` model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHLqF83h0R6d"
      },
      "source": [
        "class ResNetModel(keras.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.block1 = ResBlock([32, 64, 128])\n",
        "    self.block2 = ResBlock([128, 128, 256])\n",
        "    self.block3 = ResBlock([128, 256, 512])\n",
        "    self.pool = keras.layers.GlobalAveragePooling2D()\n",
        "    self.classifier = keras.layers.Dense(10)\n",
        "\n",
        "  def call(self, x, training=False):\n",
        "    x = self.block1(x, training=training)\n",
        "    x = self.block2(x, training=training)\n",
        "    x = self.block3(x, training=training)\n",
        "    x = self.pool(x, training=training)\n",
        "    return self.classifier(x)\n",
        "\n",
        "  def model(self):\n",
        "    x = keras.layers.Input(shape=(32, 32, 3))\n",
        "    return keras.Model(inputs=[x], outputs=self.call(x))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENFCu6ix0R3n"
      },
      "source": [
        "### Creating the dataset to test our `ResNetModel`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62_M_XcF0R0e"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "X_test_tensors = tf.convert_to_tensor(X_test.reshape(-1, 32, 32, 3)/255.0, dtype=tf.float32)\n",
        "X_train_tensors = tf.convert_to_tensor(X_train.reshape(-1, 32, 32, 3)/255.0, dtype=tf.float32)\n",
        "y_test_tensors = tf.one_hot(tf.squeeze(y_test), depth=10)\n",
        "y_train_tensors = tf.one_hot(tf.squeeze(y_train), depth=10)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGPtAHZl5jkr"
      },
      "source": [
        ""
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE41XNG30Rx1",
        "outputId": "5932fb4f-9837-45e2-f32f-d24af8edd4f0"
      },
      "source": [
        "model_2 = ResNetModel()\n",
        "model_2.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "model_2.fit(X_train_tensors, y_train_tensors, epochs=2, verbose=1, validation_data=(X_test_tensors, y_test_tensors))\n",
        "model_2.model().summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 1.2641 - accuracy: 0.5424 - val_loss: 1.5766 - val_accuracy: 0.5048\n",
            "Epoch 2/2\n",
            "1563/1563 [==============================] - 35s 23ms/step - loss: 0.8198 - accuracy: 0.7117 - val_loss: 1.9679 - val_accuracy: 0.4830\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "res_block_36 (ResBlock)      (None, 16, 16, 128)       95936     \n",
            "_________________________________________________________________\n",
            "res_block_37 (ResBlock)      (None, 8, 8, 256)         739968    \n",
            "_________________________________________________________________\n",
            "res_block_38 (ResBlock)      (None, 4, 4, 512)         2364032   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_11  (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 3,205,066\n",
            "Trainable params: 3,201,802\n",
            "Non-trainable params: 3,264\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_HMzcf90Row",
        "outputId": "1019664f-3107-4643-e506-64054782322a"
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "res_block_27 (ResBlock)      (None, 14, 14, 128)       94208     \n",
            "_________________________________________________________________\n",
            "res_block_28 (ResBlock)      (None, 7, 7, 256)         739968    \n",
            "_________________________________________________________________\n",
            "res_block_29 (ResBlock)      (None, 3, 3, 512)         2364032   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_8 ( (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 3,203,338\n",
            "Trainable params: 3,200,074\n",
            "Non-trainable params: 3,264\n",
            "_________________________________________________________________\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "res_block_27 (ResBlock)      (None, 14, 14, 128)       94208     \n",
            "_________________________________________________________________\n",
            "res_block_28 (ResBlock)      (None, 7, 7, 256)         739968    \n",
            "_________________________________________________________________\n",
            "res_block_29 (ResBlock)      (None, 3, 3, 512)         2364032   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_8 ( (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 3,203,338\n",
            "Trainable params: 3,200,074\n",
            "Non-trainable params: 3,264\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVf-5W8n0Rl3"
      },
      "source": [
        "**Conclusion:** The subclass API is more flexible way of building models. \n",
        "\n",
        "✔ **Other resources:**\n",
        "\n",
        "[towardsdatascience](https://towardsdatascience.com/model-sub-classing-and-custom-training-loop-from-scratch-in-tensorflow-2-cc1d4f10fb4e)"
      ]
    }
  ]
}