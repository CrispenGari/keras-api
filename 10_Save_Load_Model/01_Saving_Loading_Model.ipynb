{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_Saving_Loading_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsWZU7NMi2vJ"
      },
      "source": [
        "### Saving and Loading models - ``TensorFlow``\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7InLgJZzivXz"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vocIXDXRnldb"
      },
      "source": [
        "### Configuring the ``device`` for the environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Albz4LFHnkve"
      },
      "source": [
        "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deJx0d64nPlS"
      },
      "source": [
        "### Let's create a model that will train on the `MNIST` dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9ZTB1WtjadF",
        "outputId": "beca3fef-10c3-4901-aa12-80ffd8809631"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
        "X_train.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgsWuJXLlYdB"
      },
      "source": [
        "def normalize(image):\n",
        "  image = tf.convert_to_tensor(image.astype('float32'))/255\n",
        "  return image"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRo-bFwtlJIn"
      },
      "source": [
        "X_train_tensors =tf.convert_to_tensor(list(map(normalize, X_train)))\n",
        "X_test_tensors = tf.convert_to_tensor(list(map(normalize, X_test)))\n",
        "\n",
        "y_test_tensors = tf.convert_to_tensor(y_test)\n",
        "y_train_tensors = tf.convert_to_tensor(y_train)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XgJ-wjHlI_W",
        "outputId": "09232eb2-2065-46d2-b3fd-016d94e7894a"
      },
      "source": [
        "y_test_tensors[:2]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=uint8, numpy=array([7, 2], dtype=uint8)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdPfEESOlI1B"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsWfwQMKjq7q",
        "outputId": "c52a2ded-a636-4f6e-8359-3e68ce0e6fb8"
      },
      "source": [
        "model = keras.Sequential([\n",
        "      keras.layers.Input(shape=(28, 28,)),\n",
        "      keras.layers.Flatten(),\n",
        "      keras.layers.Dense(64, activation=\"relu\"),\n",
        "      keras.layers.Dense(128, activation=\"relu\"),\n",
        "      keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "              optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"]\n",
        "              )\n",
        "model.fit(X_train_tensors, y_train_tensors, epochs=5, verbose=1, batch_size=32, validation_data=(X_test_tensors, y_test_tensors))\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2747 - accuracy: 0.9196 - val_loss: 0.1494 - val_accuracy: 0.9557\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1227 - accuracy: 0.9619 - val_loss: 0.1134 - val_accuracy: 0.9637\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0867 - accuracy: 0.9730 - val_loss: 0.0954 - val_accuracy: 0.9693\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0671 - accuracy: 0.9783 - val_loss: 0.0895 - val_accuracy: 0.9733\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0545 - accuracy: 0.9829 - val_loss: 0.0887 - val_accuracy: 0.9734\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                50240     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 59,850\n",
            "Trainable params: 59,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm-DvBkRnHDX"
      },
      "source": [
        "#### Saving model weights\n",
        "To save the model weights we call `model.save_weights(path)` method. So if we want to load the weights to the model we just call `model.save_weights`.\n",
        "\n",
        "#### Saving `weights`\n",
        "\n",
        "```python\n",
        "model.save_weights('checkpoints/')\n",
        "```\n",
        "\n",
        "#### Loading the weights to the model.\n",
        "\n",
        "```python\n",
        "model.load_weights('checkpoints/')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQjzUOBbng9j",
        "outputId": "a0d66b18-e129-45e5-cc3d-ba83e8b145f2"
      },
      "source": [
        "model.save_weights(\"checkpoints/\")\n",
        "print(\"Weights saved\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weights saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV5e6J4dp3Ru"
      },
      "source": [
        "> When we call the `model.load_weights` then the model will continue trainning from the loaded previous weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ie0rgi-UqGBX",
        "outputId": "a59ad9c9-3c10-4df6-af17-1a774c2eca80"
      },
      "source": [
        "model.load_weights('checkpoints/')\n",
        "print(\"Mode Weights loaded\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mode Weights loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Khsgbu9RqT53",
        "outputId": "c6e47445-8aad-4b5d-f273-a5b9cb40978a"
      },
      "source": [
        "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "              optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"]\n",
        "              )\n",
        "model.fit(X_train_tensors, y_train_tensors, epochs=5, verbose=1, batch_size=32, validation_data=(X_test_tensors, y_test_tensors))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0461 - accuracy: 0.9848 - val_loss: 0.0897 - val_accuracy: 0.9745\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0394 - accuracy: 0.9872 - val_loss: 0.0904 - val_accuracy: 0.9735\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0316 - accuracy: 0.9894 - val_loss: 0.0882 - val_accuracy: 0.9739\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0274 - accuracy: 0.9905 - val_loss: 0.1012 - val_accuracy: 0.9736\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0244 - accuracy: 0.9917 - val_loss: 0.0928 - val_accuracy: 0.9754\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff87a0a4190>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nu6ohJd6qVzo"
      },
      "source": [
        "> We can esentially see that the model's first epoch accuracy is simmilar or close to the previous model. Meaning this model just continued trainning from where it left of it's 5th epoch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LFUY9Jgq-lp"
      },
      "source": [
        "#### Model Serialization.\n",
        "This means saving the whole model. We can do that by calling `model.save(path)`. \n",
        "\n",
        "#### Serializing Model\n",
        "```python\n",
        "model.save(\"my_model.h5\")\n",
        "```\n",
        "#### Loading the Serialized model.\n",
        "\n",
        "\n",
        "```python\n",
        "new_model = keras.models.load_model(\"my_model.h5\")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJ64A-4Yr_aA",
        "outputId": "55796312-5d7d-4034-e39b-6595b1ceb61b"
      },
      "source": [
        "model.save(\"my_model.h5\")\n",
        "print(\"Model Saved.\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Saved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAmn635Yr_W1"
      },
      "source": [
        "### Evaluating our loaded model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SImUmsbtr_MS",
        "outputId": "85fd3abd-5738-4a76-b79f-6681476b7323"
      },
      "source": [
        "new_model = keras.models.load_model(\"my_model.h5\")\n",
        "new_model.evaluate(X_test_tensors, y_test_tensors, batch_size=32, verbose=1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0928 - accuracy: 0.9754\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.09283297508955002, 0.9753999710083008]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euu5_Z4psSBB"
      },
      "source": [
        "> So we are getting the same accuracy from the previous model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8kkSdzXseAN"
      },
      "source": [
        "#### Saving models to json.\n",
        "We can also save the model weights as json. Let's take a look at the following example:\n",
        "\n",
        "* [Ref](https://machinelearningmastery.com/save-load-keras-deep-learning-models/#:~:text=Keras%20separates%20the%20concerns%20of,different%20formats%3A%20JSON%20and%20YAML.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldPnsAmdtkXl"
      },
      "source": [
        "#### Serialize model to ``JSON``"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nD5rqJrsd3N",
        "outputId": "306057b4-a3cd-406b-911c-41143282b1ce"
      },
      "source": [
        "model_json = model.to_json() # convert the model to json.\n",
        "\n",
        "with open('model_json.json', 'w') as f:\n",
        "  f.write(model_json)\n",
        "print(\"Model Saved.\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Saved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLWkEThGsd0K"
      },
      "source": [
        "#### Loading the `JSON` model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67c6netesdxN",
        "outputId": "86a73bdc-dd3b-4429-dc35-823f0fbbf952"
      },
      "source": [
        "json_file = open('model_json.json', 'r')\n",
        "model_json_loaded = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = keras.models.model_from_json(model_json_loaded)\n",
        "print(loaded_model.summary())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                50240     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 59,850\n",
            "Trainable params: 59,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2u9EyuvJsduN"
      },
      "source": [
        "### Serialize model to ``YAML``\n",
        "This is simmilar to saving and loading the model in json."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTXsiSQxuYa8",
        "outputId": "67c1b938-56bf-4649-9405-178f7087f626"
      },
      "source": [
        "model_yaml = model.to_yaml() # convert the model to yaml.\n",
        "\n",
        "with open('model_yaml.yaml', 'w') as f:\n",
        "  f.write(model_yaml)\n",
        "print(\"Model Saved.\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Saved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5bvDpRiuYYE",
        "outputId": "a490caac-ed91-4d8a-acd5-397c9b45b301"
      },
      "source": [
        "yaml_file = open('model_yaml.yaml', 'r')\n",
        "model_yaml_loaded = yaml_file.read()\n",
        "yaml_file.close()\n",
        "loaded_model = keras.models.model_from_yaml(model_yaml_loaded)\n",
        "print(loaded_model.summary())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                50240     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 59,850\n",
            "Trainable params: 59,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQi7XfF4uX7t"
      },
      "source": [
        "> That's more of it about loading and saving model and model weights."
      ]
    }
  ]
}