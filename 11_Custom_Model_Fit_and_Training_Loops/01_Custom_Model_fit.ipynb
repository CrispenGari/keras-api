{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_Custom_Model.fit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsWZU7NMi2vJ"
      },
      "source": [
        "### Customizing what happens in fit().\n",
        "\n",
        "When you need to write your own training loop from scratch, you can use the ``GradientTape`` and take control of every little detail.\n",
        "\n",
        "When you need to customize what ``fit()`` does, you should override the training step function of the Model class. This is the function that is called by ``fit()`` for every batch of data. You will then be able to call ``fit()`` as usual -- and it will be running your own learning algorithm.\n",
        "\n",
        "* [Docs](https://keras.io/guides/customizing_what_happens_in_fit/)\n",
        "\n",
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7InLgJZzivXz"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vocIXDXRnldb"
      },
      "source": [
        "### Configuring the ``device`` for the environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Albz4LFHnkve"
      },
      "source": [
        "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deJx0d64nPlS"
      },
      "source": [
        "### Let's create a model that will train on the `MNIST` dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9ZTB1WtjadF",
        "outputId": "3ffcfae1-963c-43e7-e720-c901a7575cb7"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
        "X_train.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgsWuJXLlYdB"
      },
      "source": [
        "def normalize(image):\n",
        "  image = tf.convert_to_tensor(image.astype('float32'))/255\n",
        "  return image"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRo-bFwtlJIn"
      },
      "source": [
        "X_train_tensors =tf.convert_to_tensor(list(map(normalize, X_train)))\n",
        "X_test_tensors = tf.convert_to_tensor(list(map(normalize, X_test)))\n",
        "\n",
        "y_test_tensors = tf.convert_to_tensor(y_test)\n",
        "y_train_tensors = tf.convert_to_tensor(y_train)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XgJ-wjHlI_W",
        "outputId": "2e34bde1-e78a-4478-ea84-6322cbc28cf3"
      },
      "source": [
        "y_test_tensors[:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=uint8, numpy=array([7, 2], dtype=uint8)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDbDn_PzLDng"
      },
      "source": [
        " ### Let's create a `Sequential` model that will fit on our custom `.fit()` method.\n",
        " We can do this in many ways.\n",
        "\n",
        " [2nd way](https://keras.io/guides/customizing_what_happens_in_fit/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHtvL4_XLDlF",
        "outputId": "6873daf7-8562-4299-ee2d-be15c7570eaf"
      },
      "source": [
        "model = keras.Sequential([\n",
        "      keras.layers.Input(shape=(28, 28,)),\n",
        "      keras.layers.Flatten(),\n",
        "      keras.layers.Dense(64, activation=\"relu\"),\n",
        "      keras.layers.Dense(128, activation=\"relu\"),\n",
        "      keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_grgWRXlLDhx"
      },
      "source": [
        "class CustomFit(keras.Model):\n",
        "   def __init__(self, model):\n",
        "    super(CustomFit, self).__init__()\n",
        "    self.model = model\n",
        "   def train_step(self, data):\n",
        "        x, y = data\n",
        "        with tf.GradientTape() as tape:\n",
        "            # forward pass\n",
        "            y_pred = self.model(x, training=True)\n",
        "            # calclate the loss\n",
        "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
        "\n",
        "        # gradient calculations\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        # Update the weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZZhL2UsOBp_"
      },
      "source": [
        "### Fitting the model using our custom ``fit``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzAYMrhJLDfY",
        "outputId": "8bf1ab07-701c-44f2-9b04-66e60f6cc782"
      },
      "source": [
        "new_model = CustomFit(model)\n",
        "new_model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "                optimizer=\"adam\",\n",
        "                metrics=[\"accuracy\"]\n",
        "              )\n",
        "new_model.fit(X_train_tensors, y_train_tensors, batch_size=32, epochs=5)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0221 - accuracy: 0.9922\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0175 - accuracy: 0.9938\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0175 - accuracy: 0.9941\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0144 - accuracy: 0.9951\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0151 - accuracy: 0.9947\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0c8a76e8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02qroK4qLDWI"
      },
      "source": [
        "### Now let's create a custom `.fit()` and `.evaluate()`.\n",
        "We have seen thet to create a `.fit()` method we need to overide the `train_step` which mean if we want to create the `.evaluate()` we need to overide the `test_step`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9hgk04oLDTG"
      },
      "source": [
        "class CustomFitEval(keras.Model):\n",
        "  def __init__(self, model):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "\n",
        "  # fit\n",
        "  def train_step(self, data):\n",
        "    x, y = data\n",
        "    # forward pass\n",
        "    with tf.GradientTape() as tape:\n",
        "      y_pred = self.model(x, training=True)\n",
        "      # loss\n",
        "      loss = self.compiled_loss(y, y_pred)\n",
        "    # caculate the gradients\n",
        "    gradients = tape.gradient(loss, self.trainable_variables)\n",
        "    # update the weights\n",
        "    self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "      \n",
        "    # update the metrics\n",
        "    self.compiled_metrics.update_state(y, y_pred)\n",
        "    return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "  # evaluate\n",
        "  def test_step(self, data):\n",
        "    x, y = data\n",
        "    # making predictions\n",
        "    y_pred = self.model(x)\n",
        "    # loss\n",
        "    loss = self.compiled_loss(y, y_pred)\n",
        "    self.compiled_metrics.update_state(y, y_pred)\n",
        "    return {m.name: m.result() for m in self.metrics}"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMwizUnpLDGE",
        "outputId": "9dfd21bf-05d0-47e1-e084-45b932463ee6"
      },
      "source": [
        "model = keras.Sequential([\n",
        "      keras.layers.Input(shape=(28, 28,)),\n",
        "      keras.layers.Flatten(),\n",
        "      keras.layers.Dense(64, activation=\"relu\"),\n",
        "      keras.layers.Dense(128, activation=\"relu\"),\n",
        "      keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "new_model_1 = CustomFitEval(model)\n",
        "\n",
        "new_model_1.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "                optimizer=\"adam\",\n",
        "                metrics=[\"accuracy\"]\n",
        "              )\n",
        "new_model_1.fit(X_train_tensors, y_train_tensors, batch_size=32, epochs=5,\n",
        "                validation_data=(X_test_tensors, y_test_tensors), validation_batch_size=16\n",
        "                )"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2610 - accuracy: 0.9236 - val_loss: 0.1215 - val_accuracy: 0.9629\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1124 - accuracy: 0.9649 - val_loss: 0.0986 - val_accuracy: 0.9709\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0835 - accuracy: 0.9740 - val_loss: 0.0949 - val_accuracy: 0.9701\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0660 - accuracy: 0.9790 - val_loss: 0.0903 - val_accuracy: 0.9718\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0552 - accuracy: 0.9821 - val_loss: 0.0813 - val_accuracy: 0.9761\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0d00200c90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZH9SPVYnYCvs"
      },
      "source": [
        "### Evaluating the `model`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tobgTqyzYCs8",
        "outputId": "22f158cc-9e52-4abb-ed60-8b9ca9202855"
      },
      "source": [
        "new_model_1.evaluate(X_test_tensors, y_test_tensors, batch_size=32)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0886 - accuracy: 0.9736\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08860763907432556, 0.9735999703407288]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "truuUdfIHyV8"
      },
      "source": [
        "> That's more of it, in the next notebook we are going to implement our custom `model.compile()`."
      ]
    }
  ]
}