{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_Custom_compile_fit_evaluate_all_APIs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsWZU7NMi2vJ"
      },
      "source": [
        "### Creating ``.fit()``, `.compile()` and `.evaluate()` for all the api's.\n",
        "\n",
        "In this notebook we are going to use subclassing to create our custom `.fit()`, `.compile()` and `.evaluate()` methods that will work on both  of the following api's.\n",
        "\n",
        "1. Sequantial API\n",
        "2. Functional API\n",
        "3. Subclassing API\n",
        "\n",
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7InLgJZzivXz"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vocIXDXRnldb"
      },
      "source": [
        "### Configuring the ``device`` for the environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Albz4LFHnkve"
      },
      "source": [
        "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deJx0d64nPlS"
      },
      "source": [
        "### Let's create a model that will train on the `MNIST` dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9ZTB1WtjadF",
        "outputId": "170a18be-61af-4203-e82a-4eb35c0f90fe"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
        "X_train.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgsWuJXLlYdB"
      },
      "source": [
        "def normalize(image):\n",
        "  image = tf.convert_to_tensor(image.astype('float32'))/255\n",
        "  return image"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRo-bFwtlJIn"
      },
      "source": [
        "X_train_tensors =tf.convert_to_tensor(list(map(normalize, X_train)))\n",
        "X_test_tensors = tf.convert_to_tensor(list(map(normalize, X_test)))\n",
        "\n",
        "y_test_tensors = tf.convert_to_tensor(y_test)\n",
        "y_train_tensors = tf.convert_to_tensor(y_train)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t55hD-rnHTBB"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XgJ-wjHlI_W",
        "outputId": "752bd5d1-6660-404d-9e11-c37159b030af"
      },
      "source": [
        "y_test_tensors[:2]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=uint8, numpy=array([7, 2], dtype=uint8)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjAzyCQk1PrY"
      },
      "source": [
        "### Custom `evaluate()`, `compile()` and `fit()`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U08T2YeP1Yxw"
      },
      "source": [
        "class Model(keras.Model):\n",
        "  def __init__(self, model):\n",
        "    super().__init__(self)\n",
        "    self.model = model\n",
        "\n",
        "  # .compile()\n",
        "  def compile(self, loss, optimizer, metrics):\n",
        "    self.loss = loss\n",
        "    self.custom_metrics = metrics\n",
        "    self. optimizer = optimizer\n",
        "\n",
        "  # .fit()\n",
        "  def train_step(self, data):\n",
        "    x, y = data\n",
        "    # forward pass\n",
        "    with tf.GradientTape() as tape:\n",
        "      y_pred = self.model(x, training=True)\n",
        "      # loss\n",
        "      loss = self.loss(y, y_pred)\n",
        "    # calculate the gradients\n",
        "    gradients = tape.gradient(loss, self.trainable_variables)\n",
        "    # update the weights\n",
        "    self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "    # update the metrics\n",
        "    self.custom_metrics.update_state(y, y_pred)\n",
        "    return {\"loss\": loss, \"accuracy\": self.custom_metrics.result()}\n",
        "\n",
        "  def test_step(self, data):\n",
        "    x, y = data\n",
        "    y_pred = model(x, training=False)\n",
        "    loss = self.loss(y, y_pred)\n",
        "    self.custom_metrics.update_state(y, y_pred)\n",
        "    return {\"loss\": loss, \"accuracy\": self.custom_metrics.result()}\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDbDn_PzLDng"
      },
      "source": [
        " ### Let's create a `Sequential` model that will use our custom `.fit()`, `.compile()` and `.evaluate()` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMQ_5tea1Zgw",
        "outputId": "40aaae5e-3ebd-4fb2-fd27-1e004ea3b3c2"
      },
      "source": [
        "seq_model = keras.Sequential([\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(64, activation=\"relu\"),\n",
        "    keras.layers.Dense(128, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "], name=\"seq_model\")\n",
        "\n",
        "seq_model_1 = Model(seq_model)\n",
        "seq_model.compile(\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics = keras.metrics.SparseCategoricalAccuracy()           \n",
        ")\n",
        "seq_model.fit(X_train_tensors, y_train_tensors, epochs=2, verbose=1, batch_size=32,\n",
        "          validation_data=(X_test_tensors, y_test_tensors),\n",
        "          validation_batch_size=16)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "1875/1875 [==============================] - 9s 3ms/step - loss: 0.2611 - sparse_categorical_accuracy: 0.9235 - val_loss: 0.1384 - val_sparse_categorical_accuracy: 0.9579\n",
            "Epoch 2/2\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1157 - sparse_categorical_accuracy: 0.9646 - val_loss: 0.1084 - val_sparse_categorical_accuracy: 0.9651\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd3e3917e90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHlUpzUp06TE"
      },
      "source": [
        " ### Let's create a `Functional` model that will use our custom `.fit()`, `.compile()` and `.evaluate()` method.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCtu3hcM1aEr",
        "outputId": "20f37fa2-a659-49cb-8f6e-37b03641d28f"
      },
      "source": [
        "input_layer = keras.layers.Input(shape=(28, 28, ))\n",
        "flatten_layer = keras.layers.Flatten()(input_layer)\n",
        "hidden_1 = keras.layers.Dense(64, activation='relu')(flatten_layer)\n",
        "hidden_2 = keras.layers.Dense(128, activation=\"relu\")(hidden_1)\n",
        "output_layer = keras.layers.Dense(10, activation=\"softmax\")(hidden_2)\n",
        "\n",
        "fn_model = keras.Model(inputs=input_layer, outputs=output_layer, name=\"fn_model\")\n",
        "\n",
        "fn_model_1 = Model(fn_model)\n",
        "fn_model.compile(\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics = keras.metrics.SparseCategoricalAccuracy()           \n",
        ")\n",
        "fn_model.fit(X_train_tensors, y_train_tensors, epochs=2, verbose=1, batch_size=32,\n",
        "          validation_data=(X_test_tensors, y_test_tensors),\n",
        "          validation_batch_size=16)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2691 - sparse_categorical_accuracy: 0.9206 - val_loss: 0.1461 - val_sparse_categorical_accuracy: 0.9551\n",
            "Epoch 2/2\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1176 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.1056 - val_sparse_categorical_accuracy: 0.9686\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd3e3ab7a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-T2GCaI1DBx"
      },
      "source": [
        " ### Let's create a `Subclassing` model that will use our custom `.fit()`, `.compile()` and `.evaluate()` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHtvL4_XLDlF",
        "outputId": "74c52b0f-c9f2-4804-ca17-1f3473924fbc"
      },
      "source": [
        "class MNISTModel(keras.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten_layer = keras.layers.Flatten(input_shape=(28, 28))\n",
        "    self.dense_1 = keras.layers.Dense(64, activation='relu')\n",
        "    self.dense_2 = keras.layers.Dense(128, activation='relu')\n",
        "    self.output_layer = keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.flatten_layer(x)\n",
        "    y = self.dense_1(x)\n",
        "    y = self.dense_2(y)\n",
        "    y = self.output_layer(y)\n",
        "    return y\n",
        "  def model(self):\n",
        "    x = keras.layers.Input(shape=(28*28,))\n",
        "    return keras.Model(inputs=[x], outputs=self.call(x))\n",
        "\n",
        "sub_model_1 = MNISTModel()\n",
        "sub_model_1.compile(\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics = [keras.metrics.SparseCategoricalAccuracy()   ]        \n",
        ")\n",
        "sub_model_1.fit(X_train_tensors, y_train_tensors, epochs=2, verbose=1, batch_size=32,\n",
        "          validation_data=(X_test_tensors, y_test_tensors),\n",
        "          validation_batch_size=16)\n",
        "\n",
        "sub_model_1.model().summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2565 - sparse_categorical_accuracy: 0.9247 - val_loss: 0.1385 - val_sparse_categorical_accuracy: 0.9583\n",
            "Epoch 2/2\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1151 - sparse_categorical_accuracy: 0.9648 - val_loss: 0.1058 - val_sparse_categorical_accuracy: 0.9670\n",
            "Model: \"model_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "flatten_25 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_75 (Dense)             (None, 64)                50240     \n",
            "_________________________________________________________________\n",
            "dense_76 (Dense)             (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_77 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 59,850\n",
            "Trainable params: 59,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsLNPpOkXMCd"
      },
      "source": [
        "### Observations:\n",
        "The keras subclass api didn't work with the custom `.fit()`, `.train()` and `.evaluate()` but I've learned something about the subclass, which is specifying the input shape."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_x0B1CXWMZv"
      },
      "source": [
        "### Getting an error?\n",
        "* [Solution](https://stackoverflow.com/questions/67787156/attributeerror-layer-mnist-model-35-has-no-inbound-nodes-tensorflow-keras-subc/67787639#67787639)"
      ]
    }
  ]
}