{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_Custom_compile_fit_evaluate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsWZU7NMi2vJ"
      },
      "source": [
        "### Customizing what happens in ``.fit()``, `.compile` and `.evaluate()`.\n",
        "\n",
        "In this notebook we are going to use subclassing to create our custom `.fit()`, `.compile()` and `.evaluate()` methods on our model.\n",
        "\n",
        "The implementation is the same throughout all models achitectures:\n",
        "1. Sequantial API\n",
        "2. Functional API\n",
        "3. Subclassing API\n",
        "\n",
        "In this notebook we will use the `Sequential` API but late on we will use all these apis.\n",
        "\n",
        "* [Docs](https://keras.io/guides/customizing_what_happens_in_fit/)\n",
        "\n",
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7InLgJZzivXz"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vocIXDXRnldb"
      },
      "source": [
        "### Configuring the ``device`` for the environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Albz4LFHnkve"
      },
      "source": [
        "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deJx0d64nPlS"
      },
      "source": [
        "### Let's create a model that will train on the `MNIST` dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9ZTB1WtjadF",
        "outputId": "bfb4e402-974f-4531-bd49-ea5e818c8fef"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
        "X_train.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgsWuJXLlYdB"
      },
      "source": [
        "def normalize(image):\n",
        "  image = tf.convert_to_tensor(image.astype('float32'))/255\n",
        "  return image"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRo-bFwtlJIn"
      },
      "source": [
        "X_train_tensors =tf.convert_to_tensor(list(map(normalize, X_train)))\n",
        "X_test_tensors = tf.convert_to_tensor(list(map(normalize, X_test)))\n",
        "\n",
        "y_test_tensors = tf.convert_to_tensor(y_test)\n",
        "y_train_tensors = tf.convert_to_tensor(y_train)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XgJ-wjHlI_W",
        "outputId": "2e34bde1-e78a-4478-ea84-6322cbc28cf3"
      },
      "source": [
        "y_test_tensors[:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=uint8, numpy=array([7, 2], dtype=uint8)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDbDn_PzLDng"
      },
      "source": [
        " ### Let's create a `Sequential` model that will fit on our custom `.fit()`, `.compile()` and `.evaluate()` method.\n",
        "\n",
        "The compile method will be a simple one. It takes 3 keword args, metrics, loss, optimizer\n",
        "```\n",
        "```\n",
        "\n",
        " [2nd way](https://keras.io/guides/customizing_what_happens_in_fit/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHtvL4_XLDlF"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_grgWRXlLDhx"
      },
      "source": [
        "\n",
        "class CustomCompileFitEvaluate(keras.Model):\n",
        "  def __init__(self, model):\n",
        "    super(CustomCompileFitEvaluate, self).__init__()\n",
        "    self.model = model\n",
        "\n",
        "  # .compile() -> compiling the model\n",
        "  def compile(self, loss, optimizer, metrics):\n",
        "    super().compile()\n",
        "    self.loss = loss\n",
        "    self.optimizer = optimizer\n",
        "    self.custom_metrics = metrics\n",
        "\n",
        "  # .fit() -> trainning the model\n",
        "  def train_step(self, data):\n",
        "    x, y = data\n",
        "    # forward pass\n",
        "    with tf.GradientTape() as tape:\n",
        "      y_pred = self.model(x, training=True)\n",
        "      # loss\n",
        "      loss = self.loss(y, y_pred)\n",
        "    # Calculate gradients\n",
        "    gradients = tape.gradient(loss, self.trainable_variables)\n",
        "    # updating the weights\n",
        "    self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "    # updating the metrics\n",
        "    self.custom_metrics.update_state(y, y_pred)\n",
        "\n",
        "    return {\"loss\": loss ,\"accuracy\": self.custom_metrics.result()}\n",
        "  # .evaluate() -> Evaluating the model\n",
        "  def test_step(self, data):\n",
        "    x, y = data\n",
        "    y_pred = self.model(x, training=False)\n",
        "    # loss\n",
        "    loss = self.loss(y, y_pred)\n",
        "    self.custom_metrics.update_state(y, y_pred)\n",
        "    return {\"loss\": loss ,\"accuracy\": self.custom_metrics.result()}"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZZhL2UsOBp_"
      },
      "source": [
        "### Fitting the model using our custom:\n",
        "\n",
        "```\n",
        "compile() -> fit() -> evaluate()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzAYMrhJLDfY",
        "outputId": "b45c25be-8f9c-4995-9154-2899ecd1a97b"
      },
      "source": [
        "model = keras.Sequential([\n",
        "      keras.layers.Flatten(),\n",
        "      keras.layers.Dense(64, activation=\"relu\"),\n",
        "      keras.layers.Dense(128, activation=\"relu\"),\n",
        "      keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "new_model = CustomCompileFitEvaluate(model)\n",
        "new_model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "                  optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  metrics = keras.metrics.SparseCategoricalAccuracy()\n",
        "              )\n",
        "new_model.fit(X_train_tensors, y_train_tensors, batch_size=32, epochs=5,\n",
        "              validation_data=(X_test_tensors, y_test))\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2722 - accuracy: 0.8606 - val_loss: 0.0575 - val_accuracy: 0.9590\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1193 - accuracy: 0.9621 - val_loss: 0.0135 - val_accuracy: 0.9644\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0865 - accuracy: 0.9729 - val_loss: 0.0131 - val_accuracy: 0.9714\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0674 - accuracy: 0.9791 - val_loss: 0.0139 - val_accuracy: 0.9746\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0578 - accuracy: 0.9834 - val_loss: 0.1781 - val_accuracy: 0.9743\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f71d878f150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgHrw7I1y7F7"
      },
      "source": [
        "### Evaluating the `model`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hs9s2bo8y-WN",
        "outputId": "4bee80ad-a9e0-4dd6-9fc5-c44aa8ed4072"
      },
      "source": [
        "new_model.evaluate(X_test_tensors, y_test_tensors, batch_size=32, verbose=1)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0810 - accuracy: 0.9723\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9743000268936157, 0.17808373272418976]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "truuUdfIHyV8"
      },
      "source": [
        "> That's all about creating our own custom `fit()`, `compile()` and `evaluate()` to go in depth [read](https://keras.io/guides/customizing_what_happens_in_fit/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEzryEXbz1fW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}