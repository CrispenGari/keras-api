{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_Custom_Training_Testing_loop.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsWZU7NMi2vJ"
      },
      "source": [
        "### Training loops.\n",
        "\n",
        "In this notebook we are going to create our own, trainning loops.\n",
        "\n",
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7InLgJZzivXz"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vocIXDXRnldb"
      },
      "source": [
        "### Configuring the ``device`` for the environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Albz4LFHnkve"
      },
      "source": [
        "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deJx0d64nPlS"
      },
      "source": [
        "### Let's create a model that will train on the `MNIST` dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9ZTB1WtjadF"
      },
      "source": [
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    \"mnist\",\n",
        "    split=[\"train\", \"test\"],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgsWuJXLlYdB"
      },
      "source": [
        "def normalize_img(image, label):\n",
        "    return tf.cast(image, tf.float32) / 255.0, label"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRo-bFwtlJIn"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "ds_train = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
        "ds_train = ds_train.cache()\n",
        "ds_train = ds_train.shuffle(ds_info.splits[\"train\"].num_examples)\n",
        "ds_train = ds_train.batch(BATCH_SIZE)\n",
        "ds_train = ds_train.prefetch(AUTOTUNE)\n",
        "\n",
        "ds_test = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
        "ds_test = ds_train.batch(128)\n",
        "ds_test = ds_train.prefetch(AUTOTUNE)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDbDn_PzLDng"
      },
      "source": [
        " ### Let's create our custom trainning loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHtvL4_XLDlF"
      },
      "source": [
        "model = keras.Sequential([\n",
        "      keras.layers.Flatten(input_shape=(28, 28)),\n",
        "      keras.layers.Dense(64, activation=\"relu\"),\n",
        "      keras.layers.Dense(128, activation=\"relu\"),\n",
        "      keras.layers.Dense(10)\n",
        "])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp7ITKnEN1f7"
      },
      "source": [
        "criterion = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = keras.optimizers.Adam()\n",
        "accuracy_metric = keras.metrics.SparseCategoricalAccuracy()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et-fBEcUQYYy"
      },
      "source": [
        "### The `train` loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6Fci3rEOKXc",
        "outputId": "f4fbe2ba-e332-4e17-9630-f6e9ceaba824"
      },
      "source": [
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "  print(f\"Epoch: {epoch}/{epochs}\")\n",
        "  for X_batch, y_batch in ds_train:\n",
        "    with tf.GradientTape() as tape:\n",
        "      # forward pass\n",
        "      y_pred = model(X_batch, training=True)\n",
        "      loss = criterion(y_batch, y_pred)\n",
        "    # calculate gradients\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    \n",
        "    # forward pass\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    #update the metrics\n",
        "    accuracy_metric.update_state(y_batch, y_pred)\n",
        " \n",
        "  print(f\"loss: {loss:.3f}, accuracy: {accuracy_metric.result():.3f}\")\n",
        "  accuracy_metric.reset_state()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0/5\n",
            "loss: 0.048, accuracy: 0.910\n",
            "Epoch: 1/5\n",
            "loss: 0.129, accuracy: 0.960\n",
            "Epoch: 2/5\n",
            "loss: 0.049, accuracy: 0.971\n",
            "Epoch: 3/5\n",
            "loss: 0.083, accuracy: 0.977\n",
            "Epoch: 4/5\n",
            "loss: 0.067, accuracy: 0.980\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3X4hbUPWQcLJ"
      },
      "source": [
        "### The `test` loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuByVuLeQfBh",
        "outputId": "b32f65f4-c233-422a-f2d6-2b2886c06226"
      },
      "source": [
        "for x_batch, y_batch in ds_test:\n",
        "  y_pred = model(x_batch, training=False)\n",
        "  loss = criterion(y_batch, y_pred)\n",
        "  accuracy_metric.update_state(y_batch, y_pred)\n",
        "\n",
        "print(f\"loss: {loss:.3f}, accuracy: {accuracy_metric.result():.3f}\")\n",
        "accuracy_metric.reset_state()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 0.084, accuracy: 0.985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMJISFexc-B7"
      },
      "source": [
        "That's how flexible are custom trainning loops."
      ]
    }
  ]
}