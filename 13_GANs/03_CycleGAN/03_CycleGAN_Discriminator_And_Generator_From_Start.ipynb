{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_CycleGAN_Discriminator_And_Generator_From_Start.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e1sUNi-DTl9"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecMqnOLuIBan"
      },
      "source": [
        "\n",
        "The model architecture used in this notebook is very similar to what was used in [pix2pix](https://github.com/tensorflow/examples/blob/master/tensorflow_examples/models/pix2pix/pix2pix.py). Some of the differences are:\n",
        "\n",
        "* Cyclegan uses [instance normalization](https://arxiv.org/abs/1607.08022) instead of [batch normalization](https://arxiv.org/abs/1502.03167).\n",
        "* The [CycleGAN](https://arxiv.org/abs/1703.10593) paper uses a modified resnet based generator. This notebook is using a modified unet generator for simplicity.\n",
        "There are 2 generators (G and F) and 2 discriminators (X and Y) being trained here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSUAiAfyISj_"
      },
      "source": [
        "### Instace Normalization.\n",
        "First we will create an ``InstanceNormalization``Layer from this [paper](https://arxiv.org/abs/1607.08022)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72KSSZizVjxs",
        "outputId": "73ee3b2a-7366-4111-fae5-55a500769bfb"
      },
      "source": [
        "test_image = tf.random.normal([256, 256, 3])\n",
        "test_image.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([256, 256, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CkuCxbLEyH_"
      },
      "source": [
        "class InstanceNormalization(keras.layers.Layer):\n",
        "  def __init__(self, epsilon=1e-5):\n",
        "    super(InstanceNormalization, self).__init__()\n",
        "    self.epsilon = epsilon\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.scale = self.add_weight(\n",
        "        name=\"scale\",\n",
        "        shape=input_shape[-1:],\n",
        "        initializer=tf.random_normal_initializer(1., 0.02),\n",
        "        trainable = True\n",
        "    )\n",
        "    self.offset = self.add_weight(\n",
        "        name=\"offset\",\n",
        "        shape=input_shape[-1:],\n",
        "        initializer = \"zeros\",\n",
        "        trainable = True\n",
        "    )\n",
        "  \n",
        "  def call(self, x):\n",
        "    mean, varience = tf.nn.moments(\n",
        "        x, axes=[1, 2], keepdims=True\n",
        "    )\n",
        "    inv = tf.math.rsqrt(variance + self.epsilon)\n",
        "    normalized = (x - mean) * inv\n",
        "    return self.scale * normalized + self.offset\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_e_RW1TuJ_Mv"
      },
      "source": [
        "### Encoder, (Downsampler)\n",
        "We are going to create a class that will downsample the image from higher resolution to a lower resolution. The structure of the downsampler is as follows:\n",
        "\n",
        "```py\n",
        "[ Conv2D ] => [ Batchnorm ] => [ LeakyRelu ]\n",
        "```\n",
        "\n",
        "Args:\n",
        "\n",
        "```\n",
        "  Args:\n",
        "    filters: number of filters\n",
        "    size: filter size\n",
        "    norm_type: Normalization type; either 'batchnorm' or 'instancenorm'.\n",
        "    apply_norm: If True, adds the batchnorm layer\n",
        "```\n",
        "\n",
        "Return:\n",
        "```\n",
        "Downsample Keras Layer\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4PxEWG4J6oE"
      },
      "source": [
        "class Encoder(keras.layers.Layer):\n",
        "  def __init__(self, in_features, kernel_size,\n",
        "               norm_type=\"batchnorm\", apply_norm=True):\n",
        "    super(Encoder, self).__init__()\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "    self.apply_norm = apply_norm\n",
        "\n",
        "    self.conv = keras.layers.Conv2D(\n",
        "        in_features, kernel_size = kernel_size, strides=2,\n",
        "        padding=\"same\",\n",
        "        kernel_initializer=initializer, use_bias=False\n",
        "    )\n",
        "\n",
        "    self.norm = None\n",
        "    if  norm_type.lower() == 'batchnorm':\n",
        "      self.norm = keras.layers.BatchNormalization()\n",
        "    elif norm_type.lower() == 'instancenorm':\n",
        "       self.norm = InstanceNormalization()\n",
        "\n",
        "    self.l_relu = keras.layers.LeakyReLU()\n",
        "    \n",
        "  def call(self, x):\n",
        "    x = self.conv(x)\n",
        "    if self.apply_norm:\n",
        "      x = self.norm(x)\n",
        "    return self.l_relu(x)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqqQa0ciVyRF",
        "outputId": "7ec1e88b-c48a-4c35-a7b6-d1fafb569559"
      },
      "source": [
        "down_model = Encoder(3, 4)\n",
        "down_model(tf.expand_dims(test_image, 0)).shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 128, 128, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLLtQBW3N0q-"
      },
      "source": [
        "### Decoder (Upsampler).\n",
        "\n",
        "In the ``Decoder`` or the `Upsampler` we are going to use the ``Conv2DTranspose()`` you can also use the UpSampling2D together with ``Conv2D`` which is what we will do later on. The structure of this layer looks as follows:\n",
        "\n",
        "```\n",
        "[ Conv2DTranspose ] => [ Batchnorm ] => [ Dropout ] => [ ReLu ]\n",
        "```\n",
        "\n",
        "Args:\n",
        "```\n",
        "  Args:\n",
        "    filters: number of filters\n",
        "    size: filter size\n",
        "    norm_type: Normalization type; either 'batchnorm' or 'instancenorm'.\n",
        "    apply_dropout: If True, adds the dropout layer\n",
        "```\n",
        "\n",
        "Returns:\n",
        "```\n",
        "Returns:\n",
        "    Upsample Keras Layer.\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2MlUJmBLZWf"
      },
      "source": [
        "class Decoder(keras.layers.Layer):\n",
        "  def __init__(self, in_features, kernel_size, \n",
        "               norm_type=\"batchnorm\", apply_dropout=False):\n",
        "    super(Decoder, self).__init__()\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "    self.norm = None\n",
        "    self.apply_dropout = apply_dropout\n",
        "    self.conv_2d_transpose = keras.layers.Conv2DTranspose(\n",
        "      in_features, kernel_size=kernel_size, strides=2,\n",
        "      padding=\"same\",\n",
        "      kernel_initializer= initializer,\n",
        "      use_bias = False\n",
        "    )\n",
        "    if norm_type.lower() == 'batchnorm':\n",
        "      self.norm = keras.layers.BatchNormalization()\n",
        "    elif norm_type.lower() == 'instancenorm':\n",
        "      self.norm = InstanceNormalization()\n",
        "\n",
        "    self.dropout = keras.layers.Dropout(.5, name=\"decoder_dropout\")\n",
        "    self.relu = keras.layers.ReLU()\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv_2d_transpose(x)\n",
        "    x = self.norm(x)\n",
        "    if self.apply_dropout:\n",
        "      x = self.dropout(x)\n",
        "    return self.relu(x)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0jGXgjhRJrV"
      },
      "source": [
        "### The ``discriminator`` model.\n",
        "\n",
        "We are going to us the [PatchGan](https://arxiv.org/abs/1611.07004) discriminator. which take the following args:\n",
        "\n",
        "```\n",
        "Args:\n",
        "    norm_type: Type of normalization. Either 'batchnorm' or 'instancenorm'.\n",
        "    target: Bool, indicating whether target image is an input or not.\n",
        "```\n",
        "and returns:\n",
        "\n",
        "```\n",
        "Returns:\n",
        "  Discriminator model\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IurVfZBYU07t"
      },
      "source": [
        "IMG_HEIGHT = IMG_WIDTH = 256"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybu60_85QHeE"
      },
      "source": [
        "def discriminator(norm_type='batchnorm', target=True):\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "  inp = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, 3], name='input_image')\n",
        "  x = inp\n",
        "\n",
        "  if target:\n",
        "    tar = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, 3], name='target_image')\n",
        "    x = keras.layers.concatenate([inp, tar], name=\"concatenated_inputs\") # (batch_size, 256, 256, channels*2)\n",
        " \n",
        "  down_1 = Encoder(64, 4, norm_type,  False)(x) # (batch_size, 128, 128, 64)\n",
        "  down_2 = Encoder(128, 4, norm_type)(down_1)  # (batch_size, 64, 64, 128)\n",
        "  down_3 = Encoder(256, 4, norm_type)(down_2) # (batch_size, 32, 32, 256)\n",
        "  zero_pad1 = keras.layers.ZeroPadding2D(name=\"zero_padding_layer_1\")(down_3) # (batch_size, 34, 34, 256)\n",
        "  \n",
        "  conv = keras.layers.Conv2D(512, 4, strides=1, kernel_initializer=initializer,\n",
        "                             use_bias=False,\n",
        "                             name=\"conv_layer\")(zero_pad1)\n",
        "  norm = None\n",
        "  if norm_type.lower() == \"batchnorm\":\n",
        "    norm = keras.layers.BatchNormalization(name=\"batch_norm\")(conv)\n",
        "  elif norm_type.lower() == 'instancenorm':\n",
        "    norm = InstanceNormalization()(conv)\n",
        "  \n",
        "  leaky_relu = keras.layers.LeakyReLU(name=\"leaky_relu\")(norm)\n",
        "\n",
        "  zero_pad2 = keras.layers.ZeroPadding2D(name=\"zero_padding_layer_2\")(leaky_relu) # (batch_size, 33, 33, 512)\n",
        "  last = keras.layers.Conv2D(1, 4, strides=1,\n",
        "                                kernel_initializer=initializer,\n",
        "                             name=\"output_layer\"\n",
        "                             )(zero_pad2)  # (batch_size, 30, 30, 1)\n",
        "\n",
        "  if target:\n",
        "    return keras.Model(inputs=[inp, tar], outputs=last, name=\"discriminator_model\")\n",
        "  else:\n",
        "    return keras.Model(inputs=inp, outputs=last, name=\"discriminator_model\")\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iM7ghpXRr0S",
        "outputId": "9eed55db-0ee4-4bf6-cf28-2a38aeded3d2"
      },
      "source": [
        "discriminator().summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"discriminator_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_image (InputLayer)        [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "target_image (InputLayer)       [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenated_inputs (Concatenat (None, 256, 256, 6)  0           input_image[0][0]                \n",
            "                                                                 target_image[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "encoder_15 (Encoder)            (None, 128, 128, 64) 6144        concatenated_inputs[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "encoder_16 (Encoder)            (None, 64, 64, 128)  131584      encoder_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "encoder_17 (Encoder)            (None, 32, 32, 256)  525312      encoder_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding_layer_1 (ZeroPaddi (None, 34, 34, 256)  0           encoder_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv_layer (Conv2D)             (None, 31, 31, 512)  2097152     zero_padding_layer_1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_norm (BatchNormalization) (None, 31, 31, 512)  2048        conv_layer[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_relu (LeakyReLU)          (None, 31, 31, 512)  0           batch_norm[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding_layer_2 (ZeroPaddi (None, 33, 33, 512)  0           leaky_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "output_layer (Conv2D)           (None, 30, 30, 1)    8193        zero_padding_layer_2[0][0]       \n",
            "==================================================================================================\n",
            "Total params: 2,770,433\n",
            "Trainable params: 2,768,641\n",
            "Non-trainable params: 1,792\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e70H4X9bZG70"
      },
      "source": [
        "### The ``generator`` model.\n",
        "\n",
        "We are going to build a `unet_generator` based on [this paper](https://arxiv.org/abs/1611.07004) which takes the following args.\n",
        "\n",
        "Args:\n",
        "```\n",
        "Args:\n",
        "  output_channels: Output channels\n",
        "  norm_type: Type of normalization. Either 'batchnorm' or 'instancenorm'.\n",
        "```\n",
        "\n",
        "Return:\n",
        "```\n",
        "  Returns:\n",
        "    Generator model\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfD88Kn3Rruj"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U37-A8E4Rrq8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuyDsfcDRrnz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6Cz4VbtPIq3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}