{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "essential-venue",
   "metadata": {},
   "source": [
    "### DCGAN's (Deep Convlutional Generative Adversarial Networks).\n",
    "\n",
    "Generative Adversarial Networks `(GANs)` are one of the most interesting ideas in computer science today. Two models are trained simultaneously by an adversarial process. A **generator** (\"the artist\") learns to create images that look real, while a **discriminator** (\"the art critic\") learns to tell real images apart from fakes.\n",
    "\n",
    "\n",
    "````\n",
    "\n",
    "       [-------------]                  [--------------]\n",
    "   --> [Discriminator] -> (fake/real)   [  Generator   ]-|\n",
    "   |   [_____________]                  [______________] |\n",
    "   |_____________________________________________________|\n",
    "                       (Generated image)(fake)\n",
    "\n",
    "````\n",
    "1. So the generator its purpose is to genarate images from random noise and pass to he discriminator to detemine if the image is real or fake.\n",
    "2. The discriminator then detemines if the image is for sure real or fake.\n",
    "3. So we have 2 agents in an environment (discriminator) and (generator)\n",
    "4. Their goal is to maximize their rewards. **But how?**.\n",
    "5. A generator gets it's reward when a discriminator fake fake from real images.\n",
    "6. A discrimnator then get's it's reward if it can not be fooled by the generator.\n",
    "7. **As we train more and more the generator model will become better and better so that it will be able to produce fake images that a discriminator model can not discriminate from real images.**\n",
    "\n",
    "### Let's implement this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-vehicle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing import image , image_dataset_from_directory\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-daily",
   "metadata": {},
   "source": [
    "### Renaming all the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "veterinary-george",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'data/images/img_10.jpg' -> 'data/images/img_2.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-2f7cfa6122b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/images/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'data/images/{image}'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf'data/images/img_{i}.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Done\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'data/images/img_10.jpg' -> 'data/images/img_2.jpg'"
     ]
    }
   ],
   "source": [
    "for i, image in enumerate(os.listdir('./data/images/')):\n",
    "    os.rename(f'data/images/{image}', f'data/images/img_{i}.jpg')\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-lyric",
   "metadata": {},
   "source": [
    "### Folder Structures\n",
    "\n",
    "```\n",
    "data\n",
    "    images\n",
    "```\n",
    "\n",
    "### Creating a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "comfortable-uncertainty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3308 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "ds = image_dataset_from_directory(\n",
    "    './data',\n",
    "    label_mode = None,# because unsupervised\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    image_size=(64, 64),\n",
    ").map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-conspiracy",
   "metadata": {},
   "source": [
    "### Displaying some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "documented-munich",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x in ds:\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow((x.numpy() * 255).astype(\"int32\")[0], cmap=\"gray\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-auction",
   "metadata": {},
   "source": [
    "### Create the discriminator.\n",
    "This model will maps the (`image_width` x `image_height`) in our case (`64` x `64`) to a binary class (**fake** or **real**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "seventh-rolling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        3136      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       131200    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 8193      \n",
      "=================================================================\n",
      "Total params: 404,801\n",
      "Trainable params: 404,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = keras.Sequential([\n",
    "    keras.layers.Input(shape=(64, 64, 3)),\n",
    "    keras.layers.Conv2D(64, kernel_size=(4, 4), padding=\"same\", strides=(2, 2)),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Conv2D(128, kernel_size=(4, 4), padding=\"same\", strides=(2, 2)),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Conv2D(128, kernel_size=(4, 4), padding=\"same\", strides=(2, 2)),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dropout(.2),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "], name=\"discriminator\")\n",
    "\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-narrative",
   "metadata": {},
   "source": [
    "### Create the generator.\n",
    "This model is the mirror of the `discriminator` model. Replacing `Conv2D` layers with `Conv2DTranspose` layers.\n",
    "\n",
    "* `Conv2DTranspose` - is just an inverse of `Conv2D`.\n",
    "* Our goal is to create an image from a vector to an image of shape `(64, 64, 3)`.\n",
    "* We are going to have `128` latent_dim.\n",
    "* `\"latent_dim\"` is the number of nodes used as input of the generator.\n",
    "\n",
    "#### Implementation\n",
    "1. We will start with the image of shape `8` x `8`.\n",
    "2. Add a reshape layer to get shape (8 x 8 x latent_dim)\n",
    "3. Our image now is in a shape that we can put in a `Conv` layer.\n",
    "4. We will then add a `Conv2DTranspose` layer with `strides =2`. Why? Remember in a normal Conv2D if we have an image of shape (16, 16)  and strides are (2, 2) the image will be reduced to (8, 8) but in a `Conv2DTranspose` the image will be increased to (32, 32) shape, which is our goal. So we want to add these `Conv2DTranspose` layers until we reach (64, 64) image shape.\n",
    "\n",
    "5. We will then add `Conv2D` layer with 3 input features, this is because we want to output 3 channels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "tracked-virginia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8192)              1056768   \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 16, 16, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 256)       524544    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 64, 64, 512)       2097664   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 64, 64, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 3)         38403     \n",
      "=================================================================\n",
      "Total params: 3,979,651\n",
      "Trainable params: 3,979,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 128\n",
    "generator = keras.Sequential([\n",
    "    keras.layers.Input(shape=(latent_dim, )),\n",
    "    keras.layers.Dense(8 * 8 * latent_dim, activation=\"relu\"),\n",
    "    keras.layers.Reshape((8, 8, latent_dim)),\n",
    "    keras.layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "    keras.layers.LeakyReLU(0.2),\n",
    "    keras.layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
    "    keras.layers.LeakyReLU(0.2),\n",
    "    keras.layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
    "    keras.layers.LeakyReLU(0.2),\n",
    "    keras.layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n",
    "], name=\"generator\")\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-extreme",
   "metadata": {},
   "source": [
    "### Override `train_step`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "recent-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(GAN, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "    # .compile()\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "        \n",
    "    @property\n",
    "    def metric(self):\n",
    "        return [\n",
    "            self.d_loss_metric,\n",
    "            self.g_loss_metric\n",
    "        ]\n",
    "    \n",
    "    # .fit()\n",
    "    def train_step(self, real_images):\n",
    "        # Sample random points in the latent space\n",
    "        \"\"\"\n",
    "        We need to create latent_vectors with shape (batch_size_of_real_images, latent_dim)\n",
    "        \"\"\"\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        \n",
    "        \"\"\"\n",
    "        Generate fake images of size (batch_size)\n",
    "        \"\"\"\n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "        \n",
    "        \"\"\"\n",
    "        Combine images, generated and real\n",
    "        \"\"\"\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "\n",
    "        \"\"\"\n",
    "        Assemble labels discriminating real from fake images\n",
    "        \"\"\"\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "        \"\"\"\n",
    "        Add random noise to the labels - important trick!\n",
    "        \"\"\"\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "        \n",
    "        \"\"\"\n",
    "        Train the discriminator.\n",
    "        \"\"\"\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "            \n",
    "        gradients = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(gradients, self.discriminator.trainable_weights )\n",
    "        )\n",
    "        \n",
    "        # Sample random points in the latent space\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Assemble labels that say \"all real images\"\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "        \"\"\"\n",
    "        Train the generator (note that we should *not* update the weights\n",
    "        of the discriminator)!\n",
    "        \"\"\"\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Update metrics\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\n",
    "            \"d_loss\": self.d_loss_metric.result(),\n",
    "            \"g_loss\": self.g_loss_metric.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-layer",
   "metadata": {},
   "source": [
    "### Create a callback that periodically saves `generated` images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ignored-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('generated'):\n",
    "    os.mkdir('generated')\n",
    "\n",
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = keras.preprocessing.image.array_to_img(generated_images[i])\n",
    "            img.save(\"generated/generated_img_%03d_%d.png\" % (epoch, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-belgium",
   "metadata": {},
   "source": [
    "### Train the end-to-end model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "magnetic-effectiveness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7/104 [=>............................] - ETA: 40:32 - d_loss: 0.6702 - g_loss: 0.7799"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-1af6045ce951>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mloss_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBinaryCrossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m )\n\u001b[1;32m----> 8\u001b[1;33m gan.fit(\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mGANMonitor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_img\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m )\n",
      "\u001b[1;32m~\\Documents\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\Documents\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1  # In practice, use ~100 epochs\n",
    "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
    ")\n",
    "gan.fit(\n",
    "    ds, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-worry",
   "metadata": {},
   "source": [
    "### Reference.\n",
    "\n",
    "* [Keras DCGANs](https://keras.io/examples/generative/dcgan_overriding_train_step/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-instruction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
