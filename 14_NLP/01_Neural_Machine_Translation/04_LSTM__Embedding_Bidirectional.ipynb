{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_LSTM__Embedding_Bidirectional.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBEmZC70Drnk"
      },
      "source": [
        "### Bidirectional LSTM\n",
        "\n",
        "In this notebook we are going to expand the previous notebook even futher by make use of the Bidirectional LSTM, model that will be able to get reasonable accuracy in translating sequences from english to french.\n",
        "\n",
        "**Note**: The rest of the notebook will remain the same, when there's a change i will highlight.\n",
        "\n",
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEGRciNODh3o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2b4a826a-8a31-4e82-d763-28a856f0570c"
      },
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "import helper, os, time\n",
        "\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-6SXAJDHBHa"
      },
      "source": [
        "### Mounting the Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3C26uJADrWf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f3b428e-d7cd-4703-bf8f-fafd1a23d575"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rc3hfXU7HZix"
      },
      "source": [
        "### Paths to the files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_690XgdzDrTz"
      },
      "source": [
        "base_path = '/content/drive/MyDrive/NLP Data/seq2seq/fr-en-small'\n",
        "en_path = 'small_vocab_en.txt'\n",
        "fr_path = 'small_vocab_fr.txt'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gltNO_9sH4B7"
      },
      "source": [
        "### Loading the data.\n",
        "\n",
        "We have two files that are located at this path `'/content/drive/MyDrive/NLP Data/seq2seq/fr-en-small'` and thes files are:\n",
        "\n",
        "```\n",
        "small_vocab_fr.txt\n",
        "small_vocab_en.txt\n",
        "```\n",
        "\n",
        "The following line help us to load the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "581k-VQpDrOY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "293b77aa-adc9-471b-fb99-1e3ec4e9cc79"
      },
      "source": [
        "eng_sents = open(os.path.join(base_path, en_path), encoding='utf8').read().split('\\n')\n",
        "fre_sents = open(os.path.join(base_path, fr_path), encoding='utf8').read().split('\\n')\n",
        "\n",
        "print(\"Data Loaded\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EroZAWUvJneb",
        "outputId": "75861631-3b91-491d-ed01-f47423fbd77c"
      },
      "source": [
        "eng_sents[1]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'the united states is usually chilly during july , and it is usually freezing in november .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzQHLHzDJwYB"
      },
      "source": [
        "By looking at the data we can see that the data is already preprocessed, which means we are not going to do that step here.\n",
        "\n",
        "### Next, Bulding the Vocabulary.\n",
        "\n",
        "Vocabulary in my definition is just unique words in the curpus. Let's look at the vocabulary size of french and english. But first we need to tokenize each sentence, Inorder for us to do that I'm going to use the `spacy` library which is my favourite when it comes to tokenization of languages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYdwgsDDDrIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01de24e8-8fa0-4b4d-8de3-c72145301f82"
      },
      "source": [
        "import spacy\n",
        "spacy.cli.download('fr_core_news_sm')\n",
        "\n",
        "spacy_fr = spacy.load('fr_core_news_sm')\n",
        "spacy_en = spacy.load('en_core_web_sm')\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em20rVNkDrFo"
      },
      "source": [
        "def tokenize_fr(sent):\n",
        "  return [tok.text for tok in spacy_fr.tokenizer(sent)]\n",
        "  \n",
        "def tokenize_en(sent):\n",
        "  return [tok.text for tok in spacy_en.tokenizer(sent)]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqbCQ512DrCi"
      },
      "source": [
        "en_counter = Counter()\n",
        "fr_counter = Counter()\n",
        "\n",
        "for sent in eng_sents:\n",
        "  en_counter.update(tokenize_en(sent.lower()))\n",
        "for sent in fre_sents:\n",
        "  fr_counter.update(tokenize_fr(sent.lower()))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq9JM8HIL6RT",
        "outputId": "d8874944-b166-41d1-87bf-107c7d7cefb6"
      },
      "source": [
        "en_vocab_size = len(en_counter)\n",
        "fr_vocab_size = len(fr_counter)\n",
        "\n",
        "fr_vocab_size, en_vocab_size"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(340, 201)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4n7K3LsMWW8"
      },
      "source": [
        "Here we have `340` unique words for french in this dataset and `201` unique words for english.\n",
        "\n",
        "### Preprocessing.\n",
        "\n",
        "We will convert our text data into sequence of integers so basically we are going to perform the following:\n",
        "\n",
        "1. Tokenize the words into ids\n",
        "2. Pad the tokens so that they will have same length.\n",
        "\n",
        "For this task we are going to use the keras `Tokenizer` class to perform the task, We have been using this for sentiment analyisis so the procedure is the same.\n",
        "\n",
        "We are going to have two tokenizers for each language.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_JJVUlADq_q"
      },
      "source": [
        "en_tokenizer = Tokenizer(num_words=en_vocab_size, oov_token=\"<oov>\")\n",
        "en_tokenizer.fit_on_texts(eng_sents)\n",
        "\n",
        "fr_tokenizer = Tokenizer(num_words=fr_vocab_size, oov_token=\"<oov>\")\n",
        "fr_tokenizer.fit_on_texts(fre_sents)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1EScuA6T1Nx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APoyIFAiDq7x"
      },
      "source": [
        "en_word_indices = en_tokenizer.word_index\n",
        "en_word_indices_reversed = dict([\n",
        "    (v, k) for (k, v) in en_word_indices.items()\n",
        "])\n",
        "\n",
        "fr_word_indices = fr_tokenizer.word_index\n",
        "fr_word_indices_reversed = dict([\n",
        "    (v, k) for (k, v) in fr_word_indices.items()\n",
        "])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "An7_ADx7Olap"
      },
      "source": [
        "### Helper functions\n",
        "We will create some helper function that converts sequences to text and text to sequences for each language. These function will be used for inference later on.\n",
        "\n",
        "**We have set the out of vocabulary `oov_token|| <\"oov\">`token to `1`  which means the word that does not exist in the vocabulary it's integer representation is 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDQsSkoAOlBS"
      },
      "source": [
        "def en_seq_to_text(sequences):\n",
        "  return \" \".join(en_word_indices_reversed[i] for i in sequences )\n",
        "\n",
        "def en_seq_to_text(sequences):\n",
        "  return \" \".join(fr_word_indices_reversed[i] for i in sequences )\n",
        "\n",
        "def en_text_to_seq(sent):\n",
        "  words = tokenize_en(sent.lower())\n",
        "  sequences = []\n",
        "  for word in words:\n",
        "    try:\n",
        "      sequences.append(en_word_indices[word])\n",
        "    except:\n",
        "      sequences.append(1)\n",
        "  return sequences\n",
        "\n",
        "def fr_text_to_seq(sent):\n",
        "  words = tokenize_fr(sent.lower())\n",
        "  sequences = []\n",
        "  for word in words:\n",
        "    try:\n",
        "      sequences.append(fr_word_indices[word])\n",
        "    except:\n",
        "      sequences.append(1)\n",
        "  return sequences"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwvQ_uFHTTBK"
      },
      "source": [
        "### Converting text to sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nspRxCCTSUs"
      },
      "source": [
        "en_sequences = en_tokenizer.texts_to_sequences(eng_sents)\n",
        "fr_sequences = fr_tokenizer.texts_to_sequences(fre_sents)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnbY97HGUrGP",
        "outputId": "81fc38df-b1be-4f00-8250-8452f1423d18"
      },
      "source": [
        "fr_sequences[0:4]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[36, 35, 2, 9, 68, 38, 12, 25, 7, 4, 2, 113, 3, 51],\n",
              " [5, 33, 32, 2, 13, 20, 3, 50, 7, 4, 96, 70, 3, 52],\n",
              " [102, 2, 13, 68, 3, 46, 7, 4, 2, 13, 22, 3, 42],\n",
              " [5, 33, 32, 2, 9, 270, 3, 42, 7, 4, 104, 20, 3, 49]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKF4CdRUQJCy"
      },
      "source": [
        "### Padding Sequences.\n",
        "\n",
        "In our case we are going to assume that the longest sentence has `100` words for both `fr` and `en` languages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhkhdZ-8QI4F"
      },
      "source": [
        "max_words = 100\n",
        "en_tokens_padded = pad_sequences(\n",
        "    en_sequences, \n",
        "    maxlen=max_words, \n",
        "    padding=\"post\", \n",
        "    truncating=\"post\"\n",
        ")\n",
        "fr_tokens_padded = pad_sequences(\n",
        "    fr_sequences, \n",
        "    maxlen=max_words, \n",
        "    padding=\"post\", \n",
        "    truncating=\"post\"\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHomR9cmDq2s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2027c21f-e820-495a-b450-05a7c29b5816"
      },
      "source": [
        "en_tokens_padded[:2]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[18, 24,  2,  9, 68,  5, 40,  8,  4,  2, 56,  3, 45,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0],\n",
              "       [ 6, 21, 22,  2, 10, 63,  5, 44,  8,  4,  2, 10, 52,  3, 46,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FJ69jNAVOnT"
      },
      "source": [
        "### Logits to text.\n",
        "\n",
        "We are going to create 1 more helper function that will help us to take logits or the predictions probabilities and then we convert them to human understandable format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDlG7MzYVvi2"
      },
      "source": [
        "\n",
        "def logits_to_text(logits, tokenizer):\n",
        "  index_to_words = {id: word for word, id\n",
        "                    in tokenizer.word_index.items()}\n",
        "  index_to_words[0] = '<pad>'\n",
        "  \"\"\"\n",
        "  For every prediction we are going to ignore the pad token\n",
        "  \"\"\"\n",
        "  return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)]).replace(\"<pad>\", \"\")\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moeeDvRxYQhd"
      },
      "source": [
        "### Bidirectional LSTM\n",
        "\n",
        "We are going to create a bidirectional LSTM model with both LSTM layers for the backward and forward layers\n",
        "\n",
        "![img](https://github.com/LeanManager/Machine_Translation/raw/e6567f10a6e380eea453fa392de94f26973c8b16/images/bidirectional.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTvuC7kQYMcU",
        "outputId": "9b8b786a-5be5-4dba-9651-60d7aba77b17"
      },
      "source": [
        "\n",
        "forward_layer = keras.layers.LSTM(128, dropout=.5,\n",
        "                                    return_sequences=True,\n",
        "                                  go_backwards=False\n",
        "                                    )\n",
        "backward_layer = keras.layers.LSTM(128, dropout=.5,\n",
        "                                    return_sequences=True,\n",
        "                                  go_backwards=True\n",
        "                                    )\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Embedding(\n",
        "        en_vocab_size,\n",
        "        128, \n",
        "        input_length=max_words\n",
        "    ),\n",
        "  keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=False)),\n",
        "   keras.layers.RepeatVector(100),\n",
        "  keras.layers.Bidirectional(forward_layer, backward_layer=backward_layer),\n",
        "  keras.layers.TimeDistributed(keras.layers.Dense(fr_vocab_size, activation='softmax'))\n",
        "    \n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_17 (Embedding)     (None, 100, 128)          25728     \n",
            "_________________________________________________________________\n",
            "bidirectional_29 (Bidirectio (None, 256)               263168    \n",
            "_________________________________________________________________\n",
            "repeat_vector_3 (RepeatVecto (None, 100, 256)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_30 (Bidirectio (None, 100, 256)          394240    \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, 100, 340)          87380     \n",
            "=================================================================\n",
            "Total params: 770,516\n",
            "Trainable params: 770,516\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvgWiu5UcWhw",
        "outputId": "bc643adb-de01-4085-9dd2-8fc108dece38"
      },
      "source": [
        "tmp_x = en_tokens_padded.reshape(\n",
        "   -1, 100, 1\n",
        ")\n",
        "tmp_x.shape"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(137861, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpbN8rTBb9Qy",
        "outputId": "54a4c9c4-ae5b-41a4-dbce-c7504b06b553"
      },
      "source": [
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(tmp_x, \n",
        "          fr_tokens_padded, \n",
        "          batch_size=1024, \n",
        "          epochs=30,\n",
        "          validation_split=0.2\n",
        ")\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "108/108 [==============================] - 35s 282ms/step - loss: 0.9868 - accuracy: 0.8706 - val_loss: 0.5507 - val_accuracy: 0.8870\n",
            "Epoch 2/30\n",
            "108/108 [==============================] - 29s 270ms/step - loss: 0.5278 - accuracy: 0.8880 - val_loss: 0.4931 - val_accuracy: 0.8919\n",
            "Epoch 3/30\n",
            "108/108 [==============================] - 29s 267ms/step - loss: 0.4725 - accuracy: 0.8959 - val_loss: 0.4473 - val_accuracy: 0.9032\n",
            "Epoch 4/30\n",
            "108/108 [==============================] - 29s 269ms/step - loss: 0.4301 - accuracy: 0.9034 - val_loss: 0.3991 - val_accuracy: 0.9068\n",
            "Epoch 5/30\n",
            "108/108 [==============================] - 29s 269ms/step - loss: 0.3703 - accuracy: 0.9078 - val_loss: 0.3403 - val_accuracy: 0.9121\n",
            "Epoch 6/30\n",
            "108/108 [==============================] - 29s 269ms/step - loss: 0.3333 - accuracy: 0.9129 - val_loss: 0.3154 - val_accuracy: 0.9165\n",
            "Epoch 7/30\n",
            "108/108 [==============================] - 29s 268ms/step - loss: 0.3112 - accuracy: 0.9174 - val_loss: 0.2989 - val_accuracy: 0.9206\n",
            "Epoch 8/30\n",
            "108/108 [==============================] - 29s 270ms/step - loss: 0.2917 - accuracy: 0.9214 - val_loss: 0.2764 - val_accuracy: 0.9257\n",
            "Epoch 9/30\n",
            "108/108 [==============================] - 29s 270ms/step - loss: 0.2726 - accuracy: 0.9261 - val_loss: 0.2607 - val_accuracy: 0.9294\n",
            "Epoch 10/30\n",
            "108/108 [==============================] - 29s 270ms/step - loss: 0.2574 - accuracy: 0.9294 - val_loss: 0.2435 - val_accuracy: 0.9332\n",
            "Epoch 11/30\n",
            "108/108 [==============================] - 29s 270ms/step - loss: 0.2617 - accuracy: 0.9303 - val_loss: 0.2287 - val_accuracy: 0.9364\n",
            "Epoch 12/30\n",
            "108/108 [==============================] - 29s 269ms/step - loss: 0.2274 - accuracy: 0.9361 - val_loss: 0.2162 - val_accuracy: 0.9391\n",
            "Epoch 13/30\n",
            "108/108 [==============================] - 29s 270ms/step - loss: 0.2139 - accuracy: 0.9392 - val_loss: 0.2036 - val_accuracy: 0.9421\n",
            "Epoch 14/30\n",
            "108/108 [==============================] - 29s 270ms/step - loss: 0.2026 - accuracy: 0.9419 - val_loss: 0.1907 - val_accuracy: 0.9452\n",
            "Epoch 15/30\n",
            "108/108 [==============================] - 29s 269ms/step - loss: 0.1913 - accuracy: 0.9448 - val_loss: 0.1813 - val_accuracy: 0.9476\n",
            "Epoch 16/30\n",
            "108/108 [==============================] - 29s 269ms/step - loss: 0.1807 - accuracy: 0.9477 - val_loss: 0.1703 - val_accuracy: 0.9506\n",
            "Epoch 17/30\n",
            "108/108 [==============================] - 29s 269ms/step - loss: 0.1702 - accuracy: 0.9507 - val_loss: 0.1592 - val_accuracy: 0.9541\n",
            "Epoch 18/30\n",
            "108/108 [==============================] - 29s 269ms/step - loss: 0.1592 - accuracy: 0.9539 - val_loss: 0.1480 - val_accuracy: 0.9570\n",
            "Epoch 19/30\n",
            "108/108 [==============================] - 29s 269ms/step - loss: 0.1491 - accuracy: 0.9565 - val_loss: 0.1380 - val_accuracy: 0.9598\n",
            "Epoch 20/30\n",
            "108/108 [==============================] - 29s 270ms/step - loss: 0.1404 - accuracy: 0.9589 - val_loss: 0.1293 - val_accuracy: 0.9624\n",
            "Epoch 21/30\n",
            "108/108 [==============================] - 29s 270ms/step - loss: 0.1323 - accuracy: 0.9611 - val_loss: 0.1222 - val_accuracy: 0.9640\n",
            "Epoch 22/30\n",
            "108/108 [==============================] - 29s 270ms/step - loss: 0.1244 - accuracy: 0.9633 - val_loss: 0.1157 - val_accuracy: 0.9660\n",
            "Epoch 23/30\n",
            "108/108 [==============================] - 29s 270ms/step - loss: 0.1174 - accuracy: 0.9653 - val_loss: 0.1079 - val_accuracy: 0.9686\n",
            "Epoch 24/30\n",
            "108/108 [==============================] - 29s 270ms/step - loss: 0.1104 - accuracy: 0.9675 - val_loss: 0.1012 - val_accuracy: 0.9708\n",
            "Epoch 25/30\n",
            "108/108 [==============================] - 29s 270ms/step - loss: 0.1034 - accuracy: 0.9697 - val_loss: 0.0934 - val_accuracy: 0.9731\n",
            "Epoch 26/30\n",
            "108/108 [==============================] - 29s 270ms/step - loss: 0.0959 - accuracy: 0.9721 - val_loss: 0.0865 - val_accuracy: 0.9753\n",
            "Epoch 27/30\n",
            "108/108 [==============================] - 29s 269ms/step - loss: 0.0899 - accuracy: 0.9739 - val_loss: 0.0810 - val_accuracy: 0.9771\n",
            "Epoch 28/30\n",
            "108/108 [==============================] - 29s 270ms/step - loss: 0.0834 - accuracy: 0.9760 - val_loss: 0.0739 - val_accuracy: 0.9793\n",
            "Epoch 29/30\n",
            "108/108 [==============================] - 29s 270ms/step - loss: 0.0779 - accuracy: 0.9777 - val_loss: 0.0695 - val_accuracy: 0.9806\n",
            "Epoch 30/30\n",
            "108/108 [==============================] - 29s 270ms/step - loss: 0.0723 - accuracy: 0.9795 - val_loss: 0.0646 - val_accuracy: 0.9823\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd254eefd50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVPSOGBSDpb8"
      },
      "source": [
        "The rest of the notebook will remain the same, I believe we can load the \n",
        "word pretrained word embeddings in our embedding layer as well, but that will be later on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kszwT1o-drRi"
      },
      "source": [
        "### Making some predictions.\n",
        "Our model is targeting to predict french words, during the predict function we are going to do the following:\n",
        "\n",
        "1. Get the sequence of the english sentence \n",
        "2. Pad the english sequences and pass them to the model'\n",
        "3. Reshape the logits output to the shape of `(max_len, trg_vocabsize(french)`\n",
        "4. Call the `logits_to_text` function and pass the tokenizer as the `fr_tokenizer`.\n",
        "5. Get the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3iYsDDTzZzx0",
        "outputId": "3319348b-ed2a-412f-972f-c527d5637d51"
      },
      "source": [
        "def predict(sent):\n",
        "  sequences = en_text_to_seq(sent)\n",
        "  padded_tokens = pad_sequences([sequences], maxlen=max_words, padding=\"post\", truncating=\"post\")\n",
        "  logits = model(padded_tokens)\n",
        "  logits = tf.reshape(logits, (100, -1))\n",
        "  return logits_to_text(logits, fr_tokenizer)\n",
        "predict(\"your least liked fruit is the grape.\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'votre fruit le aimÃ© est le le le le                                                                                           '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLbX_HGdwa9l"
      },
      "source": [
        "### Making more predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfsVPgfWqwsr"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "def tabulate_translations(column_names, data, title, max_characters=25):\n",
        "  table = PrettyTable(column_names)\n",
        "  table.title= title\n",
        "  table.align[column_names[0]] = 'l'\n",
        "  table.align[column_names[1]] = 'l'\n",
        "  table.align[column_names[2]] = 'l'\n",
        "  table._max_width = {column_names[0] :max_characters, column_names[1] :max_characters, column_names[2]:max_characters}\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)\n",
        "columns_names = [\n",
        "    \"English (real src sentence)\", \"French (the actual text)\", \"Translated (translated version)\"\n",
        "]\n",
        "title = \"ENGLISH TO FRENCH TRANSLATOR\""
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YO1nrCJvxKXt",
        "outputId": "54ad4397-014e-4a13-9059-2c675bbc4709"
      },
      "source": [
        "max_characters= 25\n",
        "total_translations= 10\n",
        "for i, (eng, fre) in enumerate(zip(eng_sents[:total_translations], fre_sents)):\n",
        "    rows_data = [[eng, fre, predict(eng)]]\n",
        "    if i + 1 != total_translations:\n",
        "      rows_data.append([\"-\" * max_characters, \"-\" * max_characters, \"-\" * max_characters ])\n",
        "    tabulate_translations(columns_names, rows_data, title, max_characters)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| new jersey is sometimes     | new jersey est parfois    | new jersey est parfois calme    |\n",
            "| quiet during autumn , and   | calme pendant l' automne  | pendant cours et l' est et il   |\n",
            "| it is snowy in april .      | , et il est neigeux en    | est en en                       |\n",
            "|                             | avril .                   |                                 |\n",
            "| -------------------------   | ------------------------- | -------------------------       |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| the united states is        | les Ã©tats-unis est        | les Ã©tats unis est gÃ©nÃ©ralement |\n",
            "| usually chilly during july  | gÃ©nÃ©ralement froid en     | froid en juillet et il gÃ¨le     |\n",
            "| , and it is usually         | juillet , et il gÃ¨le      | habituellement habituellement   |\n",
            "| freezing in november .      | habituellement en         | en novembre                     |\n",
            "|                             | novembre .                |                                 |\n",
            "| -------------------------   | ------------------------- | -------------------------       |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| california is usually quiet | california est            | california est gÃ©nÃ©ralement     |\n",
            "| during march , and it is    | gÃ©nÃ©ralement calme en     | calme en mars et il est         |\n",
            "| usually hot in june .       | mars , et il est          | gÃ©nÃ©ralement chaud en en        |\n",
            "|                             | gÃ©nÃ©ralement chaud en     |                                 |\n",
            "|                             | juin .                    |                                 |\n",
            "| -------------------------   | ------------------------- | -------------------------       |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| the united states is        | les Ã©tats-unis est        | les Ã©tats unis est parfois doux |\n",
            "| sometimes mild during june  | parfois lÃ©gÃ¨re en juin ,  | en juin et il est froid froid   |\n",
            "| , and it is cold in         | et il fait froid en       | en septembre                    |\n",
            "| september .                 | septembre .               |                                 |\n",
            "| -------------------------   | ------------------------- | -------------------------       |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| your least liked fruit is   | votre moins aimÃ© fruit    | votre fruit aimÃ© moins aimÃ© le  |\n",
            "| the grape , but my least    | est le raisin , mais mon  | raisin mais mon moins aimÃ© est  |\n",
            "| liked is the apple .        | moins aimÃ© est la pomme . | la pomme pomme                  |\n",
            "| -------------------------   | ------------------------- | -------------------------       |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| his favorite fruit is the   | son fruit prÃ©fÃ©rÃ© est     | son fruit prÃ©fÃ©rÃ© est l'orange  |\n",
            "| orange , but my favorite is | l'orange , mais mon       | mais mon prÃ©fÃ©rÃ© est le raisin  |\n",
            "| the grape .                 | prÃ©fÃ©rÃ© est le raisin .   |                                 |\n",
            "| -------------------------   | ------------------------- | -------------------------       |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| paris is relaxing during    | paris est relaxant en     | paris est relaxant en dÃ©cembre  |\n",
            "| december , but it is        | dÃ©cembre , mais il est    | mais il est gÃ©nÃ©ralement froid  |\n",
            "| usually chilly in july .    | gÃ©nÃ©ralement froid en     | en janvier                      |\n",
            "|                             | juillet .                 |                                 |\n",
            "| -------------------------   | ------------------------- | -------------------------       |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| new jersey is busy during   | new jersey est occupÃ© au  | new jersey est occupÃ© au        |\n",
            "| spring , and it is never    | printemps , et il est     | printemps et il est jamais      |\n",
            "| hot in march .              | jamais chaude en mars .   | jamais en mars                  |\n",
            "| -------------------------   | ------------------------- | -------------------------       |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| our least liked fruit is    | notre fruit est moins     | notre fruit aimÃ© moins aimÃ© le  |\n",
            "| the lemon , but my least    | aimÃ© le citron , mais mon | raisin mais mon moins aimÃ© est  |\n",
            "| liked is the grape .        | moins aimÃ© est le raisin  | le raisin raisin                |\n",
            "|                             | .                         |                                 |\n",
            "| -------------------------   | ------------------------- | -------------------------       |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| the united states is        | les Ã©tats-unis est        | les Ã©tats unis est parfois      |\n",
            "| sometimes busy during       | parfois occupÃ© en janvier | occupÃ© en janvier et il est     |\n",
            "| january , and it is         | , et il est parfois chaud | parfois chaud en novembre       |\n",
            "| sometimes warm in november  | en novembre .             |                                 |\n",
            "| .                           |                           |                                 |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkLm2D3MzNLb"
      },
      "source": [
        "### Conclusion.\n",
        "In this notebook we have learnt how to create an `LSTM` bidirectional model. Then what's next.\n",
        "\n",
        "### Next\n",
        "In the next notebook we will learn how we can make use of the `Encoder-Decoder` model achitecture. And probably we will get reasonable better accuracy than in this model after just training for a few epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjYzfKS0zBZR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}