{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07_Nureal_Machine_Translation_Encoder-Decoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr9mUbejssts"
      },
      "source": [
        "### Nueral Machine Translation\n",
        "\n",
        "In this notebook we are going to create a nueral machine translation model that translate sequencial text from 1 domain to the other domain.\n",
        "\n",
        "I will be following [this](https://blog.paperspace.com/neural-machine-translation-with-tensorflow/) tutorial to bring my code to live. \n",
        "\n",
        "### Imports.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBKju3StssfQ",
        "outputId": "bbc885b3-6e88-4f6e-b0ef-df0b69179860"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import os, time, random, math\n",
        "\n",
        "from tensorflow import keras\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbkM2rh4tjgO"
      },
      "source": [
        "### Data Loading and preprocessing\n",
        "\n",
        "I've already downloaded [this](https://www.manythings.org/anki/fra-eng.zip\n",
        ") dataset and unzip it and uploaded it on my google drive as uasual.\n",
        "\n",
        "### Paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQGpi7cKsscY"
      },
      "source": [
        "base_path = \"/content/drive/My Drive/NLP Data/seq2seq/data/eng-fra.txt\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEx6qgieuziv"
      },
      "source": [
        "### Checking the first line in the corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_awgLeSxu0TE",
        "outputId": "01ff34ac-b0d4-4970-91e0-f5d9b1ce2d43"
      },
      "source": [
        "lines = open(base_path, encoding=\"utf8\").read().split('\\n')\n",
        "lines[0]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Go.\\tVa !'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lutNqAhyvJnJ"
      },
      "source": [
        "### Creating a `Lang` class\n",
        "\n",
        "Let's create a class, for each language that is going to map each word in a language to a unique integer number. \n",
        "\n",
        "This class is going to have three dictionary data structures, one to map each word to a unique integer, one to map an integer to a word and the third, to map a word to its total number in the corpus. \n",
        "\n",
        "The class is going to have two important functions to add words from the corpus to their class dictionaries. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DiVu6NUssX1"
      },
      "source": [
        "class Lang:\n",
        "  def __init__(self, name):\n",
        "    self.name = name\n",
        "    self.stoi = {} # string to intenger\n",
        "    self.stof = {} # string to frequence\n",
        "    self.itos = {0 : \"<sos>\", 1 : \"<eos>\", 2: \"<unk>\"}  # integer to string\n",
        "    self.word_count = 3 # initial tokens are 3, <sos>,...\n",
        "\n",
        "  def addWord(self, word):\n",
        "    if word not in self.stoi:\n",
        "      self.stoi[word] = self.word_count\n",
        "      self.stof[word] = 1\n",
        "      self.itos[self.word_count] = word\n",
        "      self.word_count += 1\n",
        "    else:\n",
        "      self.stof[word] += 1\n",
        "\n",
        "  def addSentence(self, sentence):\n",
        "    # Next time we will use tokenizers.\n",
        "    for word in sentence.split(\" \"):\n",
        "      self.addWord(word)\n",
        "      "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrg0ynnkyBgk"
      },
      "source": [
        "### A step futher.\n",
        "Our corpus consists of French words which may have some characters like ‘Ç’. For simplicity sake, we convert them into their normal corresponding ASCII characters(Ç → C). Also we create white spaces between words and punctuation attached to these words . (hello’s → hello s). This is to ensure that the presence of a punctuation does not create two words for a particular word (difference integers would be assign to “they’re” and they are).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwwwFI4essWK"
      },
      "source": [
        "import unicodedata, re\n",
        "\n",
        "def unicodeToAscii(s):\n",
        "  return \"\".join(c for c in unicodedata.normalize(\"NFD\", s) \\\n",
        "                  if unicodedata.category(c) != \"Mn\")\n",
        "    \n",
        "def normalizeString(s):\n",
        "  s = unicodeToAscii(s.lower().strip())\n",
        "  s = re.sub(r\"([!.?])\", r\" \\1\", s)\n",
        "  s = re.sub(r\"[^a-zA-Z?.!]+\", \" \", s)\n",
        "  return s"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3MsUCJYyXdF"
      },
      "source": [
        "### Loading the dataset.\n",
        "Now let's combine these two helper functions and load the dataset containing the pairs of sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LJWXqFXssR2"
      },
      "source": [
        "def load_dataset(path):\n",
        "  lines = open(base_path, encoding=\"utf8\").read().split('\\n')\n",
        "  return [[normalizeString(pair) for pair in \n",
        "              line.strip().split('\\t')] for line in lines]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81es53vXssP-",
        "outputId": "d1254d35-1be6-4068-860f-15d36a63ec45"
      },
      "source": [
        "pairs = load_dataset(base_path)\n",
        "pairs[:2]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['go .', 'va !'], ['run !', 'cours !']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nurdic-zzvWg"
      },
      "source": [
        "To reduce the training time for our demonstration, we are going to filter out our dataset to remove sentences with more than ten words. We can achieve that with the functions below which iterates through our pairs and removes pairs which have sentences containing more than ten words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD8BA212ssMS"
      },
      "source": [
        "MAX_LENGTH = 10\n",
        "def filterPair(p):\n",
        "    return len(p[0].split()) < MAX_LENGTH and len(p[1].split()) < MAX_LENGTH\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]\n",
        "    "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lp6yp_Ja0IKO"
      },
      "source": [
        "### Converting strings to numbers representaion.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1hkdBiJssKS"
      },
      "source": [
        "SOS = 0\n",
        "EOS = 1\n",
        "UNK = 2\n",
        "\n",
        "def sentencetoIndexes(sentence, lang):\n",
        "    indexes = [lang.stoi[word] for word in sentence.split()]\n",
        "    indexes.append(EOS)\n",
        "    return indexes"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VB-NPJsu09lH"
      },
      "source": [
        "Next, we are going to populate our `stoi` disctionary for each language class with words and assign a correcponding integer to each word ina a new function. Also we are going to batch our dataset and apply padding to sentences with words less than the maximum length of 10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffmKvO6NssGY"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "def build_lang(lang1, lang2, max_length=10):\n",
        "  input_lang = Lang(lang1)\n",
        "  output_lang = Lang(lang2)\n",
        "  input_seq = []\n",
        "  output_seq = []\n",
        "  for pair in pairs:\n",
        "    try:\n",
        "      input_lang.addSentence(pair[1])\n",
        "      output_lang.addSentence(pair[0])\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  for pair in pairs:\n",
        "    try:\n",
        "      input_seq.append(sentencetoIndexes(pair[1], input_lang))\n",
        "      output_seq.append(sentencetoIndexes(pair[0], output_lang))\n",
        "    except:\n",
        "      pass\n",
        "  return pad_sequences(input_seq, maxlen=max_length, padding='post', truncating='post'), pad_sequences(output_seq, padding='post', truncating='post'), input_lang, output_lang\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3pdtC24ssEx"
      },
      "source": [
        "input_tensor, output_tensor, input_lang, output_lang = build_lang('fr',\n",
        "                                                                  'en')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwKNwU7GssBB",
        "outputId": "75fa7d1e-bd9a-4fd1-b796-61e2448fd8c1"
      },
      "source": [
        "print(\"input_tensor at index 10: {}\".format(input_tensor[10]))\n",
        "print(\"output_tensor at index 10: {}\".format(output_tensor[10]))\n",
        "print(\"corresponding integer value for 'nous' {}\".format(input_lang.stoi['nous']))\n",
        "print(\"corresponding integer value for 'she' {}\".format(output_lang.stoi['she']))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_tensor at index 10: [20  4  1  0  0  0  0  0  0  0]\n",
            "output_tensor at index 10: [12  6  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0]\n",
            "corresponding integer value for 'nous' 83\n",
            "corresponding integer value for 'she' 158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJHA2-DA5AW1"
      },
      "source": [
        "### Creating data batches.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X24woyLUsr-8"
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor)\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (input_tensor, output_tensor)\n",
        ").shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8w35aG15mbA"
      },
      "source": [
        "### Building the `Seq2Seq` model.\n",
        "\n",
        "> There are several architectures of Recurrent Neural Networks, each suited for a particular group of tasks. Some examples are many-to-one architecture for task such as sentiment analysis and one-to-many for music generation but we are going to employ the many-to-many architecture which is suited for tasks such as chat-bots and of course Neural Machine Translation.\n",
        "\n",
        "<p align=\"center\"><img src=\"https://blog.paperspace.com/content/images/2019/08/image-3.png\"/>\n",
        "\n",
        "<center>\n",
        "<strong align=\"center\">Different <i>RNN</i> acticectures</strong>\n",
        "</center>\n",
        "</p>\n",
        "\n",
        "> As you can see from the image above, there are two types of many-to-many architectures but we are going to use the first one which consist of two networks: one to take in the input sentence and the other to translate into another language in the case of machine translation. This architecture is suitable for our task because we have inputs and outputs with different lengths. This special class of architecture is called a Sequence to Sequence model. The network where the input is encoded is called the Encoder. The other network is called the decoder since it receives a fixed size vector from the encoder to decode the outputs.t sentence. The minds behind this architecture are Ilya Sutskever, Oriol Vinyals and Quoc V. Le.  Link to paper: https://arxiv.org/pdf/1409.3215.pdf\n",
        "\n",
        "\n",
        "### Attention Mechanism\n",
        "\n",
        "Later that same year when Sutskever and his team proposed their sequence to sequence architecture, several efforts were made to surmount the bottleneck in Sutskever’s model. One major breakthrough that caught the attention of many was the work of Yoshua Bengio and some others in the paper titled Neural Machine Translation by Jointly Learning to Align and Translate. The basic idea behind this architecture is that whenever the decoder is generating a particular output word, it considers information about all the words in the input sentence and determines which words in the inputs sentence are relevant to generate the correct output word. In a sequence model, the common way to pass information about the data at a particular time-step to the next time-step is through the hidden states. This means each hidden state at a particular time-step in our model has some information about the word at that time-step. It does make sense that not every word in the input sentence is required to generate a particular word in the output sentence. For example, when we humans want to translate the french sentence \"Je suis garcon\" to \"I am a boy\", obviously when we are translating the word \"boy\", intuitively we would be paying more attention to the word \"garcon\" than any other word in our input french sentence. That is exactly how attention mechanism in a sequence to sequence model works - our decoder pays attention to a particular word or group of words when generating a particular word. You probably might be wondering how our decoder network pays attention to words. Well it uses connections or weights. The greater the connection or weight to a particular word in the input sentence, the more our decoder is paying attention to that word. We also ought to know that our weights should be a function of the hidden state immediately before the time step we are decoding ( this gives the decoder information about already decoded words) and the encoder outputs but we don’t know what that function is so we let back-propagation take over to learn the appropriate weights. We also ensure that all weights mapping all words in the input sentence to a particular word in the output sentence add up to one. This is asserted using a softmax function. Now that we have some basic idea of attention mechanism, let’s go ahead and implement our model. We’ll start with the encoder. (Does not employ attention mechanism).\n",
        "\n",
        "### Encoder\n",
        "\n",
        "The Encoder is usually very easy to implement. It’s made up of two layers: the Embedding layer which converts each token(word) into a dense representation and a Recurrent Network layer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R27Si37Jsr74"
      },
      "source": [
        "class Encoder(keras.Model):\n",
        "  def __init__(self,vocab_size,\n",
        "               num_hidden=256,\n",
        "               num_embedding=256, \n",
        "               batch_size=16\n",
        "               ):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.num_hidden = num_hidden\n",
        "    self.num_embedding = num_embedding\n",
        "    self.embedding = keras.layers.Embedding(vocab_size, num_embedding)\n",
        "    self.gru = keras.layers.GRU(num_hidden,\n",
        "                                return_sequences=True, # very important\n",
        "                               recurrent_initializer='glorot_uniform',\n",
        "                                return_state=True # very important\n",
        "                             )\n",
        "  def call(self, x, hidden):\n",
        "    embedded = self.embedding(x)\n",
        "    rnn_out, hidden = self.gru(embedded, initial_state=hidden)\n",
        "    return rnn_out, hidden\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return tf.zeros(shape=(self.batch_size, self.num_hidden))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEum5AbRCmsm"
      },
      "source": [
        "inputs, outputs = next(iter(dataset))\n",
        "hidden = tf.zeros((16, 256))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFko_D00Cq3D"
      },
      "source": [
        "encoder = Encoder(input_lang.word_count)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r49gdtGwC02D",
        "outputId": "64afe709-f2da-472b-d2e5-49f9e9ad6d71"
      },
      "source": [
        "e_outputs, e_hidden = encoder(inputs, hidden)\n",
        "e_hidden"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(16, 256), dtype=float32, numpy=\n",
              "array([[-0.00549383,  0.00859579,  0.02028259, ..., -0.00107742,\n",
              "         0.0179934 ,  0.01089506],\n",
              "       [ 0.00920012,  0.01402   ,  0.01171976, ..., -0.0044369 ,\n",
              "         0.01388076, -0.00042458],\n",
              "       [-0.01438294, -0.00073432,  0.00790572, ...,  0.01442005,\n",
              "         0.01272794, -0.00554024],\n",
              "       ...,\n",
              "       [ 0.02305173,  0.02369477,  0.00135033, ..., -0.00722299,\n",
              "         0.01104399, -0.01294329],\n",
              "       [ 0.03167223, -0.0097674 ,  0.0169453 , ...,  0.00436738,\n",
              "        -0.00440438,  0.00045385],\n",
              "       [ 0.00714136,  0.0130656 ,  0.01286327, ..., -0.0051284 ,\n",
              "         0.00948083,  0.00018757]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF0-7JwU9835"
      },
      "source": [
        "In teh GRU implementation: return_sequences and return_state. return_sequences ensures that the GRU outputs the hidden state of each time step. Remember that we need this information to access information about each word in the input sequence. Return state returns the hidden state of the last time step. We need this tensor to be used as initial hidden state for the decoder.\n",
        "\n",
        "### Decoder \n",
        "Unlike the Encoder, the Decoder is a bit complex. It has in addition to the Embedding and Gated Recurrent Network layer an Attention layer and a fully connected layer. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr8d8C7Msr5C"
      },
      "source": [
        "class BahdanauAttention(keras.models.Model):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = keras.layers.Dense(units)\n",
        "    self.W2 = keras.layers.Dense(units)\n",
        "    self.V = keras.layers.Dense(1)\n",
        "      \n",
        "  def call(self, encoder_out, hidden):\n",
        "    #shape of encoder_out : batch_size, seq_length, hidden_dim (16, 10, 1024)\n",
        "    #shape of encoder_hidden : batch_size, hidden_dim (16, 1024)\n",
        "    hidden = tf.expand_dims(hidden, axis=1) #out: (16, 1, 1024)\n",
        "    score = self.V(tf.nn.tanh(self.W1(encoder_out) + \\\n",
        "                              self.W2(hidden))) #out: (16, 10, 1)\n",
        "    attn_weights = tf.nn.softmax(score, axis=1)\n",
        "    context =  attn_weights * encoder_out #out: ((16,10,1) * (16,10,1024))=16, 10, 1024\n",
        "    context = tf.reduce_sum(context, axis=1) #out: 16, 1024\n",
        "    return context, attn_weights\n",
        "    "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA-qj_cyDTVJ"
      },
      "source": [
        "attn = BahdanauAttention(256)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBRgp3aIDTCg"
      },
      "source": [
        "context, attn_weights = attn(e_outputs, e_hidden)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0fPjxp2DS-4",
        "outputId": "e6985804-db8c-4168-9715-1d66989b447c"
      },
      "source": [
        "attn_weights.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([16, 10, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCOaJhs3-1gM"
      },
      "source": [
        "It seems pretty simple to implement but you really need to pay attention to the dimensions as data moves through the pipeline. The call function where forward propagation takes place takes in two parameters; encoder_out which represents all the hidden states at each timestep in the encoder and hidden which represents the hidden state before the current timestep where we are generating the correct word.\n",
        "\n",
        "Since the hidden is the hidden state of a timestep in the decoder, we add a dimension of size 1 to represent the timestep hence shape of hidden becomes (batch_size, time_step, hidden_size). Earlier, we mentioned that the weights for determining attention for a particular word are a function of the hidden_state immediately before that timestep in the decoder and all the hidden_states(encoder_out) of the encoder. That is exactly what we implemented and assigned to score in the code above. We then apply softmax to score across the max_length dimension which is at axis=1. Let’s see a visual explanation.\n",
        "\n",
        "![img](https://blog.paperspace.com/content/images/2019/08/image-11.png)\n",
        "\n",
        "From the diagram above, hi and zj represent all hidden states of encoder and hidden state immediately before the timestep we are in the decoder respectively.The end product of the softmax function gives us the weights which we multiply with all the hidden states from the encoder. A hidden state at a particular timestep with a bigger weight value means more attention is being paid on the word at that timestep. You may have noticed we performed a reduce_sum to produce the context vector. After multiplying each hidden_state with its corresponding weight, we combine all resultant values through a summation. That's it for the attention layer. It returns the context vector and the attention weights.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXg3A6Khsr09"
      },
      "source": [
        "class Decoder(keras.models.Model):\n",
        "  def __init__(self, \n",
        "                vocab_size, \n",
        "                dec_dim=256, \n",
        "                embedding_dim=256\n",
        "                ):\n",
        "      super(Decoder, self).__init__()\n",
        "      self.attn = BahdanauAttention(dec_dim)\n",
        "      self.embedding = keras.layers.Embedding(vocab_size, \n",
        "                                              embedding_dim\n",
        "                                              )\n",
        "      self.gru = keras.layers.GRU(dec_dim, \n",
        "                                  recurrent_initializer='glorot_uniform',\n",
        "                                  return_sequences=True, \n",
        "                                  return_state=True)\n",
        "      self.fc = keras.layers.Dense(vocab_size)\n",
        "        \n",
        "  def call(self, x, hidden, enc_out):\n",
        "    # x.shape = (16, 1)\n",
        "    # enc_out.shape = (16, 10, 256)\n",
        "    # enc_hidden.shape = (16, 256)\n",
        "    x = self.embedding(x)\n",
        "    # x.shape = (16, 1, 256)\n",
        "    context, attn_weights = self.attn(enc_out, hidden)\n",
        "    # context.shape = (16, 256)\n",
        "    x = tf.concat((tf.expand_dims(context, 1), x), -1)\n",
        "    # x.shape = (16, 1, e_c_hidden_size + d_c_embedding_size)\n",
        "    r_out, hidden = self.gru(x, initial_state=hidden)\n",
        "    out = tf.reshape(r_out,shape=(-1, r_out.shape[2]))\n",
        "    # out.shape = (16, 256)\n",
        "    return self.fc(out), hidden, attn_weights"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF1gaFVRDftu"
      },
      "source": [
        "decoder = Decoder(output_lang.word_count)\n",
        "input_tensor, output_tensor = next(iter(dataset))\n",
        "x = np.expand_dims(output_tensor[:,1], -1)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LET8pa3_rsi"
      },
      "source": [
        "In the call function, we pass in three parameters, x representing the tensor of a single word, hidden which represents the hidden state of the previous timestep and enc_out which represents all the hidden states of the encoder,  we pass x through an embedding layer which maps the single integer token into a dense 256 dimensional vector and concatenate it with the context vector generated by the attention layer. The resultant tensor becomes our input for the Gated Recurrent Network for a single timestep. Finally we pass the output of the GRU through a fully connected layer which outputs a vector of size (batch_size, number of english words). We also return hidden state to be fed into the next timestep and the attention weights for later visualizations. Our complete model is now ready to be trained. \n",
        "\n",
        "### Loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVNxDg0JsrzG"
      },
      "source": [
        "def loss_fn(real, pred):\n",
        "  criterion = keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
        "                                                            reduction='none')\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  _loss = criterion(real, pred)\n",
        "  mask = tf.cast(mask, dtype=_loss.dtype)\n",
        "  _loss *= mask\n",
        "  return tf.reduce_mean(_loss)\n",
        "  "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVIC-QLXAULd"
      },
      "source": [
        "We use keras’s sparse categorical cross entropy module since we have a large number of categories(number of english words). We create a mask that asserts that the padding tokens are not included in calculating the loss.Now let’s dive in into our training pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUgv9uNHEKFh"
      },
      "source": [
        "optimizer = tf.optimizers.Adam()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BktVSRlPsrvo"
      },
      "source": [
        "def train_step(input_tensor, target_tensor, enc_hidden):\n",
        "  loss = 0.0\n",
        "  with tf.GradientTape() as tape:\n",
        "    batch_size = input_tensor.shape[0]\n",
        "    enc_output, enc_hidden = encoder(input_tensor, enc_hidden)\n",
        "\n",
        "    SOS_tensor = np.array([SOS])\n",
        "    dec_input = tf.squeeze(tf.expand_dims([SOS_tensor]*batch_size, 1), -1)\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    for tx in range(target_tensor.shape[1]-1):\n",
        "      dec_out, dec_hidden, _ = decoder(dec_input, dec_hidden,\n",
        "                                      enc_output)\n",
        "      loss += loss_fn(target_tensor[:, tx], dec_out)\n",
        "      dec_input = tf.expand_dims(target_tensor[:, tx], 1)\n",
        "\n",
        "  batch_loss = loss / target_tensor.shape[1]\n",
        "  t_variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, t_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, t_variables))\n",
        "  return batch_loss"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBREoIn7DyFg",
        "outputId": "7bcad0b7-3ddf-496c-bf40-a575cd06b17e"
      },
      "source": [
        "hidden = tf.zeros(shape=(16, 256))\n",
        "loss = train_step(input_tensor, output_tensor, hidden)\n",
        "print(loss)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(1.4865503, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMuG6WZWBiG6"
      },
      "source": [
        "The above snippet implements a single training step. In our single training step, we pass the input_tensor which represent the input sentence through the forward propagation pipeline of the Encoder. This return the enc_output(hidden_state of all timesteps) and enc_hidden(last hidden_state). Notice that the last hidden_state of the encoder is used as the initial hidden_state of the decoder. In the decoding part, we use a technique called teacher forcing where instead of using the predicted word as input for the next timestep, we use the actual word. At the start of decoding, we feed the Start Of Sentence token as input and maximize the probability of the decoder predicting the first word in the output sequence as it output. We then take the actual first word and feed it into the second timestep and maximize the probability of the decoder predicting the second word in the output sequence as it output. This continues sequentially until we reach the End of Sentence token<EOS>. We accumulate all the losses, derive the gradients and train both networks end-to-end with the gradients. That’s all it takes to complete a single training step. Let’s implement a helper function to save our model at certain points during our training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uS8FfedEoRZ"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_uFxtRkEoOl"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A5pWRa4sruI"
      },
      "source": [
        "def checkpoint(model, name=None):\n",
        "  if name is not None:\n",
        "    model.save_weights('/content/drive/My Drive/{}.h5'.format(name))\n",
        "  else:\n",
        "    raise NotImplementedError"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJWRlZb7BwNS"
      },
      "source": [
        "The final part of our training pipeline is a training loop. It’s pretty simple to understand. All we do is to run through some epochs and at each epoch, we iterate through our dataset and call the train_step function on each batch of the dataset. There are some if-else statements just to log our training statistics on screen. Let’s see how.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rls90jMqsrqu"
      },
      "source": [
        "EPOCHS = 10\n",
        "log_every = 50\n",
        "steps_per_epoch = len(pairs) # BATCH_SIZE\n",
        "for e in range(1, EPOCHS):\n",
        "  total_loss = 0.0\n",
        "  enc_hidden = encoder.init_hidden()\n",
        "  for idx, (input_tensor, target_tensor) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(input_tensor, target_tensor, hidden)\n",
        "    total_loss += batch_loss\n",
        "    if idx % log_every == 0:\n",
        "        print(\"Epochs: {} batch_loss: {:.4f}\".format(e, batch_loss))\n",
        "        checkpoint(encoder, 'encoder')\n",
        "        checkpoint(decoder, 'decoder')   \n",
        "  if e % 2 == 0:\n",
        "      print(\"Epochs: {}/{} total_loss: {:.4f}\".format(\n",
        "      e, EPOCHS, total_loss / steps_per_epoch))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ4viVsasron"
      },
      "source": [
        "encoder.load_weights('/content/drive/My Drive/encoder.h5')\n",
        "decoder.load_weights('/content/drive/My Drive/decoder.h5')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i61qpCp9FzdJ"
      },
      "source": [
        "### Model Inference.\n",
        "\n",
        "In order to perform the translation, we need to write a function much like what we did in the train_step function but instead of feeding in the actual word at a particular time step into the next time step, we feed in the word predicted by our network. This algorithm is known as **Greedy search**.\n",
        "\n",
        "![img](https://paper-attachments.dropbox.com/s_3ADD797BBE9B7540EC42A58CE89CCEBD7EBACC0602B60C6909B8EC8B7088ACFD_1564871734930_seq2seq_vanilla_decoder.svg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PyC2OHosDXm"
      },
      "source": [
        "def translate(sentence, max_length=10):\n",
        "    result = ''\n",
        "    attention_plot = np.zeros((10,10))\n",
        "    sentence = normalizeString(sentence)\n",
        "    sentence = sentencetoIndexes(sentence, input_lang)\n",
        "    sentence = pad_sequences([sentence],padding='post',\n",
        "                                maxlen=max_length,\n",
        "                               truncating='post')\n",
        "    encoder_hidden = hidden = [tf.zeros((1, 256))]\n",
        "    \n",
        "    enc_out, enc_hidden = encoder(sentence, encoder_hidden)\n",
        "    \n",
        "    dec_hidden = enc_hidden\n",
        "    SOS_tensor = np.array([SOS])\n",
        "    dec_input = tf.squeeze(tf.expand_dims([SOS_tensor], 1), -1)\n",
        "    \n",
        "    for tx in range(max_length):\n",
        "      dec_out, dec_hidden, attn_weights = decoder(dec_input,\n",
        "                                                  dec_hidden, enc_out)\n",
        "      attn_weights = tf.reshape(attn_weights, (-1, ))\n",
        "      attention_plot[tx] = attn_weights.numpy()\n",
        "      pred = tf.argmax(dec_out, axis=1).numpy()\n",
        "      result += output_lang.itos[pred[0]] + \" \"\n",
        "      if output_lang.itos[pred[0]] == \"<eos>\":\n",
        "          break\n",
        "      dec_input = tf.expand_dims(pred, axis=1)\n",
        "    return result, attention_plot"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7elFuRfHTBS"
      },
      "source": [
        "Our translate function takes in two parameters, the sentence and maximum length for the input sentence . The sentence passes through a preprocessing stage where it is normalized, converted to integer values and padded. The preprocessed tensor is passed through the encoder to generate the encoder_output and encoder_hidden which are conveyed to the decoder. Notice that at the decoding stage, the decoder first receives the Start of Sentence<SOS> token as the first input word or token.  After propagating the Start of Sentence token forward through the first time step along with the encoder last hidden state and all the hidden states of the encoder for attention mechanism, a probability distribution is outputted with the word intended to be predicted having the highest value in the distribution. Taking the argmax of this distribution just returns the integer position of the intended word (maximum value in the distribution) in the distribution. This integer position is actually the integer correspondent of the word in the int2word mapping in our Language class. We retrieve the string word using the int2word dictionary, append it to a string and feed back the integer correspondent into the next time step and repeat the process until we encounter the End of Sentence token. We also populate our attention_plot data container with the attention weights produced at each timestep. The final string returned should have the translation for the input sentence we entered. Let’s see a demo!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4O_Jq5mNHMdl",
        "outputId": "57f52e72-cd75-49fb-96fd-baab3e0e6530"
      },
      "source": [
        "sentence = \"j'ai besoin de quelqu'un pour m'aider ?\"\n",
        "pred, attn_weights = translate(sentence)\n",
        "print(pred)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i m a lot to a lot to a lot \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xiojCUvHZ-_"
      },
      "source": [
        "### Attention mechanism.\n",
        "We are going to visualize how much attention the network is paying to each word in the input sentence when generating a word in the output sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWw34GqJIgjd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deLFnVKVHi-O"
      },
      "source": [
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  plt.show()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "id": "Sfi1izGqMWJG",
        "outputId": "5079f271-281c-4c76-9f83-66168b9dc0f5"
      },
      "source": [
        "attn_weights = attn_weights[:len(pred.split(' ')), :len(sentence.split(' '))]\n",
        "plot_attention(attn_weights, sentence.split(), pred.split())"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmpSeAz6HyNe"
      },
      "source": [
        "### Conclusion.\n",
        "We have learnt how to create an Encoder, Decoder Model with Attention for Neural Machine Translation task.\n",
        "\n",
        "**Note in this notebook we did not focus much on the translations because we did not give the model enough time to train.In the next notebook we are going to give the model time to train.**\n",
        "\n",
        "### Refs\n",
        "* [Paperspace blog post](https://blog.paperspace.com/neural-machine-translation-with-tensorflow/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTpdV1b7HxMO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}