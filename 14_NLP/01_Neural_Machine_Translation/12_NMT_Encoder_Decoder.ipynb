{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "12_NMT_Encoder_Decoder.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNqu7pFKchNr"
      },
      "source": [
        "### 12. Encoder Decoder Model - ``NMT``\n",
        "\n",
        "We are going to create a simple NMT model that will translate from spaniszh to english using the encoder decoder achitecture.\n",
        "\n",
        "In this notebook we are going to look at the basics of NMT in tensorflow 2. We will then have a look on a step futher in by adding the `Attention` mechanism so that we get better results. The basic Encoder Decoder model looks as follows:\n",
        "\n",
        "![img](https://github.com/edumunozsala/NMT-encoder-decoder-Attention/raw/ca7d7f969a17ddf390f707fceb22d5881d33b1c3/images/encoder_decoder_basic.png)\n",
        "\n",
        "The seq2seq model consists of two sub-networks, the encoder and the decoder. The encoder, on the left hand, receives sequences from the source language as inputs and produces as a result a compact representation of the input sequence, trying to summarize or condense all its information. Then that output becomes an input or initial state of the decoder, which can also receive another external input. At each time step, the decoder generates an element of its output sequence based on the input received and its current state, as well as updating its own state for the next time step. \n",
        "\n",
        "Mention that the input and output sequences are of fixed size but they do not have to match, the length of the input sequence may differ from that of the output sequence.\n",
        "\n",
        "The critical point of this model is how to get the encoder to provide the most complete and meaningful representation of its input sequence in a single output element to the decoder. Because this vector or state is the only information the decoder will receive from the input to generate the corresponding output. The longer the input, the harder to compress in a single vector.\n",
        "\n",
        "\n",
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "I00tsWmRbxmL",
        "outputId": "8de8fef3-4471-4948-cb4d-d454327c8924"
      },
      "source": [
        "import numpy as np\n",
        "import typing\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "\n",
        "import re, os, time, unicodedata\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.6.0'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qv-N1-Mg_1O"
      },
      "source": [
        "### Mounting the drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Vbu4Gv8b4cY",
        "outputId": "02af45db-fc23-4428-b625-2dac28ecc95b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKh1Onbdb4Zr",
        "outputId": "bfa29917-858d-4b5c-a140-cbd487a90db3"
      },
      "source": [
        "file_path = \"/content/drive/My Drive/NLP Data/seq2seq/spa-en/spa.txt\"\n",
        "os.path.exists(file_path)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvtnHUHxiYkG"
      },
      "source": [
        "We will use spainish as our source language and english as our target language in this example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSj--AajiXw6"
      },
      "source": [
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvIrHBQ8iXn4"
      },
      "source": [
        "def preprocess_sentence(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "    w = w.strip()\n",
        "    # Adding the start and end of sequences tokens \n",
        "    # w = '<sos> ' + w + ' <eos>'\n",
        "    return w"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-WtkAejhssT"
      },
      "source": [
        "### Data and text processing.\n",
        "\n",
        "We need to remove accents, lower case the sentences and replace everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQeZnEDfNE01"
      },
      "source": [
        "INPUT_COLUMN = 'input'\n",
        "TARGET_COLUMN = 'target'\n",
        "\n",
        "TARGET_FOR_INPUT = 'target_for_input'\n",
        "NUM_SAMPLES = 20000 #40000\n",
        "MAX_VOCAB_SIZE = 20000\n",
        "EMBEDDING_DIM = 128\n",
        "HIDDEN_DIM= 1024\n",
        "\n",
        "BATCH_SIZE = 64  # Batch size for training.\n",
        "EPOCHS = 10  # Number of epochs to train for.\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06fs8uIfMf0M",
        "outputId": "48112433-a071-4e4d-bcb6-71cea23f07e7"
      },
      "source": [
        "# Load the dataset: sentence in english, sentence in spanish \n",
        "df=pd.read_csv(file_path, sep=\"\\t\", header=None, names=[TARGET_COLUMN, INPUT_COLUMN], usecols=[0,1], \n",
        "               nrows=NUM_SAMPLES)\n",
        "\n",
        "# Preprocess the input data\n",
        "input_data=df[INPUT_COLUMN].apply(lambda x : preprocess_sentence(x)).tolist()\n",
        "# Preprocess and include the end of sentence token to the target text\n",
        "target_data=df[TARGET_COLUMN].apply(lambda x : preprocess_sentence(x)+ ' <eos>').tolist()\n",
        "# Preprocess and include a start of setence token to the input text to the decoder, it is rigth shifted\n",
        "target_input_data=df[TARGET_COLUMN].apply(lambda x : '<sos> '+ preprocess_sentence(x)).tolist()\n",
        "\n",
        "print(input_data[:5])\n",
        "print(target_data[:5])\n",
        "print(target_input_data[:5])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ve .', 'vete .', 'vaya .', 'vayase .', 'hola .']\n",
            "['go . <eos>', 'go . <eos>', 'go . <eos>', 'go . <eos>', 'hi . <eos>']\n",
            "['<sos> go .', '<sos> go .', '<sos> go .', '<sos> go .', '<sos> hi .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3wBerjHlezP"
      },
      "source": [
        "### Tokenization\n",
        "\n",
        "* Tokenize the data, to convert the raw text into a sequence of integers. First, we create a Tokenizer object from the keras library and fit it to our text (one tokenizer for the input and another one for the output).\n",
        "* Extract sequence of integers from the text: we call the ``text_to_sequence`` method of the tokenizer for every input and output text.\n",
        "* Calculate the maximum length of the input and output sequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtVRfcb0b4RY",
        "outputId": "f6845cb2-1ee4-4593-8f2b-c43bb535d14f"
      },
      "source": [
        "tokenizer_inputs = Tokenizer(\n",
        "    num_words = MAX_VOCAB_SIZE, filters=\"\"\n",
        ")\n",
        "tokenizer_inputs.fit_on_texts(input_data)\n",
        "input_sequences = tokenizer_inputs.texts_to_sequences(input_data)\n",
        "\n",
        "input_max_len = max(len(s) for s in input_sequences)\n",
        "print('max input length: ', input_max_len)\n",
        "\n",
        "# Show some example of tokenize sentences, useful to check the tokenization\n",
        "print(input_data[1000])\n",
        "print(input_sequences[1000])\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max input length:  17\n",
            "tomas lo intento .\n",
            "[60, 15, 765, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pExrjo17neVm"
      },
      "source": [
        "We can do the same thing to the output sequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leFgqUS7b4N1",
        "outputId": "47cc2ed7-d9df-4b80-f6ed-811e6147bc87"
      },
      "source": [
        "\n",
        "# Create a tokenizer for the output texts and fit it to them \n",
        "tokenizer_outputs = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='')\n",
        "tokenizer_outputs.fit_on_texts(target_data)\n",
        "tokenizer_outputs.fit_on_texts(target_input_data)\n",
        "\n",
        "# Tokenize and transform output texts to sequence of integers\n",
        "target_sequences = tokenizer_outputs.texts_to_sequences(target_data)\n",
        "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_input_data)\n",
        "\n",
        "# determine maximum length output sequence\n",
        "target_max_len = max(len(s) for s in target_sequences)\n",
        "print('max target length: ', target_max_len)\n",
        "\n",
        "print(target_data[1000])\n",
        "print(target_sequences[1000])\n",
        "print(target_input_data[1000])\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max target length:  9\n",
            "tom tried . <eos>\n",
            "[7, 414, 1, 2]\n",
            "<sos> tom tried .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQj3S3HNoH-_"
      },
      "source": [
        "### Creating vocabularies\n",
        "\n",
        "Using the tokenizer we have created previously we can retrieve the vocabularies, one to match word to integer (word2idx) and a second one to match the integer to the corresponding word (idx2word).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjqBg7-vb4K8",
        "outputId": "58e37863-8744-4e42-8e70-4aa04c9bd2ae"
      },
      "source": [
        "# get the word to index mapping for input language\n",
        "word2idx_inputs = tokenizer_inputs.word_index\n",
        "print('Found %s unique input tokens.' % len(word2idx_inputs))\n",
        "\n",
        "# get the word to index mapping for output language\n",
        "word2idx_outputs = tokenizer_outputs.word_index\n",
        "print('Found %s unique output tokens.' % len(word2idx_outputs))\n",
        "\n",
        "# store number of output and input words for later\n",
        "# remember to add 1 since indexing starts at 1\n",
        "num_words_output = len(word2idx_outputs) + 1\n",
        "num_words_inputs = len(word2idx_inputs) + 1\n",
        "\n",
        "# map indexes back into real words\n",
        "# so we can view the results\n",
        "idx2word_inputs = {v:k for k, v in word2idx_inputs.items()}\n",
        "idx2word_outputs = {v:k for k, v in word2idx_outputs.items()}"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7183 unique input tokens.\n",
            "Found 3669 unique output tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvJFF6hjovy5"
      },
      "source": [
        "### Padding Sequences\n",
        "Padding the sentences: we need to pad zeros at the end of the sequences so that all sequences have the same length. Otherwise, we won't be able train the model on batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQrBk3Z_b4Hp",
        "outputId": "34682c7b-f60d-4143-9ac8-2dfc55b3dd8e"
      },
      "source": [
        "# pad the input sequences\n",
        "encoder_inputs = pad_sequences(input_sequences,\n",
        "                               maxlen=input_max_len, padding='post')\n",
        "print(\"encoder_inputs.shape:\", encoder_inputs.shape)\n",
        "\n",
        "\n",
        "# pad the decoder input sequences\n",
        "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=target_max_len, padding='post')\n",
        "print(\"decoder_inputs[0]:\", decoder_inputs[0])\n",
        "print(\"decoder_inputs.shape:\", decoder_inputs.shape)\n",
        "\n",
        "# pad the target output sequences\n",
        "decoder_targets = pad_sequences(target_sequences, maxlen=target_max_len, padding='post')\n",
        "print(\"decoder_targets.shape:\", decoder_targets.shape)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder_inputs.shape: (20000, 17)\n",
            "decoder_inputs[0]: [ 3 31  1  0  0  0  0  0  0]\n",
            "decoder_inputs.shape: (20000, 9)\n",
            "decoder_targets.shape: (20000, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4A3y_CaXrsre"
      },
      "source": [
        "### Creating a Batch Data Generator\n",
        "\n",
        "* Create a batch data generator: we want to train the model on batches, group of sentences, so we need to create a Dataset using the tf.data library and the function ``batch_on_slices`` on the input and output sequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fyoKhylb4FE"
      },
      "source": [
        "BUFFER_SIZE = len(input_data)\n",
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (encoder_inputs, decoder_inputs, decoder_targets)\n",
        ").shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxLluMo0sSjf"
      },
      "source": [
        "### Encoder Decoder Model.\n",
        "For a better understanding, we can divide the model in three basic components:\n",
        "\n",
        "![img](https://github.com/edumunozsala/NMT-encoder-decoder-Attention/raw/ca7d7f969a17ddf390f707fceb22d5881d33b1c3/images/encoder_decoder_RNN.jpeg)\n",
        "\n",
        "*  **The encoder:** Layers of recurrent units where in each time step, receive a an input token, collects relevant information and produce a hidden state. Depends on the type of RNN, in our example a LSTM, the unit \"mixes\" the current hidden state and the input and return an output, discarded, and a new hidden state. \n",
        "\n",
        "* **The encoder vector:** it is the last hidden state of the encoder and it tries to contain as much of the useful input information as possible to help the decoder get the best results. It is only information from the input that the decoder will get.\n",
        "\n",
        "* **The decoder:** Layers of recurrent units, i.e. LSTMs, where each unit produces an output at a time step t. The hidden state of the first unit is the encoder vector and the rest of units accept the hidden state from the previous unit. The output is calculated using a **``_softmax_``** function to obtain a probability for every token in the output vocabulary.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Encoder Class\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-J_Ho3lb4Cl"
      },
      "source": [
        "class Encoder(keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    self.embedding = keras.layers.Embedding(\n",
        "        vocab_size, embedding_dim\n",
        "    )\n",
        "    self.lstm = keras.layers.LSTM(hidden_dim,\n",
        "                                  return_sequences=True,\n",
        "                                  return_state=True\n",
        "                                  )\n",
        "    \n",
        "  def call(self, input_sequence, states):\n",
        "    embedded  = self.embedding(input_sequence)\n",
        "    output, h_0, c_0 = self.lstm(embedded, initial_state= states)\n",
        "    return output, h_0, c_0 \n",
        "\n",
        "  def init_states(self, batch_size):\n",
        "    return(\n",
        "        tf.zeros([batch_size, self.hidden_dim]),\n",
        "        tf.zeros([batch_size, self.hidden_dim]),\n",
        "    )\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCt4dFwSulYv"
      },
      "source": [
        "### Decoder Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdoT9kcxb3_H"
      },
      "source": [
        "class Decoder(keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.embedding = keras.layers.Embedding(\n",
        "        vocab_size, embedding_dim\n",
        "    )\n",
        "    self.lstm = keras.layers.LSTM(\n",
        "         hidden_dim, return_sequences=True, return_state=True\n",
        "    )\n",
        "    self.out = keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, input_sequence, state):\n",
        "    embedded = self.embedding(input_sequence)\n",
        "    output, h_0, c_0 = self.lstm(embedded, initial_state=state)\n",
        "    logits = self.out(output)\n",
        "    return logits, h_0, c_0"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_SjwivHvtt-"
      },
      "source": [
        "Once our encoder and decoder are defined we can init them and set the initial hidden state. We have included a simple test, calling the encoder and decoder to check they works fine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrv3WeKkb38d",
        "outputId": "9d5b356e-d9fc-4b7b-898e-c08bb0094052"
      },
      "source": [
        "#Set the length of the input and output vocabulary\n",
        "num_words_inputs = len(word2idx_inputs) + 1\n",
        "num_words_output = len(word2idx_outputs) + 1\n",
        "\n",
        "#Create the encoder\n",
        "encoder = Encoder(num_words_inputs, EMBEDDING_DIM, HIDDEN_DIM)\n",
        "# Get the initial states\n",
        "initial_state = encoder.init_states(1)\n",
        "# Call the encoder for testing\n",
        "test_encoder_output = encoder(tf.constant(\n",
        "    [[1, 23, 4, 5, 0, 0]]), initial_state)\n",
        "print(test_encoder_output[0].shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create the decoder\n",
        "decoder = Decoder(num_words_output, EMBEDDING_DIM, HIDDEN_DIM)\n",
        "# Get the initial states\n",
        "de_initial_state = test_encoder_output[1:]\n",
        "# Call the decoder for testing\n",
        "test_decoder_output = decoder(tf.constant(\n",
        "    [[1, 3, 5, 7, 9, 0, 0, 0]]), de_initial_state)\n",
        "print(test_decoder_output[0].shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 6, 1024)\n",
            "(1, 8, 3670)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifUkP0AswI-H"
      },
      "source": [
        "### Loss function and metrics\n",
        "\n",
        "Now we need to define a custom loss function to avoid taking into account the 0 values, padding values, when calculating the loss. And also we have to define a custom accuracy function.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB3JtQs9b35T"
      },
      "source": [
        "def loss_func(targets, logits):\n",
        "  crossentropy = keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True)\n",
        "  # Mask padding values, they do not have to compute for loss\n",
        "  mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
        "  mask = tf.cast(mask, dtype=tf.int64) \n",
        "  loss = crossentropy(targets, logits, sample_weight=mask)\n",
        "  return loss\n",
        "     "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tN2HT0xZb32W"
      },
      "source": [
        "def accuracy_fn(y_true, y_pred):\n",
        "  # y_pred shape is batch_size, seq length, vocab size\n",
        "  # y_true shape is batch_size, seq length\n",
        "  pred_values = keras.backend.cast(keras.backend.argmax(y_pred, axis=-1), dtype='int32')\n",
        "  correct = keras.backend.cast(keras.backend.equal(y_true, pred_values), dtype='float32')\n",
        "\n",
        "  # 0 is padding, don't include those\n",
        "  mask = keras.backend.cast(keras.backend.greater(y_true, 0),\n",
        "                            dtype='float32')\n",
        "  n_correct = keras.backend.sum(mask * correct)\n",
        "  n_total = keras.backend.sum(mask)\n",
        "  return n_correct / n_total\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSxaF6g9xMNH"
      },
      "source": [
        "### Training\n",
        "\n",
        "As we mentioned before, we are interested in training the network in batches, therefore, we create a function that carries out the training of a batch of the data:\n",
        "\n",
        "* Call the encoder for the batch input sequence, the output is the encoded vector.\n",
        "* Set the decoder initial states to the encoded vector\n",
        "* Call the decoder, taking the right shifted target sequence as input. The output are the logits (the softmax function is applied in the loss function)\n",
        "* Calculate the loss and accuracy of the batch data\n",
        "* Update the learnable parameters of the encoder and the decoder\n",
        "update the optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uABOj_7b3zS"
      },
      "source": [
        "@tf.function\n",
        "def train_step(\n",
        "     input_seq, target_seq_in, target_seq_out,\n",
        "     en_initial_states, optimizer\n",
        "  ):\n",
        "  with tf.GradientTape() as tape:\n",
        "    # Get the encoder outputs\n",
        "    en_outputs = encoder(input_seq, en_initial_states)\n",
        "    # Set the encoder and decoder states\n",
        "    en_states = de_states = en_outputs[1:]\n",
        "\n",
        "    # Get the decoder outputs\n",
        "    de_outputs = decoder(target_seq_in, de_states)\n",
        "    # Take the actual output\n",
        "    logits = de_outputs[0]\n",
        "    # Calculate the loss function\n",
        "    loss = loss_func(target_seq_out, logits)\n",
        "    acc = accuracy_fn(target_seq_out, logits)\n",
        "  \n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "  return loss, acc"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3KOGX3oyrbi"
      },
      "source": [
        "Our train function receives three sequences:\n",
        "\n",
        "**Input sequence:** array of integers of shape [batch_size, max_seq_len, embedding dim]. It is the input sequence to the encoder.\n",
        "\n",
        "**target sequence:** array of integers of shape [batch_size, max_seq_len, embedding dim]. It is the target of our model, the output that we want for our model.\n",
        "\n",
        "**Target input sequence:** array of integers of shape [batch_size, max_seq_len, embedding dim]. It is the input sequence to the decoder because we use Teacher Forcing.\n",
        "\n",
        "\n",
        "### Oh Teacher Forcing\n",
        "Teacher forcing is a training method critical to the development of deep learning models in NLP. It is a way for quickly and efficiently training recurrent neural network models that use the ground truth from a prior time step as input.\n",
        "\n",
        "In a recurrent network usually the input to a RNN at the time step t is the output of the RNN in the previous time step, t-1. But with teacher forcing we can use the actual output to improve the learning capabilities of the model.\n",
        "\n",
        "_\"Teacher forcing works by using the actual or expected output from the training dataset at the current time step y(t) as input in the next time step X(t+1), rather than the output generated by the network. So, in our example, the input to the decoder is the target sequence right-shifted, the target output at time step t is the decoder input at time step t+1.\"_\n",
        "\n",
        "When our model output do not vary from what was seen by the model during training, teacher forcing is very effective. But if we need a more \"creative\" model, where given an input sequence there can be several possible outputs, we should avoid this technique or apply it randomly (only in some random time steps).\n",
        "\n",
        "Now, we can code the whole training process:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmrvv4ehb3wQ"
      },
      "source": [
        "def fit(encoder, decoder, dataset, n_epochs, batch_size,\n",
        "        optimizer, checkpoint, checkpoint_prefix\n",
        "        ):\n",
        "  losses =[]\n",
        "  accuracies = []\n",
        "  for e in range(n_epochs):\n",
        "    start = time.time()\n",
        "    en_initial_states = encoder.init_states(batch_size)\n",
        "    for batch, (input_seq, target_seq_in, target_seq_out) in enumerate(dataset.take(-1)):\n",
        "      loss, accuracy = train_step(input_seq, target_seq_in,\n",
        "                                  target_seq_out, \n",
        "                                  en_initial_states, optimizer)\n",
        "      if batch % 100 == 0:\n",
        "        losses.append(loss)\n",
        "        accuracies.append(accuracy)\n",
        "        print('Epoch {} Batch {} Loss {:.4f} Acc:{:.4f}'.format(e + 1, batch, loss.numpy(), accuracy.numpy()))\n",
        "      \n",
        "    if (e + 1) % 2 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "    print('Time taken for 1 epoch {:.4f} sec\\n'.format(time.time() - start))\n",
        "  return losses, accuracies\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uawlTlLI0mrP"
      },
      "source": [
        "We are almost ready, our last step include a call to the main train function and we create a checkpoint object to save our model. Because the training process require a long time to run, every two epochs we save it. Later we can restore it and use it to make predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skD0n1Edb3tC",
        "outputId": "6e35a16b-01ed-4a8e-ed44-88fd8edd1aaf"
      },
      "source": [
        "# Create an Adam optimizer and clips gradients by norm\n",
        "optimizer = tf.keras.optimizers.Adam(clipnorm=5.0)\n",
        "# Create a checkpoint object to save the model\n",
        "checkpoint_dir = './training_ckpt_seq2seq'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)\n",
        "\n",
        "losses, accuracies = fit(encoder, decoder,\n",
        "                         dataset, EPOCHS,\n",
        "                         BATCH_SIZE, optimizer,\n",
        "                         checkpoint, checkpoint_prefix)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 5.0020 Acc:0.0028\n",
            "Epoch 1 Batch 100 Loss 2.2268 Acc:0.4426\n",
            "Epoch 1 Batch 200 Loss 2.1717 Acc:0.4169\n",
            "Epoch 1 Batch 300 Loss 1.9904 Acc:0.4750\n",
            "Time taken for 1 epoch 27.0743 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.9182 Acc:0.4870\n",
            "Epoch 2 Batch 100 Loss 1.7908 Acc:0.4915\n",
            "Epoch 2 Batch 200 Loss 1.6309 Acc:0.5101\n",
            "Epoch 2 Batch 300 Loss 1.6136 Acc:0.5000\n",
            "Time taken for 1 epoch 19.8295 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.5434 Acc:0.4986\n",
            "Epoch 3 Batch 100 Loss 1.5970 Acc:0.5153\n",
            "Epoch 3 Batch 200 Loss 1.5433 Acc:0.5225\n",
            "Epoch 3 Batch 300 Loss 1.4621 Acc:0.5568\n",
            "Time taken for 1 epoch 19.3780 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.3678 Acc:0.5739\n",
            "Epoch 4 Batch 100 Loss 1.3188 Acc:0.5734\n",
            "Epoch 4 Batch 200 Loss 1.3486 Acc:0.5534\n",
            "Epoch 4 Batch 300 Loss 1.3807 Acc:0.5706\n",
            "Time taken for 1 epoch 19.7670 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 1.2021 Acc:0.6124\n",
            "Epoch 5 Batch 100 Loss 1.2623 Acc:0.5881\n",
            "Epoch 5 Batch 200 Loss 1.1275 Acc:0.6246\n",
            "Epoch 5 Batch 300 Loss 1.1339 Acc:0.6023\n",
            "Time taken for 1 epoch 19.4327 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 1.0212 Acc:0.6610\n",
            "Epoch 6 Batch 100 Loss 1.0912 Acc:0.6006\n",
            "Epoch 6 Batch 200 Loss 1.1712 Acc:0.5782\n",
            "Epoch 6 Batch 300 Loss 1.1041 Acc:0.6246\n",
            "Time taken for 1 epoch 19.7434 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 1.0376 Acc:0.6230\n",
            "Epoch 7 Batch 100 Loss 1.0152 Acc:0.6490\n",
            "Epoch 7 Batch 200 Loss 1.0546 Acc:0.6326\n",
            "Epoch 7 Batch 300 Loss 1.0381 Acc:0.6177\n",
            "Time taken for 1 epoch 19.3963 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.9287 Acc:0.6685\n",
            "Epoch 8 Batch 100 Loss 0.9316 Acc:0.6734\n",
            "Epoch 8 Batch 200 Loss 0.9418 Acc:0.6630\n",
            "Epoch 8 Batch 300 Loss 0.9487 Acc:0.6584\n",
            "Time taken for 1 epoch 19.7010 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.8464 Acc:0.6816\n",
            "Epoch 9 Batch 100 Loss 0.8852 Acc:0.6818\n",
            "Epoch 9 Batch 200 Loss 0.8345 Acc:0.6816\n",
            "Epoch 9 Batch 300 Loss 0.8744 Acc:0.6620\n",
            "Time taken for 1 epoch 19.3873 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.7738 Acc:0.7225\n",
            "Epoch 10 Batch 100 Loss 0.7132 Acc:0.7437\n",
            "Epoch 10 Batch 200 Loss 0.8567 Acc:0.6546\n",
            "Epoch 10 Batch 300 Loss 0.8130 Acc:0.7151\n",
            "Time taken for 1 epoch 19.7031 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HR9d8ea08vv"
      },
      "source": [
        "### Model Evaulation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "gCh6uXGhb3oH",
        "outputId": "5676e751-416e-4a8e-ecc7-8b8930841071"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
        "\n",
        "ax1.plot(losses, label='loss')\n",
        "#plt.plot(results.history['val_loss'], label='val_loss')\n",
        "ax1.set_title('Training Loss')\n",
        "ax1.legend()\n",
        "# accuracies\n",
        "ax2.plot(accuracies, label='acc')\n",
        "#plt.plot(results.history['val_accuracy_fn'], label='val_acc')\n",
        "ax2.set_title('Training Accuracy')\n",
        "ax2.legend()\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iojOKHp1I4c"
      },
      "source": [
        "### Inference\n",
        "To restore the lastest checkpoint, saved model, you can run the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDwXcqIwb3k5",
        "outputId": "d0d2eb89-c917-4e8d-b0c6-20e98b477eef"
      },
      "source": [
        "\n",
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint_dir = './training_ckpt_seq2seq'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f543c06e310>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "To67sEZr1RdX"
      },
      "source": [
        "In the prediction step, our input is a sequence of length one, the ``sos`` token, then we call the encoder and ``decoder`` repeatedly until we get the eos token or reach the maximum length defined."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYg6__z0b3iG"
      },
      "source": [
        "def predict(\n",
        "    input_text, encoder, \n",
        "    input_max_len, tokenizer_inputs, \n",
        "    word2idx_outputs, idx2word_outputs\n",
        "  ):\n",
        "  if input_text is None:\n",
        "    input_text = input_data[np.random.choice(len(input_data))]\n",
        "    # Tokenize the input text  \n",
        "  input_seq = tokenizer_inputs.texts_to_sequences([input_text])\n",
        "  # Pad the input sentence\n",
        "  input_seq = pad_sequences(input_seq, maxlen=input_max_len,\n",
        "                            padding='post')         \n",
        "  en_initial_states = encoder.init_states(1)      \n",
        "  en_outputs = encoder(tf.constant(input_seq), en_initial_states)\n",
        "  de_input = tf.constant([[word2idx_outputs['<sos>']]]) \n",
        "  de_state_h, de_state_c = en_outputs[1:]\n",
        "  out_words = []\n",
        "  while True:\n",
        "    de_output, de_state_h, de_state_c = decoder(\n",
        "          de_input, (de_state_h, de_state_c))    \n",
        "    de_input = tf.argmax(de_output, -1)\n",
        "    out_words.append(idx2word_outputs[de_input.numpy()[0][0]])\n",
        "\n",
        "    if out_words[-1] == '<eos>' or len(out_words) >= 80:\n",
        "        break     \n",
        "  return ' '.join(out_words)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyuUvqSfb3fG",
        "outputId": "7d25f7a9-f339-4d6d-da86-606f8c1c39f3"
      },
      "source": [
        "\n",
        "for inp, trg in zip(input_data[1200: 1210], target_data[1200: 1210]):\n",
        "  predicted = predict(inp, encoder, input_max_len, tokenizer_inputs,\n",
        "                      word2idx_outputs, idx2word_outputs)\n",
        "  print(\"> input: \", inp)\n",
        "  print(\"< predicted:\", predicted)\n",
        "  print(\"< real trg:\", trg)\n",
        "  print()\n",
        "  print('*' * 100)\n",
        "  print() "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> input:  el salio a comer .\n",
            "< predicted: he went to bed . <eos>\n",
            "< real trg: he ate out . <eos>\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "> input:  el se rindio .\n",
            "< predicted: he seems hungry . <eos>\n",
            "< real trg: he gave in . <eos>\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "> input:  se rindio .\n",
            "< predicted: i ll be glad to . <eos>\n",
            "< real trg: he gave up . <eos>\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "> input:  lo dejo .\n",
            "< predicted: i ll reward you . <eos>\n",
            "< real trg: he gave up . <eos>\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "> input:  cedio .\n",
            "< predicted: it gets better . <eos>\n",
            "< real trg: he gave up . <eos>\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "> input:  tiro la toalla .\n",
            "< predicted: he seems hungry . <eos>\n",
            "< real trg: he gave up . <eos>\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "> input:  descolgo .\n",
            "< predicted: it gets better . <eos>\n",
            "< real trg: he hung up . <eos>\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "> input:  el corto .\n",
            "< predicted: he was getting old . <eos>\n",
            "< real trg: he hung up . <eos>\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "> input:  el es dj .\n",
            "< predicted: he s a bit naive . <eos>\n",
            "< real trg: he is a dj . <eos>\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "> input:  el esta aqui !\n",
            "< predicted: he s in danger . <eos>\n",
            "< real trg: he is here ! <eos>\n",
            "\n",
            "****************************************************************************************************\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnjaSpMz4XjP"
      },
      "source": [
        "### Conclusion\n",
        "In the next Notebook we are going to clone this notebook and have a look at the Encoder Decoder Model with attention. The data processing and preparation will remain the same, We are only going to change the model achitecture.\n"
      ]
    }
  ]
}