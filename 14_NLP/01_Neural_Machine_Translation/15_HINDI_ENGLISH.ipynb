{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Machine Translation\n",
        "\n",
        "In this notebook we are going to create a neural machine translation model using deep learning with tensoflow.\n",
        "\n",
        "\n",
        "First we need to import required packages for us to create this model."
      ],
      "metadata": {
        "id": "waEQCIhuukeE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vVADQFOuJTgE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "import os\n",
        "import string\n",
        "from string import digits\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import re\n",
        "import seaborn as sns\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from google.colab import drive\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data that we will be using will be loaded from a a file that was uploaded in a google drive. We got the data from [kaggle](https://www.kaggle.com/datasets/aiswaryaramachandran/hindienglish-corpora)"
      ],
      "metadata": {
        "id": "wLSTAbdpu61X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9Uzf247KL_o",
        "outputId": "574911e1-5a4f-4216-bfd5-fffa70263329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we are going to define the path where our datafile is located."
      ],
      "metadata": {
        "id": "CuSMWx7ZvMJi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZYOMgB4hKa_q"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/drive/My Drive/NLP Data/Hindi_English_Truncated_Corpus/Hindi_English_Truncated_Corpus.csv'\n",
        "assert os.path.exists(data_path), f\"The file path {data_path} does not exists.\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we are going to read this file in a pandas dataframe."
      ],
      "metadata": {
        "id": "BGWwVI-DvT0G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "v-Y8A7hWKy41"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(data_path, encoding='utf-8')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the first `5` examples in the dataframe."
      ],
      "metadata": {
        "id": "y4WEUFDOvZWS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4sZd74HALCou",
        "outputId": "3130b88d-8543-464c-f43b-d9aa03f86186"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      source                                   english_sentence  \\\n",
              "0        ted  politicians do not have permission to do what ...   \n",
              "1        ted         I'd like to tell you about one such child,   \n",
              "2  indic2012  This percentage is even greater than the perce...   \n",
              "3        ted  what we really mean is that they're bad at not...   \n",
              "4  indic2012  .The ending portion of these Vedas is called U...   \n",
              "\n",
              "                                      hindi_sentence  \n",
              "0  राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
              "1  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
              "2   यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।  \n",
              "3     हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
              "4        इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-20cea555-aca7-4f49-9135-7d9c5d039a3d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ted</td>\n",
              "      <td>politicians do not have permission to do what ...</td>\n",
              "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ted</td>\n",
              "      <td>I'd like to tell you about one such child,</td>\n",
              "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>This percentage is even greater than the perce...</td>\n",
              "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ted</td>\n",
              "      <td>what we really mean is that they're bad at not...</td>\n",
              "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>.The ending portion of these Vedas is called U...</td>\n",
              "      <td>इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20cea555-aca7-4f49-9135-7d9c5d039a3d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-20cea555-aca7-4f49-9135-7d9c5d039a3d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-20cea555-aca7-4f49-9135-7d9c5d039a3d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the distribution of the `source` where the translation was comming from."
      ],
      "metadata": {
        "id": "MWH_LT6RvhrH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPRQ6-oDLFIO",
        "outputId": "bbee8d11-9005-46e4-d214-9c677e24f94d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tides        50000\n",
              "ted          39881\n",
              "indic2012    37726\n",
              "Name: source, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df['source'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to take the english and hindi sentence pairs that are comming from the `ted` source."
      ],
      "metadata": {
        "id": "EcEh1JYEvrxP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qtFu3oNmLQWl",
        "outputId": "28ecc7a0-b522-4369-eba5-26559fb21c62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   source                                   english_sentence  \\\n",
              "0     ted  politicians do not have permission to do what ...   \n",
              "1     ted         I'd like to tell you about one such child,   \n",
              "3     ted  what we really mean is that they're bad at not...   \n",
              "7     ted   And who are we to say, even, that they are wrong   \n",
              "13    ted                   So there is some sort of justice   \n",
              "\n",
              "                                       hindi_sentence  \n",
              "0   राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
              "1   मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
              "3      हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
              "7    और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं  \n",
              "13                                   तो वहाँ न्याय है  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52bcbc28-63bf-4ac4-9a63-c574bad78912\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ted</td>\n",
              "      <td>politicians do not have permission to do what ...</td>\n",
              "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ted</td>\n",
              "      <td>I'd like to tell you about one such child,</td>\n",
              "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ted</td>\n",
              "      <td>what we really mean is that they're bad at not...</td>\n",
              "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ted</td>\n",
              "      <td>And who are we to say, even, that they are wrong</td>\n",
              "      <td>और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ted</td>\n",
              "      <td>So there is some sort of justice</td>\n",
              "      <td>तो वहाँ न्याय है</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52bcbc28-63bf-4ac4-9a63-c574bad78912')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52bcbc28-63bf-4ac4-9a63-c574bad78912 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52bcbc28-63bf-4ac4-9a63-c574bad78912');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df=df[df['source']=='ted']\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking if we have any null values and drop the null values and duplicated."
      ],
      "metadata": {
        "id": "X3j41f04v5GA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lF13dvBHLX2B",
        "outputId": "037be61f-bf23-4814-91ba-371e427337ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "source              0\n",
              "english_sentence    0\n",
              "hindi_sentence      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mQfyGpl4Lf6Q"
      },
      "outputs": [],
      "source": [
        "df=df[~pd.isnull(df['english_sentence'])]\n",
        "df.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zPs8AomLz6c"
      },
      "source": [
        "We are going to select the random `25, 000` rows from the dataset, these are the examples that we are going to work with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWNd5zx_LpMh",
        "outputId": "93ad34cb-a38f-4061-9869-11e83451fc97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df=df.sample(n=25000,random_state=42)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we are going to convert the `target` (hindi) and the `source`(english) sentences to lower case."
      ],
      "metadata": {
        "id": "86eJzPwFwLMv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "K43ZYbB-L3Hh"
      },
      "outputs": [],
      "source": [
        "df['english_sentence']=df['english_sentence'].apply(lambda x: x.lower())\n",
        "df['hindi_sentence']=df['hindi_sentence'].apply(lambda x: x.lower())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we are going to remove `qoutes` as a method of data cleaning."
      ],
      "metadata": {
        "id": "k_jbK4IUwX2Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7wTrNwQEMC9c"
      },
      "outputs": [],
      "source": [
        "# Remove quotes\n",
        "df['english_sentence']=df['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
        "df['hindi_sentence']=df['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are then going to remove special characters\n"
      ],
      "metadata": {
        "id": "jtrb945ywfJA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vt-9tvL4MOTS"
      },
      "outputs": [],
      "source": [
        "exclude = set(string.punctuation) # Set of all special characters\n",
        "# Remove all the special characters\n",
        "df['english_sentence']=df['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "df['hindi_sentence']=df['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are then going to remove numbers from both the target and sorce sentence. We are going to further on remove extra spaces that will be in our target and source sentences."
      ],
      "metadata": {
        "id": "icscL9EFwjKD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CQU3GQdXMSxH"
      },
      "outputs": [],
      "source": [
        "# Remove all numbers from text\n",
        "remove_digits = str.maketrans('', '', digits)\n",
        "df['english_sentence']=df['english_sentence'].apply(lambda x: x.translate(remove_digits))\n",
        "df['hindi_sentence']=df['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n",
        "\n",
        "df['hindi_sentence'] = df['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
        "\n",
        "# Remove extra spaces\n",
        "df['english_sentence']=df['english_sentence'].apply(lambda x: x.strip())\n",
        "df['hindi_sentence']=df['hindi_sentence'].apply(lambda x: x.strip())\n",
        "df['english_sentence']=df['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "df['hindi_sentence']=df['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the target we are going to add the `START_ ` token at the start of each sentence and ` _END` token at the end of each sentence."
      ],
      "metadata": {
        "id": "_Iv5JgbEw4XE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "eWqxCUzSMagC"
      },
      "outputs": [],
      "source": [
        "# Add start and end tokens to target sequences\n",
        "df['hindi_sentence'] = df['hindi_sentence'].apply(lambda x : 'START_ '+ x + ' _END')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the cleaned src and trg sentences."
      ],
      "metadata": {
        "id": "9Pud3OfbxGRp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uKW07M6kMgv9",
        "outputId": "b47f9b1f-43f7-4085-bc47-79cecc7a729f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       source                                   english_sentence  \\\n",
              "82040     ted  we still dont know who her parents are who she is   \n",
              "85038     ted                                        no keyboard   \n",
              "58018     ted                    but as far as being a performer   \n",
              "74470     ted                        and this particular balloon   \n",
              "122330    ted  and its not as hard as you think integrate cli...   \n",
              "\n",
              "                                           hindi_sentence  \n",
              "82040   START_ हम अभी तक नहीं जानते हैं कि उसके मातापि...  \n",
              "85038                       START_ कोई कुंजीपटल नहीं _END  \n",
              "58018             START_ लेकिन एक कलाकार होने के साथ _END  \n",
              "74470                      START_ और यह खास गुब्बारा _END  \n",
              "122330  START_ और जितना आपको लगता है यह उतना कठिन नहीं...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f44d9e14-598c-4a9a-8565-b88180d792b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>82040</th>\n",
              "      <td>ted</td>\n",
              "      <td>we still dont know who her parents are who she is</td>\n",
              "      <td>START_ हम अभी तक नहीं जानते हैं कि उसके मातापि...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85038</th>\n",
              "      <td>ted</td>\n",
              "      <td>no keyboard</td>\n",
              "      <td>START_ कोई कुंजीपटल नहीं _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58018</th>\n",
              "      <td>ted</td>\n",
              "      <td>but as far as being a performer</td>\n",
              "      <td>START_ लेकिन एक कलाकार होने के साथ _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74470</th>\n",
              "      <td>ted</td>\n",
              "      <td>and this particular balloon</td>\n",
              "      <td>START_ और यह खास गुब्बारा _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122330</th>\n",
              "      <td>ted</td>\n",
              "      <td>and its not as hard as you think integrate cli...</td>\n",
              "      <td>START_ और जितना आपको लगता है यह उतना कठिन नहीं...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f44d9e14-598c-4a9a-8565-b88180d792b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f44d9e14-598c-4a9a-8565-b88180d792b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f44d9e14-598c-4a9a-8565-b88180d792b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vocabulary\n",
        "\n",
        "In this section we are going to have a look at creating the vocabulary for our `src` and `trg` sentences."
      ],
      "metadata": {
        "id": "eA30oraaxkp2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "U6W2_Hm4Mhtt"
      },
      "outputs": [],
      "source": [
        "### Get English and Hindi Vocabulary\n",
        "all_eng_words=set()\n",
        "for eng in df['english_sentence']:\n",
        "  for word in eng.split():\n",
        "    if word not in all_eng_words:\n",
        "      all_eng_words.add(word)\n",
        "\n",
        "all_hindi_words=set()\n",
        "for hin in df['hindi_sentence']:\n",
        "  for word in hin.split():\n",
        "    if word not in all_hindi_words:\n",
        "      all_hindi_words.add(word)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the vocabulary size or number of unique words in the source vocabulary."
      ],
      "metadata": {
        "id": "PBOaCsVjx3ZK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mXsTHFDMqX-",
        "outputId": "a9e7b4cb-e2d2-4eed-d630-7a9ea09ad77a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14030"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "len(all_eng_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the vocabulary size on the size on the targe."
      ],
      "metadata": {
        "id": "BJCugP88yBe8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RG5UGw0xMvfJ",
        "outputId": "4a3ff52c-405b-41a1-e45b-c896c7f9f766"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17540"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "len(all_hindi_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can create a column that which contains the sentence length for both the source and target as follows:\n"
      ],
      "metadata": {
        "id": "c0UkmR4UyQjv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LabM29MiMxUf"
      },
      "outputs": [],
      "source": [
        "df['length_eng_sentence']=df['english_sentence'].apply(lambda x:len(x.split(\" \")))\n",
        "df['length_hin_sentence']=df['hindi_sentence'].apply(lambda x:len(x.split(\" \")))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the dataframe head with sentences length."
      ],
      "metadata": {
        "id": "YM2ZqLdjye1_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "AM7Dq3HMM4fG",
        "outputId": "f04c5254-bbcb-41cf-af66-696c845cbf9a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       source                                   english_sentence  \\\n",
              "82040     ted  we still dont know who her parents are who she is   \n",
              "85038     ted                                        no keyboard   \n",
              "58018     ted                    but as far as being a performer   \n",
              "74470     ted                        and this particular balloon   \n",
              "122330    ted  and its not as hard as you think integrate cli...   \n",
              "\n",
              "                                           hindi_sentence  \\\n",
              "82040   START_ हम अभी तक नहीं जानते हैं कि उसके मातापि...   \n",
              "85038                       START_ कोई कुंजीपटल नहीं _END   \n",
              "58018             START_ लेकिन एक कलाकार होने के साथ _END   \n",
              "74470                      START_ और यह खास गुब्बारा _END   \n",
              "122330  START_ और जितना आपको लगता है यह उतना कठिन नहीं...   \n",
              "\n",
              "        length_eng_sentence  length_hin_sentence  \n",
              "82040                    11                   16  \n",
              "85038                     2                    5  \n",
              "58018                     7                    8  \n",
              "74470                     4                    6  \n",
              "122330                   16                   20  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-049ca40d-ca6b-438f-a35e-af985306dd26\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "      <th>length_eng_sentence</th>\n",
              "      <th>length_hin_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>82040</th>\n",
              "      <td>ted</td>\n",
              "      <td>we still dont know who her parents are who she is</td>\n",
              "      <td>START_ हम अभी तक नहीं जानते हैं कि उसके मातापि...</td>\n",
              "      <td>11</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85038</th>\n",
              "      <td>ted</td>\n",
              "      <td>no keyboard</td>\n",
              "      <td>START_ कोई कुंजीपटल नहीं _END</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58018</th>\n",
              "      <td>ted</td>\n",
              "      <td>but as far as being a performer</td>\n",
              "      <td>START_ लेकिन एक कलाकार होने के साथ _END</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74470</th>\n",
              "      <td>ted</td>\n",
              "      <td>and this particular balloon</td>\n",
              "      <td>START_ और यह खास गुब्बारा _END</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122330</th>\n",
              "      <td>ted</td>\n",
              "      <td>and its not as hard as you think integrate cli...</td>\n",
              "      <td>START_ और जितना आपको लगता है यह उतना कठिन नहीं...</td>\n",
              "      <td>16</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-049ca40d-ca6b-438f-a35e-af985306dd26')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-049ca40d-ca6b-438f-a35e-af985306dd26 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-049ca40d-ca6b-438f-a35e-af985306dd26');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfCsTMuMM7Bp",
        "outputId": "0b50a4e2-79d4-4b83-e9a6-4bea109347b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "df[df['length_eng_sentence']>30].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's filter our data and trim it so that we take the rows that has at most `20` words in a sequence."
      ],
      "metadata": {
        "id": "VFQEfpkIyq5w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulndwKi7NCPD",
        "outputId": "9ea50b3e-9c1b-4d02-c920-ab29223b15b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24774, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "df=df[df['length_eng_sentence']<=20]\n",
        "df=df[df['length_hin_sentence']<=20]\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the sentence in the target and source that has the maximum length."
      ],
      "metadata": {
        "id": "T7Z7IZXty6On"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1YXh0gwNIfv",
        "outputId": "719f134d-d2b3-4006-ae1b-283f02284857"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maximum length of Hindi Sentence  20\n",
            "maximum length of English Sentence  20\n"
          ]
        }
      ],
      "source": [
        "print(\"maximum length of Hindi Sentence \",max(df['length_hin_sentence']))\n",
        "print(\"maximum length of English Sentence \",max(df['length_eng_sentence']))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we are going to get the maximum sentence length for both the src and target sentences."
      ],
      "metadata": {
        "id": "JYK8kstWzDot"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Fu2_of3dNYp2"
      },
      "outputs": [],
      "source": [
        "max_length_src=max(df['length_hin_sentence'])\n",
        "max_length_tar=max(df['length_eng_sentence'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's then sort our targets and source tokens and get the how many tokens are we having for each of the pairs."
      ],
      "metadata": {
        "id": "Zk0CaXHnzXMZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3NNHBEkNbs7",
        "outputId": "790066c8-3fd6-414b-f0fb-76b240c14396"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14030, 17540)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "input_words = sorted(list(all_eng_words))\n",
        "target_words = sorted(list(all_hindi_words))\n",
        "num_encoder_tokens = len(all_eng_words)\n",
        "num_decoder_tokens = len(all_hindi_words)\n",
        "num_encoder_tokens, num_decoder_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to add `1` token for our target sentences as `0` will be the value of the padding token."
      ],
      "metadata": {
        "id": "muqrFVf-zliK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "CTSe4atbNpTI"
      },
      "outputs": [],
      "source": [
        "num_decoder_tokens += 1 #for zero padding"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a `stoi` string to integer mapping for both the source and the target sencences in the corpus."
      ],
      "metadata": {
        "id": "_IC0pIEDz6zb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "QnWjlVVXNsSn"
      },
      "outputs": [],
      "source": [
        "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we are going to create an `itos` an integer to string mapping for both the source and target pairs in the corpus."
      ],
      "metadata": {
        "id": "Y78zn2Z30HoD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "P9UQ02rqNzQQ"
      },
      "outputs": [],
      "source": [
        "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "k5nHNxuvN3hP",
        "outputId": "e8722084-1141-4439-a9d5-edd814e07f9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       source                                   english_sentence  \\\n",
              "117802    ted     i think the market can help us figure that out   \n",
              "18220     ted                          it begins about years ago   \n",
              "20115     ted   not only do we create much more dignity for them   \n",
              "84789     ted                      theyre not just sitting there   \n",
              "46160     ted                             in a decentralized way   \n",
              "75011     ted  this simulation was run on processors for a month   \n",
              "73408     ted  one because the benefits of the marshall plan ...   \n",
              "112584    ted  if you want to see the features of this car yo...   \n",
              "48424     ted                        help people to vote on them   \n",
              "109504    ted        is the most important thing for development   \n",
              "\n",
              "                                           hindi_sentence  \\\n",
              "117802  START_ मुझे लगता है कि बाज़ार हमें इस का जवाब ...   \n",
              "18220           START_ इसकी शुरुआत लगभग साल पहले हुई _END   \n",
              "20115   START_ न सिर्फ़ हम उनके लिये ही स्वाभिमान पैदा...   \n",
              "84789       START_ वे वहां आराम से बैठे हुए नहीं हैं _END   \n",
              "46160               START_ विकेन्द्रीकृत तरीके से भी _END   \n",
              "75011   START_ इस प्रारूपण को कम्प्युटर प्रोसेसरों पर ...   \n",
              "73408   START_ पहले तो इसलिए कि मार्शल प्लान के फायदों...   \n",
              "112584  START_ अगर आप इस कार की विशेषताओं को देखना चाह...   \n",
              "48424    START_ लोगों से उन विचारों पर राय ले रहा था _END   \n",
              "109504       START_ सबसे महत्वपूर्ण है विकास के लिये _END   \n",
              "\n",
              "        length_eng_sentence  length_hin_sentence  \n",
              "117802                   10                   14  \n",
              "18220                     5                    8  \n",
              "20115                    10                   11  \n",
              "84789                     5                   10  \n",
              "46160                     4                    6  \n",
              "75011                     9                   13  \n",
              "73408                    11                   15  \n",
              "112584                   15                   18  \n",
              "48424                     6                   11  \n",
              "109504                    7                    8  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0102216c-eaaf-4d3c-9942-8ea790935ab5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "      <th>length_eng_sentence</th>\n",
              "      <th>length_hin_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>117802</th>\n",
              "      <td>ted</td>\n",
              "      <td>i think the market can help us figure that out</td>\n",
              "      <td>START_ मुझे लगता है कि बाज़ार हमें इस का जवाब ...</td>\n",
              "      <td>10</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18220</th>\n",
              "      <td>ted</td>\n",
              "      <td>it begins about years ago</td>\n",
              "      <td>START_ इसकी शुरुआत लगभग साल पहले हुई _END</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20115</th>\n",
              "      <td>ted</td>\n",
              "      <td>not only do we create much more dignity for them</td>\n",
              "      <td>START_ न सिर्फ़ हम उनके लिये ही स्वाभिमान पैदा...</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84789</th>\n",
              "      <td>ted</td>\n",
              "      <td>theyre not just sitting there</td>\n",
              "      <td>START_ वे वहां आराम से बैठे हुए नहीं हैं _END</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46160</th>\n",
              "      <td>ted</td>\n",
              "      <td>in a decentralized way</td>\n",
              "      <td>START_ विकेन्द्रीकृत तरीके से भी _END</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75011</th>\n",
              "      <td>ted</td>\n",
              "      <td>this simulation was run on processors for a month</td>\n",
              "      <td>START_ इस प्रारूपण को कम्प्युटर प्रोसेसरों पर ...</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73408</th>\n",
              "      <td>ted</td>\n",
              "      <td>one because the benefits of the marshall plan ...</td>\n",
              "      <td>START_ पहले तो इसलिए कि मार्शल प्लान के फायदों...</td>\n",
              "      <td>11</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112584</th>\n",
              "      <td>ted</td>\n",
              "      <td>if you want to see the features of this car yo...</td>\n",
              "      <td>START_ अगर आप इस कार की विशेषताओं को देखना चाह...</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48424</th>\n",
              "      <td>ted</td>\n",
              "      <td>help people to vote on them</td>\n",
              "      <td>START_ लोगों से उन विचारों पर राय ले रहा था _END</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109504</th>\n",
              "      <td>ted</td>\n",
              "      <td>is the most important thing for development</td>\n",
              "      <td>START_ सबसे महत्वपूर्ण है विकास के लिये _END</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0102216c-eaaf-4d3c-9942-8ea790935ab5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0102216c-eaaf-4d3c-9942-8ea790935ab5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0102216c-eaaf-4d3c-9942-8ea790935ab5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "df = shuffle(df)\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we are going to get the source and the target sentences as numpy arrays and split these examle pairs into train and test set."
      ],
      "metadata": {
        "id": "BerKmzGy0Zp7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aw0qyXMiN7Zs",
        "outputId": "07d37a26-b0b6-4221-cc26-210ab47ad39e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((19819,), (4955,))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "X, y = df['english_sentence'], df['hindi_sentence']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can save the `pickle` files for our source and target."
      ],
      "metadata": {
        "id": "ulx8PYAe0meY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "wPQGEbVMODa-"
      },
      "outputs": [],
      "source": [
        "X_train.to_pickle('X_train.pkl')\n",
        "X_test.to_pickle('X_test.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### colate_function\n",
        "\n",
        "We are then going to create a colate_function called `generate_batch` that will help us to generate batches during training of the model."
      ],
      "metadata": {
        "id": "SIe8Zdft0z61"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "6sGfl2vWOQsj"
      },
      "outputs": [],
      "source": [
        "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
        "    ''' Generate a batch of data '''\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "                for t, word in enumerate(input_text.split()):\n",
        "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
        "                for t, word in enumerate(target_text.split()):\n",
        "                    if t<len(target_text.split())-1:\n",
        "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
        "                    if t>0:\n",
        "                        # decoder target sequence (one hot encoded)\n",
        "                        # does not include the START_ token\n",
        "                        # Offset by one timestep\n",
        "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yxBkdEQOdB7"
      },
      "source": [
        "### Encoder-Decoder Architecture\n",
        "\n",
        "We are going to create a  decoder and encoder achitecture. We are going to use the keras functional api to create the encoder and decoder model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "v5UlCPJTOaLB"
      },
      "outputs": [],
      "source": [
        "latent_dim=300"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encoder Model\n",
        "\n",
        "In the following code cell we are going to create our `encoder_model`"
      ],
      "metadata": {
        "id": "rXi0S3El1qTI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "iveIjAqjOfY-"
      },
      "outputs": [],
      "source": [
        "# Encoder\n",
        "encoder_inputs = keras.layers.Input(shape=(None,))\n",
        "enc_emb =  keras.layers.Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
        "encoder_lstm = keras.layers.LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decoder Model\n",
        "\n",
        "In the following code cell we are going to create our `decoder_model`"
      ],
      "metadata": {
        "id": "b5lSsSI91zI6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "AGuuFP7fOnEb"
      },
      "outputs": [],
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = keras.layers.Input(shape=(None,))\n",
        "dec_emb_layer = keras.layers.Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = keras.models.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling the model."
      ],
      "metadata": {
        "id": "ILKkfcAB15dn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "D8RnDl_2Ox4C"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing the model summary..."
      ],
      "metadata": {
        "id": "81RmVJLv18eQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjKAkXFlO0h_",
        "outputId": "aedd1c27-f128-40cd-ee11-f7738347aa09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 300)    4209000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 300)    5262300     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 300),        721200      ['embedding[0][0]']              \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 300),  721200      ['embedding_1[0][0]',            \n",
            "                                 (None, 300),                     'lstm[0][1]',                   \n",
            "                                 (None, 300)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 17541)  5279841     ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 16,193,541\n",
            "Trainable params: 16,193,541\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trainhing loop\n",
        "\n",
        "During calling of the `model.fit` we are going to use the `generator` which is the `generate_batch` with the batch size of `128` and train the model for `100` epochs."
      ],
      "metadata": {
        "id": "Wlu0Znhq2Den"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "uChvghCDO2Jk"
      },
      "outputs": [],
      "source": [
        "train_samples = len(X_train)\n",
        "val_samples = len(X_test)\n",
        "batch_size = 128\n",
        "epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4itoa-AqO7Y3",
        "outputId": "ea938ca7-eca9-4134-b3a0-ac89019527be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-40-b22c3ec5e69e>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "154/154 [==============================] - 79s 422ms/step - loss: 6.9349 - val_loss: 6.3637\n",
            "Epoch 2/100\n",
            "154/154 [==============================] - 51s 325ms/step - loss: 6.3067 - val_loss: 6.3228\n",
            "Epoch 3/100\n",
            "154/154 [==============================] - 50s 324ms/step - loss: 6.2603 - val_loss: 6.3043\n",
            "Epoch 4/100\n",
            "154/154 [==============================] - 51s 329ms/step - loss: 6.2225 - val_loss: 6.2526\n",
            "Epoch 5/100\n",
            "154/154 [==============================] - 51s 331ms/step - loss: 6.1390 - val_loss: 6.1691\n",
            "Epoch 6/100\n",
            "154/154 [==============================] - 51s 329ms/step - loss: 6.0447 - val_loss: 6.0898\n",
            "Epoch 7/100\n",
            "154/154 [==============================] - 50s 323ms/step - loss: 5.9548 - val_loss: 6.0127\n",
            "Epoch 8/100\n",
            "154/154 [==============================] - 50s 326ms/step - loss: 5.8791 - val_loss: 5.9615\n",
            "Epoch 9/100\n",
            "154/154 [==============================] - 51s 335ms/step - loss: 5.8185 - val_loss: 5.9187\n",
            "Epoch 10/100\n",
            "154/154 [==============================] - 50s 325ms/step - loss: 5.7681 - val_loss: 5.8832\n",
            "Epoch 11/100\n",
            "154/154 [==============================] - 50s 328ms/step - loss: 5.7208 - val_loss: 5.8545\n",
            "Epoch 12/100\n",
            "154/154 [==============================] - 51s 334ms/step - loss: 5.6701 - val_loss: 5.8174\n",
            "Epoch 13/100\n",
            "154/154 [==============================] - 51s 330ms/step - loss: 5.6146 - val_loss: 5.7753\n",
            "Epoch 14/100\n",
            "154/154 [==============================] - 50s 324ms/step - loss: 5.5619 - val_loss: 5.7539\n",
            "Epoch 15/100\n",
            "154/154 [==============================] - 50s 324ms/step - loss: 5.5124 - val_loss: 5.7074\n",
            "Epoch 16/100\n",
            "154/154 [==============================] - 51s 329ms/step - loss: 5.4619 - val_loss: 5.6734\n",
            "Epoch 17/100\n",
            "154/154 [==============================] - 50s 328ms/step - loss: 5.4153 - val_loss: 5.6599\n",
            "Epoch 18/100\n",
            "154/154 [==============================] - 51s 331ms/step - loss: 5.3697 - val_loss: 5.6159\n",
            "Epoch 19/100\n",
            "154/154 [==============================] - 51s 332ms/step - loss: 5.3264 - val_loss: 5.5988\n",
            "Epoch 20/100\n",
            "154/154 [==============================] - 51s 331ms/step - loss: 5.2838 - val_loss: 5.5672\n",
            "Epoch 21/100\n",
            "154/154 [==============================] - 52s 337ms/step - loss: 5.2429 - val_loss: 5.5509\n",
            "Epoch 22/100\n",
            "154/154 [==============================] - 51s 330ms/step - loss: 5.2007 - val_loss: 5.5172\n",
            "Epoch 23/100\n",
            "154/154 [==============================] - 50s 326ms/step - loss: 5.1613 - val_loss: 5.5142\n",
            "Epoch 24/100\n",
            "154/154 [==============================] - 50s 327ms/step - loss: 5.1218 - val_loss: 5.4801\n",
            "Epoch 25/100\n",
            "154/154 [==============================] - 50s 322ms/step - loss: 5.0815 - val_loss: 5.4606\n",
            "Epoch 26/100\n",
            "154/154 [==============================] - 51s 329ms/step - loss: 5.0429 - val_loss: 5.4531\n",
            "Epoch 27/100\n",
            "154/154 [==============================] - 51s 334ms/step - loss: 5.0023 - val_loss: 5.4422\n",
            "Epoch 28/100\n",
            "154/154 [==============================] - 50s 325ms/step - loss: 4.9645 - val_loss: 5.4173\n",
            "Epoch 29/100\n",
            "154/154 [==============================] - 50s 324ms/step - loss: 4.9274 - val_loss: 5.3962\n",
            "Epoch 30/100\n",
            "154/154 [==============================] - 49s 321ms/step - loss: 4.8893 - val_loss: 5.3887\n",
            "Epoch 31/100\n",
            "154/154 [==============================] - 52s 336ms/step - loss: 4.8519 - val_loss: 5.3882\n",
            "Epoch 32/100\n",
            "154/154 [==============================] - 52s 338ms/step - loss: 4.8150 - val_loss: 5.3607\n",
            "Epoch 33/100\n",
            "154/154 [==============================] - 51s 333ms/step - loss: 4.7790 - val_loss: 5.3463\n",
            "Epoch 34/100\n",
            "154/154 [==============================] - 50s 328ms/step - loss: 4.7437 - val_loss: 5.3472\n",
            "Epoch 35/100\n",
            "154/154 [==============================] - 51s 334ms/step - loss: 4.7078 - val_loss: 5.3240\n",
            "Epoch 36/100\n",
            "154/154 [==============================] - 52s 340ms/step - loss: 4.6733 - val_loss: 5.3426\n",
            "Epoch 37/100\n",
            "154/154 [==============================] - 50s 327ms/step - loss: 4.6389 - val_loss: 5.3073\n",
            "Epoch 38/100\n",
            "154/154 [==============================] - 50s 328ms/step - loss: 4.6040 - val_loss: 5.2943\n",
            "Epoch 39/100\n",
            "154/154 [==============================] - 51s 331ms/step - loss: 4.5691 - val_loss: 5.2892\n",
            "Epoch 40/100\n",
            "154/154 [==============================] - 51s 331ms/step - loss: 4.5364 - val_loss: 5.2822\n",
            "Epoch 41/100\n",
            "154/154 [==============================] - 50s 327ms/step - loss: 4.5025 - val_loss: 5.2714\n",
            "Epoch 42/100\n",
            "154/154 [==============================] - 51s 331ms/step - loss: 4.4697 - val_loss: 5.2654\n",
            "Epoch 43/100\n",
            "154/154 [==============================] - 51s 330ms/step - loss: 4.4372 - val_loss: 5.2640\n",
            "Epoch 44/100\n",
            "154/154 [==============================] - 50s 326ms/step - loss: 4.4049 - val_loss: 5.2645\n",
            "Epoch 45/100\n",
            "154/154 [==============================] - 51s 332ms/step - loss: 4.3707 - val_loss: 5.2674\n",
            "Epoch 46/100\n",
            "154/154 [==============================] - 51s 331ms/step - loss: 4.3389 - val_loss: 5.2506\n",
            "Epoch 47/100\n",
            "154/154 [==============================] - 50s 326ms/step - loss: 4.3065 - val_loss: 5.2478\n",
            "Epoch 48/100\n",
            "154/154 [==============================] - 51s 331ms/step - loss: 4.2752 - val_loss: 5.2397\n",
            "Epoch 49/100\n",
            "154/154 [==============================] - 50s 326ms/step - loss: 4.2435 - val_loss: 5.2457\n",
            "Epoch 50/100\n",
            "154/154 [==============================] - 51s 330ms/step - loss: 4.2134 - val_loss: 5.2352\n",
            "Epoch 51/100\n",
            "154/154 [==============================] - 49s 322ms/step - loss: 4.1816 - val_loss: 5.2344\n",
            "Epoch 52/100\n",
            "154/154 [==============================] - 51s 331ms/step - loss: 4.1511 - val_loss: 5.2433\n",
            "Epoch 53/100\n",
            "154/154 [==============================] - 51s 330ms/step - loss: 4.1202 - val_loss: 5.2402\n",
            "Epoch 54/100\n",
            "154/154 [==============================] - 51s 330ms/step - loss: 4.0894 - val_loss: 5.2343\n",
            "Epoch 55/100\n",
            "154/154 [==============================] - 52s 337ms/step - loss: 4.0592 - val_loss: 5.2319\n",
            "Epoch 56/100\n",
            "154/154 [==============================] - 50s 324ms/step - loss: 4.0278 - val_loss: 5.2396\n",
            "Epoch 57/100\n",
            "154/154 [==============================] - 51s 331ms/step - loss: 3.9973 - val_loss: 5.2398\n",
            "Epoch 58/100\n",
            "154/154 [==============================] - 51s 331ms/step - loss: 3.9674 - val_loss: 5.2278\n",
            "Epoch 59/100\n",
            "154/154 [==============================] - 51s 330ms/step - loss: 3.9382 - val_loss: 5.2388\n",
            "Epoch 60/100\n",
            "154/154 [==============================] - 51s 332ms/step - loss: 3.9087 - val_loss: 5.2373\n",
            "Epoch 61/100\n",
            "154/154 [==============================] - 49s 320ms/step - loss: 3.8796 - val_loss: 5.2357\n",
            "Epoch 62/100\n",
            "154/154 [==============================] - 51s 329ms/step - loss: 3.8499 - val_loss: 5.2401\n",
            "Epoch 63/100\n",
            "154/154 [==============================] - 51s 330ms/step - loss: 3.8223 - val_loss: 5.2483\n",
            "Epoch 64/100\n",
            "154/154 [==============================] - 50s 328ms/step - loss: 3.7929 - val_loss: 5.2454\n",
            "Epoch 65/100\n",
            "154/154 [==============================] - 52s 338ms/step - loss: 3.7638 - val_loss: 5.2459\n",
            "Epoch 66/100\n",
            "154/154 [==============================] - 50s 324ms/step - loss: 3.7344 - val_loss: 5.2539\n",
            "Epoch 67/100\n",
            "154/154 [==============================] - 51s 331ms/step - loss: 3.7061 - val_loss: 5.2597\n",
            "Epoch 68/100\n",
            "154/154 [==============================] - 51s 329ms/step - loss: 3.6774 - val_loss: 5.2573\n",
            "Epoch 69/100\n",
            "154/154 [==============================] - 51s 329ms/step - loss: 3.6498 - val_loss: 5.2623\n",
            "Epoch 70/100\n",
            "154/154 [==============================] - 50s 324ms/step - loss: 3.6205 - val_loss: 5.2697\n",
            "Epoch 71/100\n",
            "154/154 [==============================] - 51s 331ms/step - loss: 3.5929 - val_loss: 5.2761\n",
            "Epoch 72/100\n",
            "154/154 [==============================] - 51s 333ms/step - loss: 3.5655 - val_loss: 5.2873\n",
            "Epoch 73/100\n",
            "154/154 [==============================] - 51s 329ms/step - loss: 3.5381 - val_loss: 5.2902\n",
            "Epoch 74/100\n",
            "154/154 [==============================] - 51s 335ms/step - loss: 3.5092 - val_loss: 5.2945\n",
            "Epoch 75/100\n",
            "154/154 [==============================] - 50s 325ms/step - loss: 3.4814 - val_loss: 5.3019\n",
            "Epoch 76/100\n",
            "154/154 [==============================] - 52s 336ms/step - loss: 3.4535 - val_loss: 5.3042\n",
            "Epoch 77/100\n",
            "154/154 [==============================] - 51s 333ms/step - loss: 3.4251 - val_loss: 5.3220\n",
            "Epoch 78/100\n",
            "154/154 [==============================] - 51s 334ms/step - loss: 3.3978 - val_loss: 5.3253\n",
            "Epoch 79/100\n",
            "154/154 [==============================] - 52s 341ms/step - loss: 3.3709 - val_loss: 5.3266\n",
            "Epoch 80/100\n",
            "154/154 [==============================] - 51s 330ms/step - loss: 3.3425 - val_loss: 5.3383\n",
            "Epoch 81/100\n",
            "154/154 [==============================] - 50s 326ms/step - loss: 3.3146 - val_loss: 5.3394\n",
            "Epoch 82/100\n",
            "154/154 [==============================] - 50s 326ms/step - loss: 3.2861 - val_loss: 5.3513\n",
            "Epoch 83/100\n",
            "154/154 [==============================] - 51s 329ms/step - loss: 3.2598 - val_loss: 5.3668\n",
            "Epoch 84/100\n",
            "154/154 [==============================] - 52s 339ms/step - loss: 3.2330 - val_loss: 5.3640\n",
            "Epoch 85/100\n",
            "154/154 [==============================] - 51s 332ms/step - loss: 3.2051 - val_loss: 5.3712\n",
            "Epoch 86/100\n",
            "154/154 [==============================] - 50s 327ms/step - loss: 3.1772 - val_loss: 5.3760\n",
            "Epoch 87/100\n",
            "154/154 [==============================] - 51s 334ms/step - loss: 3.1507 - val_loss: 5.3946\n",
            "Epoch 88/100\n",
            "154/154 [==============================] - 50s 325ms/step - loss: 3.1227 - val_loss: 5.3991\n",
            "Epoch 89/100\n",
            "154/154 [==============================] - 51s 332ms/step - loss: 3.0949 - val_loss: 5.4059\n",
            "Epoch 90/100\n",
            "154/154 [==============================] - 50s 326ms/step - loss: 3.0677 - val_loss: 5.4069\n",
            "Epoch 91/100\n",
            "154/154 [==============================] - 51s 331ms/step - loss: 3.0395 - val_loss: 5.4290\n",
            "Epoch 92/100\n",
            "154/154 [==============================] - 51s 330ms/step - loss: 3.0114 - val_loss: 5.4329\n",
            "Epoch 93/100\n",
            "154/154 [==============================] - 50s 323ms/step - loss: 2.9834 - val_loss: 5.4349\n",
            "Epoch 94/100\n",
            "154/154 [==============================] - 52s 336ms/step - loss: 2.9554 - val_loss: 5.4483\n",
            "Epoch 95/100\n",
            "154/154 [==============================] - 50s 325ms/step - loss: 2.9293 - val_loss: 5.4646\n",
            "Epoch 96/100\n",
            "154/154 [==============================] - 51s 330ms/step - loss: 2.9008 - val_loss: 5.4836\n",
            "Epoch 97/100\n",
            "154/154 [==============================] - 51s 330ms/step - loss: 2.8717 - val_loss: 5.4937\n",
            "Epoch 98/100\n",
            "154/154 [==============================] - 49s 321ms/step - loss: 2.8453 - val_loss: 5.4940\n",
            "Epoch 99/100\n",
            "154/154 [==============================] - 52s 336ms/step - loss: 2.8173 - val_loss: 5.5100\n",
            "Epoch 100/100\n",
            "154/154 [==============================] - 50s 325ms/step - loss: 2.7894 - val_loss: 5.5203\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe0c00b9690>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
        "                    steps_per_epoch = train_samples//batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
        "                    validation_steps = val_samples//batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the model weights..."
      ],
      "metadata": {
        "id": "O4BvLa2p2Yu3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "oxEF43zqO_rE"
      },
      "outputs": [],
      "source": [
        "model.save_weights('nmt_weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "u6nTaIzOPNKu"
      },
      "outputs": [],
      "source": [
        "# Encode the input sequence to get the \"thought vectors\"\n",
        "encoder_model = keras.models.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = keras.layers.Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = keras.layers.Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = keras.models.Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "DOpD1QB9PNHx"
      },
      "outputs": [],
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = target_token_index['START_']\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '_END' or\n",
        "           len(decoded_sentence) > 50):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making predictions."
      ],
      "metadata": {
        "id": "cujgMeaX3AFr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "4LSzufT1PM-w"
      },
      "outputs": [],
      "source": [
        "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
        "k=-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "EslVEF2UPM4J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15c0ca15-808d-45ea-f91a-f086177fe75c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Input English sentence: human rights is also important but it just gets one cross\n",
            "Actual Hindi Translation:  मानवाधिकार भी ज़रूरी है मगर उसे थोडे कम नंबर मिले हैं। \n",
            "Predicted Hindi Translation:  मानवता को सामाजिक समस्या को देख सकते हैं कि यह सब\n"
          ]
        }
      ],
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "jBMAmeumPM1D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d22202ef-54b6-4ef7-d392-ae886e24bc13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Input English sentence: mt in that respect\n",
            "Actual Hindi Translation:  इसलिए \n",
            "Predicted Hindi Translation:  तो ये है कि \n"
          ]
        }
      ],
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "8tXZ9-T2Pui4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fdbd6ad-eace-47ba-aff5-a72d7aea330f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Input English sentence: a priest\n",
            "Actual Hindi Translation:  एक पुजारी \n",
            "Predicted Hindi Translation:  एक दिन \n"
          ]
        }
      ],
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "qZRdOrAIPx-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e66f660f-82c1-4252-fb8a-0b15572b7a8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Input English sentence: we need to open our eyes and see that we are not victims\n",
            "Actual Hindi Translation:  हमें हमारी आँखे खोलनी होगी और देखना होगा कि हम पीड़ित नहीं हैं \n",
            "Predicted Hindi Translation:  हमें पता है कि हम में से अधिक लोग इस बात से नहीं च\n"
          ]
        }
      ],
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh3vuVLoPytf"
      },
      "source": [
        "### Refs\n",
        "\n",
        "1. [www.kaggle.com](https://www.kaggle.com/code/aiswaryaramachandran/english-to-hindi-neural-machine-translation/notebook)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}