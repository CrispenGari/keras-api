{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_GRU_Embeding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBEmZC70Drnk"
      },
      "source": [
        "### Simple RNN\n",
        "\n",
        "In the previous notebook we learnt how to create a simple `RNN` that was able to translate text from english to french. This time around we are going to exand that even more by creating an Embedding ``GRU`` that will be able to perform the task, even better. Note that the implementation is the same even when you are using the `LSTM`.\n",
        "\n",
        "**Note**: The rest of the notebook will remain the same, when there's a change i will highlight.\n",
        "\n",
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEGRciNODh3o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ba76bcd5-0c66-4f14-b4cf-629fc5dc339e"
      },
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "import helper, os, time\n",
        "\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-6SXAJDHBHa"
      },
      "source": [
        "### Mounting the Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3C26uJADrWf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92146744-2db0-45ac-b6d5-34b2a0cfe33e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rc3hfXU7HZix"
      },
      "source": [
        "### Paths to the files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_690XgdzDrTz"
      },
      "source": [
        "base_path = '/content/drive/MyDrive/NLP Data/seq2seq/fr-en-small'\n",
        "en_path = 'small_vocab_en.txt'\n",
        "fr_path = 'small_vocab_fr.txt'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gltNO_9sH4B7"
      },
      "source": [
        "### Loading the data.\n",
        "\n",
        "We have two files that are located at this path `'/content/drive/MyDrive/NLP Data/seq2seq/fr-en-small'` and thes files are:\n",
        "\n",
        "```\n",
        "small_vocab_fr.txt\n",
        "small_vocab_en.txt\n",
        "```\n",
        "\n",
        "The following line help us to load the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "581k-VQpDrOY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09a931ef-5598-4901-d2e4-e93028f18f1e"
      },
      "source": [
        "eng_sents = open(os.path.join(base_path, en_path), encoding='utf8').read().split('\\n')\n",
        "fre_sents = open(os.path.join(base_path, fr_path), encoding='utf8').read().split('\\n')\n",
        "\n",
        "print(\"Data Loaded\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "EroZAWUvJneb",
        "outputId": "859bc07d-d7ee-4406-a0eb-b8061876a3d2"
      },
      "source": [
        "eng_sents[1]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'the united states is usually chilly during july , and it is usually freezing in november .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzQHLHzDJwYB"
      },
      "source": [
        "By looking at the data we can see that the data is already preprocessed, which means we are not going to do that step here.\n",
        "\n",
        "### Next, Bulding the Vocabulary.\n",
        "\n",
        "Vocabulary in my definition is just unique words in the curpus. Let's look at the vocabulary size of french and english. But first we need to tokenize each sentence, Inorder for us to do that I'm going to use the `spacy` library which is my favourite when it comes to tokenization of languages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYdwgsDDDrIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d597533f-4c16-4767-d2dd-53861737f209"
      },
      "source": [
        "import spacy\n",
        "spacy.cli.download('fr_core_news_sm')\n",
        "\n",
        "spacy_fr = spacy.load('fr_core_news_sm')\n",
        "spacy_en = spacy.load('en_core_web_sm')\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em20rVNkDrFo"
      },
      "source": [
        "def tokenize_fr(sent):\n",
        "  return [tok.text for tok in spacy_fr.tokenizer(sent)]\n",
        "  \n",
        "def tokenize_en(sent):\n",
        "  return [tok.text for tok in spacy_en.tokenizer(sent)]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqbCQ512DrCi"
      },
      "source": [
        "en_counter = Counter()\n",
        "fr_counter = Counter()\n",
        "\n",
        "for sent in eng_sents:\n",
        "  en_counter.update(tokenize_en(sent.lower()))\n",
        "for sent in fre_sents:\n",
        "  fr_counter.update(tokenize_fr(sent.lower()))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq9JM8HIL6RT",
        "outputId": "cdac890d-9f1a-4631-9be5-080f813bb8b9"
      },
      "source": [
        "en_vocab_size = len(en_counter)\n",
        "fr_vocab_size = len(fr_counter)\n",
        "\n",
        "fr_vocab_size, en_vocab_size"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(340, 201)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4n7K3LsMWW8"
      },
      "source": [
        "Here we have `340` unique words for french in this dataset and `201` unique words for english.\n",
        "\n",
        "### Preprocessing.\n",
        "\n",
        "We will convert our text data into sequence of integers so basically we are going to perform the following:\n",
        "\n",
        "1. Tokenize the words into ids\n",
        "2. Pad the tokens so that they will have same length.\n",
        "\n",
        "For this task we are going to use the keras `Tokenizer` class to perform the task, We have been using this for sentiment analyisis so the procedure is the same.\n",
        "\n",
        "We are going to have two tokenizers for each language.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_JJVUlADq_q"
      },
      "source": [
        "en_tokenizer = Tokenizer(num_words=en_vocab_size, oov_token=\"<oov>\")\n",
        "en_tokenizer.fit_on_texts(eng_sents)\n",
        "\n",
        "fr_tokenizer = Tokenizer(num_words=fr_vocab_size, oov_token=\"<oov>\")\n",
        "fr_tokenizer.fit_on_texts(fre_sents)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1EScuA6T1Nx"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APoyIFAiDq7x"
      },
      "source": [
        "en_word_indices = en_tokenizer.word_index\n",
        "en_word_indices_reversed = dict([\n",
        "    (v, k) for (k, v) in en_word_indices.items()\n",
        "])\n",
        "\n",
        "fr_word_indices = fr_tokenizer.word_index\n",
        "fr_word_indices_reversed = dict([\n",
        "    (v, k) for (k, v) in fr_word_indices.items()\n",
        "])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "An7_ADx7Olap"
      },
      "source": [
        "### Helper functions\n",
        "We will create some helper function that converts sequences to text and text to sequences for each language. These function will be used for inference later on.\n",
        "\n",
        "**We have set the out of vocabulary `oov_token|| <\"oov\">`token to `1`  which means the word that does not exist in the vocabulary it's integer representation is 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDQsSkoAOlBS"
      },
      "source": [
        "def en_seq_to_text(sequences):\n",
        "  return \" \".join(en_word_indices_reversed[i] for i in sequences )\n",
        "\n",
        "def en_seq_to_text(sequences):\n",
        "  return \" \".join(fr_word_indices_reversed[i] for i in sequences )\n",
        "\n",
        "def en_text_to_seq(sent):\n",
        "  words = tokenize_en(sent.lower())\n",
        "  sequences = []\n",
        "  for word in words:\n",
        "    try:\n",
        "      sequences.append(en_word_indices[word])\n",
        "    except:\n",
        "      sequences.append(1)\n",
        "  return sequences\n",
        "\n",
        "def fr_text_to_seq(sent):\n",
        "  words = tokenize_fr(sent.lower())\n",
        "  sequences = []\n",
        "  for word in words:\n",
        "    try:\n",
        "      sequences.append(fr_word_indices[word])\n",
        "    except:\n",
        "      sequences.append(1)\n",
        "  return sequences"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwvQ_uFHTTBK"
      },
      "source": [
        "### Converting text to sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nspRxCCTSUs"
      },
      "source": [
        "en_sequences = en_tokenizer.texts_to_sequences(eng_sents)\n",
        "fr_sequences = fr_tokenizer.texts_to_sequences(fre_sents)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnbY97HGUrGP",
        "outputId": "9b87cdae-1a9f-4b5d-c6d7-6da8494172de"
      },
      "source": [
        "fr_sequences[0:4]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[36, 35, 2, 9, 68, 38, 12, 25, 7, 4, 2, 113, 3, 51],\n",
              " [5, 33, 32, 2, 13, 20, 3, 50, 7, 4, 96, 70, 3, 52],\n",
              " [102, 2, 13, 68, 3, 46, 7, 4, 2, 13, 22, 3, 42],\n",
              " [5, 33, 32, 2, 9, 270, 3, 42, 7, 4, 104, 20, 3, 49]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKF4CdRUQJCy"
      },
      "source": [
        "### Padding Sequences.\n",
        "\n",
        "In our case we are going to assume that the longest sentence has `100` words for both `fr` and `en` languages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhkhdZ-8QI4F"
      },
      "source": [
        "max_words = 100\n",
        "en_tokens_padded = pad_sequences(\n",
        "    en_sequences, \n",
        "    maxlen=max_words, \n",
        "    padding=\"post\", \n",
        "    truncating=\"post\"\n",
        ")\n",
        "fr_tokens_padded = pad_sequences(\n",
        "    fr_sequences, \n",
        "    maxlen=max_words, \n",
        "    padding=\"post\", \n",
        "    truncating=\"post\"\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHomR9cmDq2s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ab3467c-384f-4509-f508-c33bd6523955"
      },
      "source": [
        "en_tokens_padded[:2]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[18, 24,  2,  9, 68,  5, 40,  8,  4,  2, 56,  3, 45,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0],\n",
              "       [ 6, 21, 22,  2, 10, 63,  5, 44,  8,  4,  2, 10, 52,  3, 46,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FJ69jNAVOnT"
      },
      "source": [
        "### Logits to text.\n",
        "\n",
        "We are going to create 1 more helper function that will help us to take logits or the predictions probabilities and then we convert them to human understandable format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDlG7MzYVvi2"
      },
      "source": [
        "\n",
        "def logits_to_text(logits, tokenizer):\n",
        "  index_to_words = {id: word for word, id\n",
        "                    in tokenizer.word_index.items()}\n",
        "  index_to_words[0] = '<pad>'\n",
        "  \"\"\"\n",
        "  For every prediction we are going to ignore the pad token\n",
        "  \"\"\"\n",
        "  return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)]).replace(\"<pad>\", \"\")\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moeeDvRxYQhd"
      },
      "source": [
        "### Embedding GRU\n",
        "\n",
        "Unlike from the previous Notebook we never had an Embedding layer. This time we will be having the embedding layer as our first layer in the `Sequential` model.\n",
        "\n",
        "This is a simple RNN that will learn to translate english sentences to french.\n",
        "\n",
        "![img](https://github.com/LeanManager/Machine_Translation/raw/e6567f10a6e380eea453fa392de94f26973c8b16/images/embedding.png)\n",
        "\n",
        "### What is the purpose of the embbeding layer?\n",
        "The embedding layer is a layer that groups words with the similar meaning close to each other in a vector space. This helps the model to learn better and make better predictions, because if the words with similar meaning have are closer to each other interms of euclidian distance then the model will be able to ofcause notice that and learn better and faster.\n",
        "\n",
        "We are going to use the Dequential API this time around."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTvuC7kQYMcU",
        "outputId": "b7203f98-fcb0-40bc-def3-bcc87caa5f6d"
      },
      "source": [
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Embedding(\n",
        "        en_vocab_size,\n",
        "        128, \n",
        "        input_length=max_words\n",
        "    ),\n",
        "    keras.layers.GRU(128, return_sequences=True),\n",
        "    keras.layers.GRU(256, return_sequences=True),\n",
        "    keras.layers.GRU(512, return_sequences=True),\n",
        "    keras.layers.Dense(1024, activation=\"relu\"),\n",
        "    keras.layers.Dense(fr_vocab_size, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 100, 128)          25728     \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 100, 128)          99072     \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 100, 256)          296448    \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (None, 100, 512)          1182720   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100, 1024)         525312    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100, 340)          348500    \n",
            "=================================================================\n",
            "Total params: 2,477,780\n",
            "Trainable params: 2,477,780\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvgWiu5UcWhw",
        "outputId": "f72aee54-3d4e-40d1-8472-ea8a81b4d03d"
      },
      "source": [
        "tmp_x = en_tokens_padded.reshape(\n",
        "   -1, 100, 1\n",
        ")\n",
        "tmp_x.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(137861, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpbN8rTBb9Qy",
        "outputId": "2de537b9-2da5-4e86-f317-18d8255b2f03"
      },
      "source": [
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(tmp_x, \n",
        "          fr_tokens_padded, \n",
        "          batch_size=1024, \n",
        "          epochs=10,\n",
        "          validation_split=0.2\n",
        ")\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "108/108 [==============================] - 120s 1s/step - loss: 0.5654 - accuracy: 0.8847 - val_loss: 0.4026 - val_accuracy: 0.9037\n",
            "Epoch 2/10\n",
            "108/108 [==============================] - 114s 1s/step - loss: 0.2972 - accuracy: 0.9215 - val_loss: 0.2309 - val_accuracy: 0.9368\n",
            "Epoch 3/10\n",
            "108/108 [==============================] - 115s 1s/step - loss: 0.1906 - accuracy: 0.9464 - val_loss: 0.1584 - val_accuracy: 0.9542\n",
            "Epoch 4/10\n",
            "108/108 [==============================] - 115s 1s/step - loss: 0.1360 - accuracy: 0.9603 - val_loss: 0.1181 - val_accuracy: 0.9650\n",
            "Epoch 5/10\n",
            "108/108 [==============================] - 115s 1s/step - loss: 0.1047 - accuracy: 0.9679 - val_loss: 0.0995 - val_accuracy: 0.9690\n",
            "Epoch 6/10\n",
            "108/108 [==============================] - 115s 1s/step - loss: 0.0873 - accuracy: 0.9723 - val_loss: 0.0810 - val_accuracy: 0.9744\n",
            "Epoch 7/10\n",
            "108/108 [==============================] - 115s 1s/step - loss: 0.0754 - accuracy: 0.9755 - val_loss: 0.0704 - val_accuracy: 0.9771\n",
            "Epoch 8/10\n",
            "108/108 [==============================] - 115s 1s/step - loss: 0.0675 - accuracy: 0.9778 - val_loss: 0.0647 - val_accuracy: 0.9787\n",
            "Epoch 9/10\n",
            "108/108 [==============================] - 115s 1s/step - loss: 0.0617 - accuracy: 0.9794 - val_loss: 0.0599 - val_accuracy: 0.9800\n",
            "Epoch 10/10\n",
            "108/108 [==============================] - 115s 1s/step - loss: 0.0569 - accuracy: 0.9807 - val_loss: 0.0555 - val_accuracy: 0.9816\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9021756210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVPSOGBSDpb8"
      },
      "source": [
        "The rest of the notebook will remain the same, I believe we can load the \n",
        "word pretrained word embeddings in our embedding layer as well, but that will be later on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kszwT1o-drRi"
      },
      "source": [
        "### Making some predictions.\n",
        "Our model is targeting to predict french words, during the predict function we are going to do the following:\n",
        "\n",
        "1. Get the sequence of the english sentence \n",
        "2. Pad the english sequences and pass them to the model'\n",
        "3. Reshape the logits output to the shape of `(max_len, trg_vocabsize(french)`\n",
        "4. Call the `logits_to_text` function and pass the tokenizer as the `fr_tokenizer`.\n",
        "5. Get the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "3iYsDDTzZzx0",
        "outputId": "93483f3b-90d9-40e1-e253-333e079732e3"
      },
      "source": [
        "def predict(sent):\n",
        "  sequences = en_text_to_seq(sent)\n",
        "  padded_tokens = pad_sequences([sequences], maxlen=max_words, padding=\"post\", truncating=\"post\")\n",
        "  logits = model(padded_tokens)\n",
        "  logits = tf.reshape(logits, (100, -1))\n",
        "  return logits_to_text(logits, fr_tokenizer)\n",
        "predict(\"your least liked fruit is the grape.\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'votre fruit aimÃ© des fruits la raisin raisin                                                                                            '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLbX_HGdwa9l"
      },
      "source": [
        "### Making more predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfsVPgfWqwsr"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "def tabulate_translations(column_names, data, title, max_characters=25):\n",
        "  table = PrettyTable(column_names)\n",
        "  table.title= title\n",
        "  table.align[column_names[0]] = 'l'\n",
        "  table.align[column_names[1]] = 'l'\n",
        "  table.align[column_names[2]] = 'l'\n",
        "  table._max_width = {column_names[0] :max_characters, column_names[1] :max_characters, column_names[2]:max_characters}\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)\n",
        "columns_names = [\n",
        "    \"English (real src sentence)\", \"French (the actual text)\", \"Translated (translated version)\"\n",
        "]\n",
        "title = \"ENGLISH TO FRENCH TRANSLATOR\""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YO1nrCJvxKXt",
        "outputId": "6aafddd3-b410-4cb3-b68c-57c3b7eb92c4"
      },
      "source": [
        "max_characters= 25\n",
        "total_translations= 10\n",
        "for i, (eng, fre) in enumerate(zip(eng_sents[:total_translations], fre_sents)):\n",
        "    rows_data = [[eng, fre, predict(eng)]]\n",
        "    if i + 1 != total_translations:\n",
        "      rows_data.append([\"-\" * max_characters, \"-\" * max_characters, \"-\" * max_characters ])\n",
        "    tabulate_translations(columns_names, rows_data, title, max_characters)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| new jersey is sometimes     | new jersey est parfois    | new jersey est parfois calme en |\n",
            "| quiet during autumn , and   | calme pendant l' automne  | l' de et automne et il est      |\n",
            "| it is snowy in april .      | , et il est neigeux en    | neigeux  en                     |\n",
            "|                             | avril .                   |                                 |\n",
            "| -------------------------   | ------------------------- | -------------------------       |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| the united states is        | les Ã©tats-unis est        | les Ã©tats unis est gÃ©nÃ©ralement |\n",
            "| usually chilly during july  | gÃ©nÃ©ralement froid en     | froid en juillet et il est fait |\n",
            "| , and it is usually         | juillet , et il gÃ¨le      | habituellement en mars          |\n",
            "| freezing in november .      | habituellement en         |                                 |\n",
            "|                             | novembre .                |                                 |\n",
            "| -------------------------   | ------------------------- | -------------------------       |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| california is usually quiet | california est            | californie est gÃ©nÃ©ralement     |\n",
            "| during march , and it is    | gÃ©nÃ©ralement calme en     | calme en mars et il est il      |\n",
            "| usually hot in june .       | mars , et il est          | habituellement habituellement   |\n",
            "|                             | gÃ©nÃ©ralement chaud en     | en juin en                      |\n",
            "|                             | juin .                    |                                 |\n",
            "| -------------------------   | ------------------------- | -------------------------       |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| the united states is        | les Ã©tats-unis est        | les Ã©tats unis est parfois doux |\n",
            "| sometimes mild during june  | parfois lÃ©gÃ¨re en juin ,  | en juin et il est fait froid en |\n",
            "| , and it is cold in         | et il fait froid en       | septembre                       |\n",
            "| september .                 | septembre .               |                                 |\n",
            "| -------------------------   | ------------------------- | -------------------------       |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| your least liked fruit is   | votre moins aimÃ© fruit    | votre fruit aimÃ© des fruits la  |\n",
            "| the grape , but my least    | est le raisin , mais mon  | raisin raisin mais mon moins    |\n",
            "| liked is the apple .        | moins aimÃ© est la pomme . | aimÃ© est la pomme mais          |\n",
            "| -------------------------   | ------------------------- | -------------------------       |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| his favorite fruit is the   | son fruit prÃ©fÃ©rÃ© est     | son fruit prÃ©fÃ©rÃ© est la mais   |\n",
            "| orange , but my favorite is | l'orange , mais mon       | favori est prÃ©fÃ©rÃ© est la       |\n",
            "| the grape .                 | prÃ©fÃ©rÃ© est le raisin .   | banane                          |\n",
            "| -------------------------   | ------------------------- | -------------------------       |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| paris is relaxing during    | paris est relaxant en     | paris est relaxant en dÃ©cembre  |\n",
            "| december , but it is        | dÃ©cembre , mais il est    | et il il est gÃ©nÃ©ralement froid |\n",
            "| usually chilly in july .    | gÃ©nÃ©ralement froid en     | en juillet froid                |\n",
            "|                             | juillet .                 |                                 |\n",
            "| -------------------------   | ------------------------- | -------------------------       |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| new jersey is busy during   | new jersey est occupÃ© au  | new jersey est occupÃ© en        |\n",
            "| spring , and it is never    | printemps , et il est     | printemps et il est et en chaud |\n",
            "| hot in march .              | jamais chaude en mars .   | en mars                         |\n",
            "| -------------------------   | ------------------------- | -------------------------       |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| our least liked fruit is    | notre fruit est moins     | notre fruit aimÃ© des fruits la  |\n",
            "| the lemon , but my least    | aimÃ© le citron , mais mon | citron fraise mais mon plus     |\n",
            "| liked is the grape .        | moins aimÃ© est le raisin  | aimÃ© est la raisin              |\n",
            "|                             | .                         |                                 |\n",
            "| -------------------------   | ------------------------- | -------------------------       |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| the united states is        | les Ã©tats-unis est        | les Ã©tats unis est parfois      |\n",
            "| sometimes busy during       | parfois occupÃ© en janvier | occupÃ© en janvier et il est     |\n",
            "| january , and it is         | , et il est parfois chaud | fait parfois chaud en novembre  |\n",
            "| sometimes warm in november  | en novembre .             |                                 |\n",
            "| .                           |                           |                                 |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkLm2D3MzNLb"
      },
      "source": [
        "### Conclusion.\n",
        "\n",
        "In this notebook we have leant how to create a simple GRU Sequential model that translate text from `eng` to french and we were able to get reasonable accuracy and better and reasonable translation at the end.\n",
        "\n",
        "### Next\n",
        "In the next Notebook we will have a look on how we can create a `BidirectionalLSTM` that will perform even better after training for few epochs than this current model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjYzfKS0zBZR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}