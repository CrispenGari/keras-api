{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_Simple_Encoder-Decoder-Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBEmZC70Drnk"
      },
      "source": [
        "### Simple `Encoder-Decoder` model.\n",
        "\n",
        "In the previous notebook  we covered much on how to create a simple `Bidirectional RNN` model that learns to translate text from english to french. In this notebook we are going to expand this even futher by make use of the `Encoder-Decoder` achitecture to perform the same task.\n",
        "\n",
        "### Encoder-Decoder\n",
        "\n",
        "This model is made up of an encoder and decoder. The encoder creates a matrix representation of the sentence. The decoder takes this matrix as input and predicts the translation as output.\n",
        "\n",
        "> Let's jump into the code\n",
        "\n",
        "**Note**: The rest of the notebook will remain the same, when there's a change i will highlight.\n",
        "\n",
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEGRciNODh3o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eeb175e7-733e-44cb-f5a6-2859ad51294c"
      },
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "import helper, os, time\n",
        "\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-6SXAJDHBHa"
      },
      "source": [
        "### Mounting the Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3C26uJADrWf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d27c59bd-8964-4939-c6d2-99d5815138f5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rc3hfXU7HZix"
      },
      "source": [
        "### Paths to the files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_690XgdzDrTz"
      },
      "source": [
        "base_path = '/content/drive/MyDrive/NLP Data/seq2seq/fr-en-small'\n",
        "en_path = 'small_vocab_en.txt'\n",
        "fr_path = 'small_vocab_fr.txt'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gltNO_9sH4B7"
      },
      "source": [
        "### Loading the data.\n",
        "\n",
        "We have two files that are located at this path `'/content/drive/MyDrive/NLP Data/seq2seq/fr-en-small'` and thes files are:\n",
        "\n",
        "```\n",
        "small_vocab_fr.txt\n",
        "small_vocab_en.txt\n",
        "```\n",
        "\n",
        "The following line help us to load the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "581k-VQpDrOY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbb3b361-ba2c-4daf-ab49-0f636a3a3845"
      },
      "source": [
        "eng_sents = open(os.path.join(base_path, en_path), encoding='utf8').read().split('\\n')\n",
        "fre_sents = open(os.path.join(base_path, fr_path), encoding='utf8').read().split('\\n')\n",
        "\n",
        "print(\"Data Loaded\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "EroZAWUvJneb",
        "outputId": "25a65ff7-5b00-4334-fe85-41da017ee0e0"
      },
      "source": [
        "eng_sents[1]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'the united states is usually chilly during july , and it is usually freezing in november .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzQHLHzDJwYB"
      },
      "source": [
        "By looking at the data we can see that the data is already preprocessed, which means we are not going to do that step here.\n",
        "\n",
        "### Next, Bulding the Vocabulary.\n",
        "\n",
        "Vocabulary in my definition is just unique words in the curpus. Let's look at the vocabulary size of french and english. But first we need to tokenize each sentence, Inorder for us to do that I'm going to use the `spacy` library which is my favourite when it comes to tokenization of languages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYdwgsDDDrIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac71bf9b-625b-4566-e74a-87703dc933a2"
      },
      "source": [
        "import spacy\n",
        "spacy.cli.download('fr_core_news_sm')\n",
        "\n",
        "spacy_fr = spacy.load('fr_core_news_sm')\n",
        "spacy_en = spacy.load('en_core_web_sm')\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em20rVNkDrFo"
      },
      "source": [
        "def tokenize_fr(sent):\n",
        "  return [tok.text for tok in spacy_fr.tokenizer(sent)]\n",
        "  \n",
        "def tokenize_en(sent):\n",
        "  return [tok.text for tok in spacy_en.tokenizer(sent)]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqbCQ512DrCi"
      },
      "source": [
        "en_counter = Counter()\n",
        "fr_counter = Counter()\n",
        "\n",
        "for sent in eng_sents:\n",
        "  en_counter.update(tokenize_en(sent.lower()))\n",
        "for sent in fre_sents:\n",
        "  fr_counter.update(tokenize_fr(sent.lower()))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq9JM8HIL6RT",
        "outputId": "53bb0feb-f934-4b72-caa8-c83fca1a96ba"
      },
      "source": [
        "en_vocab_size = len(en_counter)\n",
        "fr_vocab_size = len(fr_counter)\n",
        "\n",
        "fr_vocab_size, en_vocab_size"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(340, 201)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4n7K3LsMWW8"
      },
      "source": [
        "Here we have `340` unique words for french in this dataset and `201` unique words for english.\n",
        "\n",
        "### Preprocessing.\n",
        "\n",
        "We will convert our text data into sequence of integers so basically we are going to perform the following:\n",
        "\n",
        "1. Tokenize the words into ids\n",
        "2. Pad the tokens so that they will have same length.\n",
        "\n",
        "For this task we are going to use the keras `Tokenizer` class to perform the task, We have been using this for sentiment analyisis so the procedure is the same.\n",
        "\n",
        "We are going to have two tokenizers for each language.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_JJVUlADq_q"
      },
      "source": [
        "en_tokenizer = Tokenizer(num_words=en_vocab_size, oov_token=\"<oov>\")\n",
        "en_tokenizer.fit_on_texts(eng_sents)\n",
        "\n",
        "fr_tokenizer = Tokenizer(num_words=fr_vocab_size, oov_token=\"<oov>\")\n",
        "fr_tokenizer.fit_on_texts(fre_sents)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1EScuA6T1Nx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APoyIFAiDq7x"
      },
      "source": [
        "en_word_indices = en_tokenizer.word_index\n",
        "en_word_indices_reversed = dict([\n",
        "    (v, k) for (k, v) in en_word_indices.items()\n",
        "])\n",
        "\n",
        "fr_word_indices = fr_tokenizer.word_index\n",
        "fr_word_indices_reversed = dict([\n",
        "    (v, k) for (k, v) in fr_word_indices.items()\n",
        "])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "An7_ADx7Olap"
      },
      "source": [
        "### Helper functions\n",
        "We will create some helper function that converts sequences to text and text to sequences for each language. These function will be used for inference later on.\n",
        "\n",
        "**We have set the out of vocabulary `oov_token|| <\"oov\">`token to `1`  which means the word that does not exist in the vocabulary it's integer representation is 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDQsSkoAOlBS"
      },
      "source": [
        "def en_seq_to_text(sequences):\n",
        "  return \" \".join(en_word_indices_reversed[i] for i in sequences )\n",
        "\n",
        "def en_seq_to_text(sequences):\n",
        "  return \" \".join(fr_word_indices_reversed[i] for i in sequences )\n",
        "\n",
        "def en_text_to_seq(sent):\n",
        "  words = tokenize_en(sent.lower())\n",
        "  sequences = []\n",
        "  for word in words:\n",
        "    try:\n",
        "      sequences.append(en_word_indices[word])\n",
        "    except:\n",
        "      sequences.append(1)\n",
        "  return sequences\n",
        "\n",
        "def fr_text_to_seq(sent):\n",
        "  words = tokenize_fr(sent.lower())\n",
        "  sequences = []\n",
        "  for word in words:\n",
        "    try:\n",
        "      sequences.append(fr_word_indices[word])\n",
        "    except:\n",
        "      sequences.append(1)\n",
        "  return sequences"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwvQ_uFHTTBK"
      },
      "source": [
        "### Converting text to sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nspRxCCTSUs"
      },
      "source": [
        "en_sequences = en_tokenizer.texts_to_sequences(eng_sents)\n",
        "fr_sequences = fr_tokenizer.texts_to_sequences(fre_sents)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnbY97HGUrGP",
        "outputId": "1858fb40-6abe-4cce-e416-3ef97e580bf1"
      },
      "source": [
        "fr_sequences[0:4]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[36, 35, 2, 9, 68, 38, 12, 25, 7, 4, 2, 113, 3, 51],\n",
              " [5, 33, 32, 2, 13, 20, 3, 50, 7, 4, 96, 70, 3, 52],\n",
              " [102, 2, 13, 68, 3, 46, 7, 4, 2, 13, 22, 3, 42],\n",
              " [5, 33, 32, 2, 9, 270, 3, 42, 7, 4, 104, 20, 3, 49]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKF4CdRUQJCy"
      },
      "source": [
        "### Padding Sequences.\n",
        "\n",
        "In our case we are going to assume that the longest sentence has `100` words for both `fr` and `en` languages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhkhdZ-8QI4F"
      },
      "source": [
        "max_words = 100\n",
        "en_tokens_padded = pad_sequences(\n",
        "    en_sequences, \n",
        "    maxlen=max_words, \n",
        "    padding=\"post\", \n",
        "    truncating=\"post\"\n",
        ")\n",
        "fr_tokens_padded = pad_sequences(\n",
        "    fr_sequences, \n",
        "    maxlen=max_words, \n",
        "    padding=\"post\", \n",
        "    truncating=\"post\"\n",
        ")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHomR9cmDq2s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93115367-beb7-4ca2-9e7b-7a648d4f73b1"
      },
      "source": [
        "en_tokens_padded[:2]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[18, 24,  2,  9, 68,  5, 40,  8,  4,  2, 56,  3, 45,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0],\n",
              "       [ 6, 21, 22,  2, 10, 63,  5, 44,  8,  4,  2, 10, 52,  3, 46,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FJ69jNAVOnT"
      },
      "source": [
        "### Logits to text.\n",
        "\n",
        "We are going to create 1 more helper function that will help us to take logits or the predictions probabilities and then we convert them to human understandable format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDlG7MzYVvi2"
      },
      "source": [
        "def logits_to_text(logits, tokenizer):\n",
        "  index_to_words = {id: word for word, id\n",
        "                    in tokenizer.word_index.items()}\n",
        "  index_to_words[0] = '<pad>'\n",
        "  \"\"\"\n",
        "  For every prediction we are going to ignore the pad token\n",
        "  \"\"\"\n",
        "  return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)]).replace(\"<pad>\", \"\")\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moeeDvRxYQhd"
      },
      "source": [
        "### Encoder Decoder Model.\n",
        "The following cell shows how we can create our very simple encoder decoder model using the sequential API.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTvuC7kQYMcU",
        "outputId": "97d72ed7-a22e-4b31-b6ed-65dde9823fa9"
      },
      "source": [
        "input_shape = (None, 100, 1)\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Embedding(\n",
        "        en_vocab_size,\n",
        "        128, \n",
        "        input_length=max_words\n",
        "    ),\n",
        "    keras.layers.GRU(128, return_sequences=True),\n",
        "    keras.layers.GRU(128, return_sequences=False),\n",
        "    keras.layers.RepeatVector(max_words),\n",
        "    keras.layers.GRU(128, return_sequences=True),\n",
        "    keras.layers.GRU(128, return_sequences=True),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(\n",
        "        fr_vocab_size, activation= \"softmax\"\n",
        "    ))   \n",
        "], name=\"encoder_decoder_model\")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder_decoder_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 100, 128)          25728     \n",
            "_________________________________________________________________\n",
            "gru_21 (GRU)                 (None, 100, 128)          99072     \n",
            "_________________________________________________________________\n",
            "gru_22 (GRU)                 (None, 128)               99072     \n",
            "_________________________________________________________________\n",
            "repeat_vector_8 (RepeatVecto (None, 100, 128)          0         \n",
            "_________________________________________________________________\n",
            "gru_23 (GRU)                 (None, 100, 128)          99072     \n",
            "_________________________________________________________________\n",
            "gru_24 (GRU)                 (None, 100, 128)          99072     \n",
            "_________________________________________________________________\n",
            "time_distributed_10 (TimeDis (None, 100, 340)          43860     \n",
            "=================================================================\n",
            "Total params: 465,876\n",
            "Trainable params: 465,876\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvgWiu5UcWhw",
        "outputId": "85bc7a6d-fe3d-4416-876c-57ce55c0f6c4"
      },
      "source": [
        "tmp_x = en_tokens_padded.reshape(\n",
        "   -1, 100, 1\n",
        ")\n",
        "tmp_x.shape"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(137861, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpbN8rTBb9Qy",
        "outputId": "79e39f01-b33b-4802-9607-9ed68b93fe86"
      },
      "source": [
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(tmp_x, \n",
        "          fr_tokens_padded, \n",
        "          batch_size=1024, \n",
        "          epochs=15,\n",
        "          validation_split=0.2\n",
        ")\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "108/108 [==============================] - 35s 287ms/step - loss: 0.3836 - accuracy: 0.9072 - val_loss: 0.3669 - val_accuracy: 0.9099\n",
            "Epoch 2/15\n",
            "108/108 [==============================] - 30s 280ms/step - loss: 0.3626 - accuracy: 0.9101 - val_loss: 0.3577 - val_accuracy: 0.9108\n",
            "Epoch 3/15\n",
            "108/108 [==============================] - 30s 280ms/step - loss: 0.3543 - accuracy: 0.9110 - val_loss: 0.3497 - val_accuracy: 0.9118\n",
            "Epoch 4/15\n",
            "108/108 [==============================] - 30s 280ms/step - loss: 0.3470 - accuracy: 0.9119 - val_loss: 0.3445 - val_accuracy: 0.9123\n",
            "Epoch 5/15\n",
            "108/108 [==============================] - 30s 281ms/step - loss: 0.3409 - accuracy: 0.9124 - val_loss: 0.3417 - val_accuracy: 0.9122\n",
            "Epoch 6/15\n",
            "108/108 [==============================] - 30s 282ms/step - loss: 0.3315 - accuracy: 0.9136 - val_loss: 0.3213 - val_accuracy: 0.9151\n",
            "Epoch 7/15\n",
            "108/108 [==============================] - 30s 282ms/step - loss: 0.2975 - accuracy: 0.9190 - val_loss: 0.2780 - val_accuracy: 0.9216\n",
            "Epoch 8/15\n",
            "108/108 [==============================] - 30s 281ms/step - loss: 0.2695 - accuracy: 0.9239 - val_loss: 0.2602 - val_accuracy: 0.9259\n",
            "Epoch 9/15\n",
            "108/108 [==============================] - 30s 281ms/step - loss: 0.2535 - accuracy: 0.9275 - val_loss: 0.2460 - val_accuracy: 0.9289\n",
            "Epoch 10/15\n",
            "108/108 [==============================] - 30s 281ms/step - loss: 0.2404 - accuracy: 0.9307 - val_loss: 0.2333 - val_accuracy: 0.9322\n",
            "Epoch 11/15\n",
            "108/108 [==============================] - 30s 281ms/step - loss: 0.2300 - accuracy: 0.9327 - val_loss: 0.2258 - val_accuracy: 0.9336\n",
            "Epoch 12/15\n",
            "108/108 [==============================] - 30s 281ms/step - loss: 0.2219 - accuracy: 0.9347 - val_loss: 0.2185 - val_accuracy: 0.9359\n",
            "Epoch 13/15\n",
            "108/108 [==============================] - 30s 280ms/step - loss: 0.2143 - accuracy: 0.9373 - val_loss: 0.2095 - val_accuracy: 0.9388\n",
            "Epoch 14/15\n",
            "108/108 [==============================] - 30s 279ms/step - loss: 0.2069 - accuracy: 0.9394 - val_loss: 0.2031 - val_accuracy: 0.9404\n",
            "Epoch 15/15\n",
            "108/108 [==============================] - 30s 279ms/step - loss: 0.2013 - accuracy: 0.9408 - val_loss: 0.1995 - val_accuracy: 0.9411\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd88419a9d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVPSOGBSDpb8"
      },
      "source": [
        "The rest of the notebook will remain the same.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kszwT1o-drRi"
      },
      "source": [
        "### Making some predictions.\n",
        "Our model is targeting to predict french words, during the predict function we are going to do the following:\n",
        "\n",
        "1. Get the sequence of the english sentence \n",
        "2. Pad the english sequences and pass them to the model'\n",
        "3. Reshape the logits output to the shape of `(max_len, trg_vocabsize(french)`\n",
        "4. Call the `logits_to_text` function and pass the tokenizer as the `fr_tokenizer`.\n",
        "5. Get the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3iYsDDTzZzx0",
        "outputId": "da8d65f3-4ffb-449f-8bb9-8b680d6835f2"
      },
      "source": [
        "def predict(sent):\n",
        "  sequences = en_text_to_seq(sent)\n",
        "  padded_tokens = pad_sequences([sequences], maxlen=max_words, padding=\"post\", truncating=\"post\")\n",
        "  logits = model(padded_tokens)\n",
        "  logits = tf.reshape(logits, (100, -1))\n",
        "  return logits_to_text(logits, fr_tokenizer)\n",
        "predict(\"your least liked fruit is the grape.\")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"son fruit préféré est l'orange mais la est                                                                                            \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLbX_HGdwa9l"
      },
      "source": [
        "### Making more predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfsVPgfWqwsr"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "def tabulate_translations(column_names, data, title, max_characters=25):\n",
        "  table = PrettyTable(column_names)\n",
        "  table.title= title\n",
        "  table.align[column_names[0]] = 'l'\n",
        "  table.align[column_names[1]] = 'l'\n",
        "  table.align[column_names[2]] = 'l'\n",
        "  table._max_width = {column_names[0] :max_characters, column_names[1] :max_characters, column_names[2]:max_characters}\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)\n",
        "columns_names = [\n",
        "    \"English (real src sentence)\", \"French (the actual text)\", \"Translated (translated version)\"\n",
        "]\n",
        "title = \"ENGLISH TO FRENCH TRANSLATOR\""
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YO1nrCJvxKXt",
        "outputId": "3349f0d3-bd6f-4508-e4cc-50ceffc57d74"
      },
      "source": [
        "max_characters= 25\n",
        "total_translations= 10\n",
        "for i, (eng, fre) in enumerate(zip(eng_sents[:total_translations], fre_sents)):\n",
        "    rows_data = [[eng, fre, predict(eng)]]\n",
        "    tabulate_translations(columns_names, rows_data, title, max_characters)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| new jersey is sometimes     | new jersey est parfois    | new jersey est jamais chaud au  |\n",
            "| quiet during autumn , and   | calme pendant l' automne  | l' de il il est agréable en     |\n",
            "| it is snowy in april .      | , et il est neigeux en    | novembre                        |\n",
            "|                             | avril .                   |                                 |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| the united states is        | les états-unis est        | les états unis est parfois      |\n",
            "| usually chilly during july  | généralement froid en     | agréable en printemps mais il   |\n",
            "| , and it is usually         | juillet , et il gèle      | est jamais en en                |\n",
            "| freezing in november .      | habituellement en         |                                 |\n",
            "|                             | novembre .                |                                 |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| california is usually quiet | california est            | californie est jamais chaud en  |\n",
            "| during march , and it is    | généralement calme en     | mois mais il est jamais est en  |\n",
            "| usually hot in june .       | mars , et il est          | en                              |\n",
            "|                             | généralement chaud en     |                                 |\n",
            "|                             | juin .                    |                                 |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| the united states is        | les états-unis est        | les états unis est parfois      |\n",
            "| sometimes mild during june  | parfois légère en juin ,  | agréable en juillet et il est   |\n",
            "| , and it is cold in         | et il fait froid en       | agréable en l'                  |\n",
            "| september .                 | septembre .               |                                 |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| your least liked fruit is   | votre moins aimé fruit    | son fruit est moins aimé la la  |\n",
            "| the grape , but my least    | est le raisin , mais mon  | mais son moins aimé est la la   |\n",
            "| liked is the apple .        | moins aimé est la pomme . |                                 |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| his favorite fruit is the   | son fruit préféré est     | son fruit préféré est la        |\n",
            "| orange , but my favorite is | l'orange , mais mon       | l'orange mais son moins préféré |\n",
            "| the grape .                 | préféré est le raisin .   | est la                          |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| paris is relaxing during    | paris est relaxant en     | paris est parfois au en de et   |\n",
            "| december , but it is        | décembre , mais il est    | il est parfois chaud en l'      |\n",
            "| usually chilly in july .    | généralement froid en     |                                 |\n",
            "|                             | juillet .                 |                                 |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| new jersey is busy during   | new jersey est occupé au  | new jersey est généralement en  |\n",
            "| spring , and it is never    | printemps , et il est     | en et il est est est en en      |\n",
            "| hot in march .              | jamais chaude en mars .   |                                 |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| our least liked fruit is    | notre fruit est moins     | son fruit est moins aimé la la  |\n",
            "| the lemon , but my least    | aimé le citron , mais mon | mais son moins aimé est la la   |\n",
            "| liked is the grape .        | moins aimé est le raisin  |                                 |\n",
            "|                             | .                         |                                 |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| the united states is        | les états-unis est        | les états unis est parfois      |\n",
            "| sometimes busy during       | parfois occupé en janvier | agréable en printemps mais il   |\n",
            "| january , and it is         | , et il est parfois chaud | est parfois chaud en l'         |\n",
            "| sometimes warm in november  | en novembre .             |                                 |\n",
            "| .                           |                           |                                 |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkLm2D3MzNLb"
      },
      "source": [
        "### Conclusion.\n",
        "In this notebook we have learnt how to create a simple Encoder Decoder model and we trained our model and get a resonable accuracy of `~93%`. What's next?\n",
        "\n",
        "### Next\n",
        "In the next notebook we will combine all these three notebooks by creating a `spanish-to-english` translator model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjYzfKS0zBZR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}