{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_Simple_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBEmZC70Drnk"
      },
      "source": [
        "### Simple RNN\n",
        "\n",
        "In the previous Notebook we have leant how we can load and preprocess the data. In this notebook we are going to expand and create a simple `RNN` that will be able to train on our preprocessed data from the previous notebook.\n",
        "\n",
        "**Note**: The rest of the notebook will remain the same, when there's a change i will highlight.\n",
        "\n",
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEGRciNODh3o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "22d54a03-28b9-4170-eb97-bedeb0498a35"
      },
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "import helper, os, time\n",
        "\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-6SXAJDHBHa"
      },
      "source": [
        "### Mounting the Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3C26uJADrWf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "965ae0c8-4516-4e06-fba5-3a3948616c6c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rc3hfXU7HZix"
      },
      "source": [
        "### Paths to the files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_690XgdzDrTz"
      },
      "source": [
        "base_path = '/content/drive/MyDrive/NLP Data/seq2seq/fr-en-small'\n",
        "en_path = 'small_vocab_en.txt'\n",
        "fr_path = 'small_vocab_fr.txt'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gltNO_9sH4B7"
      },
      "source": [
        "### Loading the data.\n",
        "\n",
        "We have two files that are located at this path `'/content/drive/MyDrive/NLP Data/seq2seq/fr-en-small'` and thes files are:\n",
        "\n",
        "```\n",
        "small_vocab_fr.txt\n",
        "small_vocab_en.txt\n",
        "```\n",
        "\n",
        "The following line help us to load the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "581k-VQpDrOY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8db01803-0789-4bcd-c56a-f618961907fe"
      },
      "source": [
        "eng_sents = open(os.path.join(base_path, en_path), encoding='utf8').read().split('\\n')\n",
        "fre_sents = open(os.path.join(base_path, fr_path), encoding='utf8').read().split('\\n')\n",
        "\n",
        "print(\"Data Loaded\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EroZAWUvJneb",
        "outputId": "258afcfe-3855-41c4-a7eb-6ad16530df42"
      },
      "source": [
        "eng_sents[1]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'the united states is usually chilly during july , and it is usually freezing in november .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzQHLHzDJwYB"
      },
      "source": [
        "By looking at the data we can see that the data is already preprocessed, which means we are not going to do that step here.\n",
        "\n",
        "### Next, Bulding the Vocabulary.\n",
        "\n",
        "Vocabulary in my definition is just unique words in the curpus. Let's look at the vocabulary size of french and english. But first we need to tokenize each sentence, Inorder for us to do that I'm going to use the `spacy` library which is my favourite when it comes to tokenization of languages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYdwgsDDDrIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4e66809-958c-4362-dc91-cde91750d724"
      },
      "source": [
        "import spacy\n",
        "spacy.cli.download('fr_core_news_sm')\n",
        "\n",
        "spacy_fr = spacy.load('fr_core_news_sm')\n",
        "spacy_en = spacy.load('en_core_web_sm')\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em20rVNkDrFo"
      },
      "source": [
        "def tokenize_fr(sent):\n",
        "  return [tok.text for tok in spacy_fr.tokenizer(sent)]\n",
        "  \n",
        "def tokenize_en(sent):\n",
        "  return [tok.text for tok in spacy_en.tokenizer(sent)]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqbCQ512DrCi"
      },
      "source": [
        "en_counter = Counter()\n",
        "fr_counter = Counter()\n",
        "\n",
        "for sent in eng_sents:\n",
        "  en_counter.update(tokenize_en(sent.lower()))\n",
        "for sent in fre_sents:\n",
        "  fr_counter.update(tokenize_fr(sent.lower()))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq9JM8HIL6RT",
        "outputId": "627d75db-3b2e-4d62-9d65-bdfa248ea742"
      },
      "source": [
        "en_vocab_size = len(en_counter)\n",
        "fr_vocab_size = len(fr_counter)\n",
        "\n",
        "fr_vocab_size, en_vocab_size"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(340, 201)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4n7K3LsMWW8"
      },
      "source": [
        "Here we have `340` unique words for french in this dataset and `201` unique words for english.\n",
        "\n",
        "### Preprocessing.\n",
        "\n",
        "We will convert our text data into sequence of integers so basically we are going to perform the following:\n",
        "\n",
        "1. Tokenize the words into ids\n",
        "2. Pad the tokens so that they will have same length.\n",
        "\n",
        "For this task we are going to use the keras `Tokenizer` class to perform the task, We have been using this for sentiment analyisis so the procedure is the same.\n",
        "\n",
        "We are going to have two tokenizers for each language.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_JJVUlADq_q"
      },
      "source": [
        "en_tokenizer = Tokenizer(num_words=en_vocab_size, oov_token=\"<oov>\")\n",
        "en_tokenizer.fit_on_texts(eng_sents)\n",
        "\n",
        "fr_tokenizer = Tokenizer(num_words=fr_vocab_size, oov_token=\"<oov>\")\n",
        "fr_tokenizer.fit_on_texts(fre_sents)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1EScuA6T1Nx"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APoyIFAiDq7x"
      },
      "source": [
        "en_word_indices = en_tokenizer.word_index\n",
        "en_word_indices_reversed = dict([\n",
        "    (v, k) for (k, v) in en_word_indices.items()\n",
        "])\n",
        "\n",
        "fr_word_indices = fr_tokenizer.word_index\n",
        "fr_word_indices_reversed = dict([\n",
        "    (v, k) for (k, v) in fr_word_indices.items()\n",
        "])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "An7_ADx7Olap"
      },
      "source": [
        "### Helper functions\n",
        "We will create some helper function that converts sequences to text and text to sequences for each language. These function will be used for inference later on.\n",
        "\n",
        "**We have set the out of vocabulary `oov_token|| <\"oov\">`token to `1`  which means the word that does not exist in the vocabulary it's integer representation is 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDQsSkoAOlBS"
      },
      "source": [
        "def en_seq_to_text(sequences):\n",
        "  return \" \".join(en_word_indices_reversed[i] for i in sequences )\n",
        "\n",
        "def en_seq_to_text(sequences):\n",
        "  return \" \".join(fr_word_indices_reversed[i] for i in sequences )\n",
        "\n",
        "def en_text_to_seq(sent):\n",
        "  words = tokenize_en(sent.lower())\n",
        "  sequences = []\n",
        "  for word in words:\n",
        "    try:\n",
        "      sequences.append(en_word_indices[word])\n",
        "    except:\n",
        "      sequences.append(1)\n",
        "  return sequences\n",
        "\n",
        "def fr_text_to_seq(sent):\n",
        "  words = tokenize_fr(sent.lower())\n",
        "  sequences = []\n",
        "  for word in words:\n",
        "    try:\n",
        "      sequences.append(fr_word_indices[word])\n",
        "    except:\n",
        "      sequences.append(1)\n",
        "  return sequences"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwvQ_uFHTTBK"
      },
      "source": [
        "### Converting text to sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nspRxCCTSUs"
      },
      "source": [
        "en_sequences = en_tokenizer.texts_to_sequences(eng_sents)\n",
        "fr_sequences = fr_tokenizer.texts_to_sequences(fre_sents)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnbY97HGUrGP",
        "outputId": "39532197-1a96-4c6f-b5ad-18c4b3ec752c"
      },
      "source": [
        "fr_sequences[0:4]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[36, 35, 2, 9, 68, 38, 12, 25, 7, 4, 2, 113, 3, 51],\n",
              " [5, 33, 32, 2, 13, 20, 3, 50, 7, 4, 96, 70, 3, 52],\n",
              " [102, 2, 13, 68, 3, 46, 7, 4, 2, 13, 22, 3, 42],\n",
              " [5, 33, 32, 2, 9, 270, 3, 42, 7, 4, 104, 20, 3, 49]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKF4CdRUQJCy"
      },
      "source": [
        "### Padding Sequences.\n",
        "\n",
        "In our case we are going to assume that the longest sentence has `100` words for both `fr` and `en` languages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhkhdZ-8QI4F"
      },
      "source": [
        "max_words = 100\n",
        "en_tokens_padded = pad_sequences(\n",
        "    en_sequences, \n",
        "    maxlen=max_words, \n",
        "    padding=\"post\", \n",
        "    truncating=\"post\"\n",
        ")\n",
        "fr_tokens_padded = pad_sequences(\n",
        "    fr_sequences, \n",
        "    maxlen=max_words, \n",
        "    padding=\"post\", \n",
        "    truncating=\"post\"\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHomR9cmDq2s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65fefdab-e64d-44b4-a3ea-38aee034a3fe"
      },
      "source": [
        "en_tokens_padded[:2]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[18, 24,  2,  9, 68,  5, 40,  8,  4,  2, 56,  3, 45,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0],\n",
              "       [ 6, 21, 22,  2, 10, 63,  5, 44,  8,  4,  2, 10, 52,  3, 46,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FJ69jNAVOnT"
      },
      "source": [
        "### Logits to text.\n",
        "\n",
        "We are going to create 1 more helper function that will help us to take logits or the predictions probabilities and then we convert them to human understandable format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDlG7MzYVvi2"
      },
      "source": [
        "\n",
        "def logits_to_text(logits, tokenizer):\n",
        "  index_to_words = {id: word for word, id\n",
        "                    in tokenizer.word_index.items()}\n",
        "  index_to_words[0] = '<pad>'\n",
        "  \"\"\"\n",
        "  For every prediction we are going to ignore the pad token\n",
        "  \"\"\"\n",
        "  return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)]).replace(\"<pad>\", \"\")\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moeeDvRxYQhd"
      },
      "source": [
        "### RNN\n",
        "\n",
        "This is a simple RNN that will learn to translate english sentences to french.\n",
        "\n",
        "![img](https://github.com/LeanManager/Machine_Translation/raw/e6567f10a6e380eea453fa392de94f26973c8b16/images/rnn.png)\n",
        "\n",
        "We are going to use the Functional API to build this toy model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTvuC7kQYMcU",
        "outputId": "92b98fcd-7172-4f0e-b5ee-91132963b943"
      },
      "source": [
        "inp = keras.layers.Input(shape=(max_words, 1 )) # 100, 1\n",
        "rnn = keras.layers.GRU(64, return_sequences=True)(inp)\n",
        "logits = keras.layers.TimeDistributed(keras.layers.Dense(fr_vocab_size, activation=\"softmax\" ))(rnn);\n",
        "\n",
        "model = keras.Model(inputs=inp, outputs=logits, name=\"simple_rnn\")\n",
        "model.summary()\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"simple_rnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 100, 1)]          0         \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 100, 64)           12864     \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 100, 340)          22100     \n",
            "=================================================================\n",
            "Total params: 34,964\n",
            "Trainable params: 34,964\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvgWiu5UcWhw",
        "outputId": "20ab3d0b-a346-4bae-f51b-efbb8d3f091d"
      },
      "source": [
        "tmp_x = en_tokens_padded.reshape(\n",
        "   -1, 100, 1\n",
        ")\n",
        "tmp_x.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(137861, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpbN8rTBb9Qy",
        "outputId": "6743563d-eb24-4c14-b9c0-49ca927ecb30"
      },
      "source": [
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(tmp_x, \n",
        "          fr_tokens_padded, \n",
        "          batch_size=1024, \n",
        "          epochs=50,\n",
        "          validation_split=0.2\n",
        ")\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "108/108 [==============================] - 9s 62ms/step - loss: 2.0551 - accuracy: 0.8757 - val_loss: 0.5693 - val_accuracy: 0.8857\n",
            "Epoch 2/50\n",
            "108/108 [==============================] - 6s 58ms/step - loss: 0.5494 - accuracy: 0.8869 - val_loss: 0.5320 - val_accuracy: 0.8886\n",
            "Epoch 3/50\n",
            "108/108 [==============================] - 6s 58ms/step - loss: 0.5186 - accuracy: 0.8893 - val_loss: 0.5036 - val_accuracy: 0.8915\n",
            "Epoch 4/50\n",
            "108/108 [==============================] - 6s 59ms/step - loss: 0.4903 - accuracy: 0.8928 - val_loss: 0.4757 - val_accuracy: 0.8937\n",
            "Epoch 5/50\n",
            "108/108 [==============================] - 6s 59ms/step - loss: 0.4619 - accuracy: 0.8957 - val_loss: 0.4471 - val_accuracy: 0.8994\n",
            "Epoch 6/50\n",
            "108/108 [==============================] - 6s 59ms/step - loss: 0.4329 - accuracy: 0.9022 - val_loss: 0.4181 - val_accuracy: 0.9047\n",
            "Epoch 7/50\n",
            "108/108 [==============================] - 6s 59ms/step - loss: 0.4054 - accuracy: 0.9073 - val_loss: 0.3933 - val_accuracy: 0.9088\n",
            "Epoch 8/50\n",
            "108/108 [==============================] - 6s 59ms/step - loss: 0.3841 - accuracy: 0.9096 - val_loss: 0.3754 - val_accuracy: 0.9108\n",
            "Epoch 9/50\n",
            "108/108 [==============================] - 6s 59ms/step - loss: 0.3686 - accuracy: 0.9113 - val_loss: 0.3621 - val_accuracy: 0.9123\n",
            "Epoch 10/50\n",
            "108/108 [==============================] - 6s 59ms/step - loss: 0.3569 - accuracy: 0.9125 - val_loss: 0.3518 - val_accuracy: 0.9131\n",
            "Epoch 11/50\n",
            "108/108 [==============================] - 6s 59ms/step - loss: 0.3475 - accuracy: 0.9134 - val_loss: 0.3431 - val_accuracy: 0.9143\n",
            "Epoch 12/50\n",
            "108/108 [==============================] - 6s 59ms/step - loss: 0.3394 - accuracy: 0.9142 - val_loss: 0.3355 - val_accuracy: 0.9148\n",
            "Epoch 13/50\n",
            "108/108 [==============================] - 6s 59ms/step - loss: 0.3321 - accuracy: 0.9150 - val_loss: 0.3286 - val_accuracy: 0.9156\n",
            "Epoch 14/50\n",
            "108/108 [==============================] - 6s 59ms/step - loss: 0.3255 - accuracy: 0.9158 - val_loss: 0.3222 - val_accuracy: 0.9162\n",
            "Epoch 15/50\n",
            "108/108 [==============================] - 6s 60ms/step - loss: 0.3192 - accuracy: 0.9165 - val_loss: 0.3161 - val_accuracy: 0.9169\n",
            "Epoch 16/50\n",
            "108/108 [==============================] - 6s 60ms/step - loss: 0.3133 - accuracy: 0.9171 - val_loss: 0.3104 - val_accuracy: 0.9173\n",
            "Epoch 17/50\n",
            "108/108 [==============================] - 6s 60ms/step - loss: 0.3077 - accuracy: 0.9184 - val_loss: 0.3049 - val_accuracy: 0.9195\n",
            "Epoch 18/50\n",
            "108/108 [==============================] - 7s 60ms/step - loss: 0.3023 - accuracy: 0.9200 - val_loss: 0.2997 - val_accuracy: 0.9201\n",
            "Epoch 19/50\n",
            "108/108 [==============================] - 6s 60ms/step - loss: 0.2972 - accuracy: 0.9211 - val_loss: 0.2947 - val_accuracy: 0.9219\n",
            "Epoch 20/50\n",
            "108/108 [==============================] - 6s 60ms/step - loss: 0.2922 - accuracy: 0.9222 - val_loss: 0.2899 - val_accuracy: 0.9225\n",
            "Epoch 21/50\n",
            "108/108 [==============================] - 6s 60ms/step - loss: 0.2876 - accuracy: 0.9230 - val_loss: 0.2855 - val_accuracy: 0.9230\n",
            "Epoch 22/50\n",
            "108/108 [==============================] - 6s 60ms/step - loss: 0.2834 - accuracy: 0.9237 - val_loss: 0.2814 - val_accuracy: 0.9242\n",
            "Epoch 23/50\n",
            "108/108 [==============================] - 6s 60ms/step - loss: 0.2795 - accuracy: 0.9242 - val_loss: 0.2777 - val_accuracy: 0.9243\n",
            "Epoch 24/50\n",
            "108/108 [==============================] - 6s 60ms/step - loss: 0.2761 - accuracy: 0.9245 - val_loss: 0.2743 - val_accuracy: 0.9248\n",
            "Epoch 25/50\n",
            "108/108 [==============================] - 6s 60ms/step - loss: 0.2728 - accuracy: 0.9249 - val_loss: 0.2713 - val_accuracy: 0.9250\n",
            "Epoch 26/50\n",
            "108/108 [==============================] - 7s 60ms/step - loss: 0.2698 - accuracy: 0.9252 - val_loss: 0.2684 - val_accuracy: 0.9255\n",
            "Epoch 27/50\n",
            "108/108 [==============================] - 7s 60ms/step - loss: 0.2670 - accuracy: 0.9257 - val_loss: 0.2656 - val_accuracy: 0.9258\n",
            "Epoch 28/50\n",
            "108/108 [==============================] - 7s 60ms/step - loss: 0.2643 - accuracy: 0.9260 - val_loss: 0.2630 - val_accuracy: 0.9259\n",
            "Epoch 29/50\n",
            "108/108 [==============================] - 7s 60ms/step - loss: 0.2619 - accuracy: 0.9262 - val_loss: 0.2606 - val_accuracy: 0.9260\n",
            "Epoch 30/50\n",
            "108/108 [==============================] - 6s 60ms/step - loss: 0.2596 - accuracy: 0.9267 - val_loss: 0.2583 - val_accuracy: 0.9274\n",
            "Epoch 31/50\n",
            "108/108 [==============================] - 7s 61ms/step - loss: 0.2574 - accuracy: 0.9269 - val_loss: 0.2563 - val_accuracy: 0.9265\n",
            "Epoch 32/50\n",
            "108/108 [==============================] - 7s 61ms/step - loss: 0.2554 - accuracy: 0.9271 - val_loss: 0.2545 - val_accuracy: 0.9268\n",
            "Epoch 33/50\n",
            "108/108 [==============================] - 7s 61ms/step - loss: 0.2536 - accuracy: 0.9275 - val_loss: 0.2526 - val_accuracy: 0.9270\n",
            "Epoch 34/50\n",
            "108/108 [==============================] - 7s 61ms/step - loss: 0.2518 - accuracy: 0.9274 - val_loss: 0.2508 - val_accuracy: 0.9274\n",
            "Epoch 35/50\n",
            "108/108 [==============================] - 7s 61ms/step - loss: 0.2501 - accuracy: 0.9276 - val_loss: 0.2491 - val_accuracy: 0.9282\n",
            "Epoch 36/50\n",
            "108/108 [==============================] - 7s 60ms/step - loss: 0.2485 - accuracy: 0.9278 - val_loss: 0.2476 - val_accuracy: 0.9275\n",
            "Epoch 37/50\n",
            "108/108 [==============================] - 6s 60ms/step - loss: 0.2470 - accuracy: 0.9278 - val_loss: 0.2460 - val_accuracy: 0.9275\n",
            "Epoch 38/50\n",
            "108/108 [==============================] - 6s 60ms/step - loss: 0.2454 - accuracy: 0.9279 - val_loss: 0.2445 - val_accuracy: 0.9277\n",
            "Epoch 39/50\n",
            "108/108 [==============================] - 7s 60ms/step - loss: 0.2440 - accuracy: 0.9282 - val_loss: 0.2432 - val_accuracy: 0.9285\n",
            "Epoch 40/50\n",
            "108/108 [==============================] - 7s 60ms/step - loss: 0.2426 - accuracy: 0.9282 - val_loss: 0.2417 - val_accuracy: 0.9280\n",
            "Epoch 41/50\n",
            "108/108 [==============================] - 7s 61ms/step - loss: 0.2412 - accuracy: 0.9284 - val_loss: 0.2403 - val_accuracy: 0.9283\n",
            "Epoch 42/50\n",
            "108/108 [==============================] - 7s 61ms/step - loss: 0.2398 - accuracy: 0.9284 - val_loss: 0.2391 - val_accuracy: 0.9282\n",
            "Epoch 43/50\n",
            "108/108 [==============================] - 7s 61ms/step - loss: 0.2384 - accuracy: 0.9287 - val_loss: 0.2376 - val_accuracy: 0.9291\n",
            "Epoch 44/50\n",
            "108/108 [==============================] - 7s 61ms/step - loss: 0.2371 - accuracy: 0.9287 - val_loss: 0.2365 - val_accuracy: 0.9292\n",
            "Epoch 45/50\n",
            "108/108 [==============================] - 7s 60ms/step - loss: 0.2359 - accuracy: 0.9289 - val_loss: 0.2350 - val_accuracy: 0.9295\n",
            "Epoch 46/50\n",
            "108/108 [==============================] - 7s 61ms/step - loss: 0.2346 - accuracy: 0.9291 - val_loss: 0.2338 - val_accuracy: 0.9289\n",
            "Epoch 47/50\n",
            "108/108 [==============================] - 7s 60ms/step - loss: 0.2333 - accuracy: 0.9293 - val_loss: 0.2326 - val_accuracy: 0.9299\n",
            "Epoch 48/50\n",
            "108/108 [==============================] - 7s 61ms/step - loss: 0.2322 - accuracy: 0.9295 - val_loss: 0.2313 - val_accuracy: 0.9300\n",
            "Epoch 49/50\n",
            "108/108 [==============================] - 7s 60ms/step - loss: 0.2309 - accuracy: 0.9298 - val_loss: 0.2301 - val_accuracy: 0.9295\n",
            "Epoch 50/50\n",
            "108/108 [==============================] - 7s 60ms/step - loss: 0.2298 - accuracy: 0.9299 - val_loss: 0.2294 - val_accuracy: 0.9311\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb32009dc90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kszwT1o-drRi"
      },
      "source": [
        "### Making some predictions.\n",
        "Our model is targeting to predict french words, during the predict function we are going to do the following:\n",
        "\n",
        "1. Get the sequence of the english sentence \n",
        "2. Pad the english sequences and pass them to the model'\n",
        "3. Reshape the logits output to the shape of `(max_len, trg_vocabsize(french)`\n",
        "4. Call the `logits_to_text` function and pass the tokenizer as the `fr_tokenizer`.\n",
        "5. Get the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3iYsDDTzZzx0",
        "outputId": "45b3d0c4-2f5b-4024-8dd8-509cde3551dd"
      },
      "source": [
        "def predict(sent):\n",
        "  sequences = en_text_to_seq(sent)\n",
        "  padded_tokens = pad_sequences([sequences], maxlen=max_words, padding=\"post\", truncating=\"post\")\n",
        "  logits = model(padded_tokens)\n",
        "  logits = tf.reshape(logits, (100, -1))\n",
        "  return logits_to_text(logits, fr_tokenizer)\n",
        "predict(\"your least liked fruit is the grape.\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'elle fruit est moins aimé la raisin                                                                                             '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLbX_HGdwa9l"
      },
      "source": [
        "### Making more predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfsVPgfWqwsr"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "def tabulate_translations(column_names, data, title, max_characters=25):\n",
        "  table = PrettyTable(column_names)\n",
        "  table.title= title\n",
        "  table.align[column_names[0]] = 'l'\n",
        "  table.align[column_names[1]] = 'l'\n",
        "  table.align[column_names[2]] = 'l'\n",
        "  table._max_width = {column_names[0] :max_characters, column_names[1] :max_characters, column_names[2]:max_characters}\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)\n",
        "columns_names = [\n",
        "    \"English (real src sentence)\", \"French (the actual text)\", \"Translated (translated version)\"\n",
        "]\n",
        "title = \"ENGLISH TO FRENCH TRANSLATOR\""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YO1nrCJvxKXt",
        "outputId": "3410e543-0478-4785-acb0-93f324ed8931"
      },
      "source": [
        "max_characters= 25\n",
        "total_translations= 10\n",
        "for i, (eng, fre) in enumerate(zip(eng_sents[:total_translations], fre_sents)):\n",
        "    rows_data = [[eng, fre, predict(eng)]]\n",
        "    if i + 1 != total_translations:\n",
        "      rows_data.append([\"-\" * max_characters, \"-\" * max_characters, \"-\" * max_characters ])\n",
        "    tabulate_translations(columns_names, rows_data, title, max_characters)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| new jersey is sometimes     | new jersey est parfois    | new jersey est parfois calme en |\n",
            "| quiet during autumn , and   | calme pendant l' automne  | l' mai parfois mai mai est en   |\n",
            "| it is snowy in april .      | , et il est neigeux en    | en en en                        |\n",
            "|                             | avril .                   |                                 |\n",
            "| -------------------------   | ------------------------- | -------------------------       |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| the united states is        | les états-unis est        | les états unis est généralement |\n",
            "| usually chilly during july  | généralement froid en     | froid en l' été parfois mais    |\n",
            "| , and it is usually         | juillet , et il gèle      | est est agréable en en en       |\n",
            "| freezing in november .      | habituellement en         |                                 |\n",
            "|                             | novembre .                |                                 |\n",
            "| -------------------------   | ------------------------- | -------------------------       |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| california is usually quiet | california est            | la est est généralement en en   |\n",
            "| during march , and it is    | généralement calme en     | en de il mai il est en relaxant |\n",
            "| usually hot in june .       | mars , et il est          | à                               |\n",
            "|                             | généralement chaud en     |                                 |\n",
            "|                             | juin .                    |                                 |\n",
            "| -------------------------   | ------------------------- | -------------------------       |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| the united states is        | les états-unis est        | les états unis est parfois doux |\n",
            "| sometimes mild during june  | parfois légère en juin ,  | en juin l' parfois il est est   |\n",
            "| , and it is cold in         | et il fait froid en       | en en en                        |\n",
            "| september .                 | septembre .               |                                 |\n",
            "| -------------------------   | ------------------------- | -------------------------       |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| your least liked fruit is   | votre moins aimé fruit    | elle fruit est moins aimé la    |\n",
            "| the grape , but my least    | est le raisin , mais mon  | raisin  est votre moins aimé    |\n",
            "| liked is the apple .        | moins aimé est la pomme . | est est                         |\n",
            "| -------------------------   | ------------------------- | -------------------------       |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| his favorite fruit is the   | son fruit préféré est     | elle fruit préféré est la       |\n",
            "| orange , but my favorite is | l'orange , mais mon       | raisin  est est favori est le   |\n",
            "| the grape .                 | préféré est le raisin .   | est                             |\n",
            "| -------------------------   | ------------------------- | -------------------------       |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| paris is relaxing during    | paris est relaxant en     | paris est est en en en en été   |\n",
            "| december , but it is        | décembre , mais il est    | est généralement généralement   |\n",
            "| usually chilly in july .    | généralement froid en     | en en en                        |\n",
            "|                             | juillet .                 |                                 |\n",
            "| -------------------------   | ------------------------- | -------------------------       |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| new jersey is busy during   | new jersey est occupé au  | new jersey est froid au mois à  |\n",
            "| spring , and it is never    | printemps , et il est     | de il est généralement          |\n",
            "| hot in march .              | jamais chaude en mars .   | généralement en en en           |\n",
            "| -------------------------   | ------------------------- | -------------------------       |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| our least liked fruit is    | notre fruit est moins     | son fruit est moins est la mais |\n",
            "| the lemon , but my least    | aimé le citron , mais mon | est votre moins aimé est est    |\n",
            "| liked is the grape .        | moins aimé est le raisin  |                                 |\n",
            "|                             | .                         |                                 |\n",
            "| -------------------------   | ------------------------- | -------------------------       |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "+-------------------------------------------------------------------------------------------+\n",
            "|                                ENGLISH TO FRENCH TRANSLATOR                               |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| English (real src sentence) | French (the actual text)  | Translated (translated version) |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n",
            "| the united states is        | les états-unis est        | les états unis est parfois      |\n",
            "| sometimes busy during       | parfois occupé en janvier | froid en l' hiver parfois il    |\n",
            "| january , and it is         | , et il est parfois chaud | est parfois froid en en en      |\n",
            "| sometimes warm in november  | en novembre .             |                                 |\n",
            "| .                           |                           |                                 |\n",
            "+-----------------------------+---------------------------+---------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkLm2D3MzNLb"
      },
      "source": [
        "### Conclusion.\n",
        "\n",
        "In this notebook we have leant how to create a simple RNN that translate text from `eng` to french and we were able to get reasonable accuracy and better and reasonable translation at the end.\n",
        "\n",
        "### Next\n",
        "We are going to expand this and change from a simple RNN to the use of the `GRU` with the `embedding` layer.\n",
        "\n",
        "* Also we are going to use the `Sequential` API Instead of the functional API which is what we used in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjYzfKS0zBZR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}