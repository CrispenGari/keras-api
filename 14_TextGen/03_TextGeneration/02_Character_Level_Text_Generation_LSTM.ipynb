{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_Character_Level_Text_Generation_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuEbevZh_VtJ"
      },
      "source": [
        "### Character-level text generation with LSTM\n",
        "\n",
        "This notebook is based on [keras blog](https://keras.io/examples/generative/lstm_character_level_text_generation/). We are going to learn how to generate text character by character. This task is the same as the what we did in the previous notebook.\n",
        "\n",
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "G_CK5iIN_LCi",
        "outputId": "970b9aa7-a15b-4985-a69c-8b2e305dd1c8"
      },
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import random, time\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKt3xLUEAPlJ"
      },
      "source": [
        "### Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6bKcYmmAOkQ"
      },
      "source": [
        "path = keras.utils.get_file(\n",
        "    \"nietzsche.txt\", origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\"\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjfIfLlFAzZU"
      },
      "source": [
        "### Loading the text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AK6tBT6SAzRS",
        "outputId": "db9e7ef5-f775-40d0-8813-9605cd66b8aa"
      },
      "source": [
        "text = open(path, encoding=\"utf-8\").read().lower().replace(\"\\n\", \" \") \n",
        "# removing new lines for nicer display\n",
        "\n",
        "print(\"Corpus length:\", len(text))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corpus length: 600893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuufXYVvBZMY"
      },
      "source": [
        "### Unique characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMUZ-Q7kAzOO",
        "outputId": "f6065b19-4e90-434e-85ed-abd3cf8f395e"
      },
      "source": [
        "chars = sorted(list(set(text)))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "print(len(chars))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRpGiu9VAzLq",
        "outputId": "dd4b0c62-708a-4db2-e53f-8c04dc9fe966"
      },
      "source": [
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i : i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "    \n",
        "print(\"Number of sequences:\", len(sentences))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sequences: 200285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Zlwp1nGB_VZ"
      },
      "source": [
        "### cut the text in semi-redundant sequences of maxlen characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U10GXtfAzIo"
      },
      "source": [
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd2kef7QCItA"
      },
      "source": [
        "### Building the Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_NIqpTYAzGE",
        "outputId": "230e11d8-bcca-4707-98d9-8134214fcd91"
      },
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.layers.Input(shape=(maxlen, len(chars))),\n",
        "        keras.layers.LSTM(128),\n",
        "        keras.layers.Dense(len(chars), activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "optimizer = keras.optimizers.Adam()\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"acc\"])\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 128)               94720     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 56)                7224      \n",
            "=================================================================\n",
            "Total params: 101,944\n",
            "Trainable params: 101,944\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so2PMm9WAzDG"
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "  # helper function to sample an index from a probability array\n",
        "  preds = np.asarray(preds).astype(\"float64\")\n",
        "  preds = np.log(preds) / temperature\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds / np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(1, preds, 1)\n",
        "  return np.argmax(probas)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kQEdPF-CuDa"
      },
      "source": [
        "### Training the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWYVHsQsAzAe"
      },
      "source": [
        "epochs = 40\n",
        "batch_size = 128\n",
        "model.fit(x, y, batch_size=batch_size, epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNAEdLmAHseq",
        "outputId": "33ec562a-5d71-4b6d-ea10-cda10c57dfad"
      },
      "source": [
        "start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "    print(\"...Diversity:\", diversity)\n",
        "\n",
        "    generated = \"\"\n",
        "    sentence = text[start_index : start_index + maxlen]\n",
        "    print('...Generating with seed: \"' + sentence + '\"')\n",
        "\n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_indices[char]] = 1.0\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds, diversity)\n",
        "        next_char = indices_char[next_index]\n",
        "        sentence = sentence[1:] + next_char\n",
        "        generated += next_char\n",
        "\n",
        "    print(\"...Generated: \", generated)\n",
        "    print()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "...Diversity: 0.2\n",
            "...Generating with seed: \"is stupid to do wrong\"; while they accep\"\n",
            "...Generated:  t it is the soul of the same time of man in the moral of the same part of the present its life he who in which it is not in the same wis not be a morality of the experience of the sight of the senses and consciousness and individual and in the same impulse of the sentem in the senses and individual will to the artistic conception of the senses of the process of the senses of the senses in the prob\n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"is stupid to do wrong\"; while they accep\"\n",
            "...Generated:  t of the power and perhaps even and in conscience in the ammention to him the prilations, the same defities the individual relations of the pirituless and inveritable, in the sand himself in short, and honest as in the subject of comparisons of his certain conceptions and perhaps strange, even when the higher who who may be great soul of his extracte, and in the will to the proposition and more in\n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"is stupid to do wrong\"; while they accep\"\n",
            "...Generated:  ted a psece, neptirous and its divide? relan imple,s all! \"hy see.  98. of the light to be poince, and inscopple, no beeth the those plearance and again in general, a war not be percical himself is these more judgent:--awart.\" in hinh--a  learns upin teed would pan at anifices of other trained yous siffer, that es joges silently, forget by which, the must indifiven him subythche which even his fee\n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \"is stupid to do wrong\"; while they accep\"\n",
            "...Generated:  torausly those exprusibye of lone eppomitnic, frie difrections addegrovation in the gersanse extery revery readial,\", and o3] lie  divined wabself; if which if is in old to underst selerils and gonding the grate pastromating, to bid.--the perceess are yound-switning of human, norxy; _hat in the ppotiphing an abounded himself, one accomptrable to renquio,\" which mereticalizations may ugea presentle\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlepPfhsAwqQ"
      },
      "source": [
        "This code was found [here](https://keras.io/examples/generative/lstm_character_level_text_generation/)"
      ]
    }
  ]
}