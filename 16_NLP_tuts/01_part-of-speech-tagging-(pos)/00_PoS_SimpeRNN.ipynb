{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "00_PoS_SimpeRNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1pYbAVBbuno"
      },
      "source": [
        "### PoS - Part of Speech Tagging \n",
        "\n",
        "In this series of notebook we are going to make use of sevaral model achitecture to perform PoS Part of Speech Tagging using tensorflow.\n",
        "\n",
        "### Part of Speech Tagging (PoS)\n",
        "\n",
        "This is a process of classifying words into their part of speech.\n",
        "\n",
        "### Imports\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nNWG8ks1buYp",
        "outputId": "559764b6-8a3c-4f87-ebbf-16f773a1e3d1"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import brown, treebank, conll2000\n",
        "\n",
        "import os, time, re, string, random, nltk\n",
        "tf.__version__"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.6.0'"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLC_AJA3eqHg"
      },
      "source": [
        "### Data loading\n",
        "\n",
        "We are going to make use of the `nltk` (Natural Language Tool Kit) to create our dataset from the imported corpus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_5fMGuyzIWM"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghTccUg8zOtd",
        "outputId": "8e4ab559-afa5-4475-e950-00838f189b33"
      },
      "source": [
        "for i in ['brown', \"treebank\", \"conll2000\", 'universal_tagset']:\n",
        "  nltk.download(i)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Package conll2000 is already up-to-date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NilkpY3TbuV4"
      },
      "source": [
        "tagged_sentences = brown.tagged_sents(tagset='universal') + treebank.tagged_sents(tagset='universal') + conll2000.tagged_sents(tagset='universal')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kc95-6KpbuTN",
        "outputId": "dc76c7f6-ae5e-4cbc-e840-4a1f70166934"
      },
      "source": [
        "len(tagged_sentences)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "72202"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfAHcfOQbuQS",
        "outputId": "5e32b887-5ce2-45c5-b45a-94aa583f7e64"
      },
      "source": [
        "tagged_sentences[7]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Merger', 'NOUN'), ('proposed', 'VERB')]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLkq2eHS2dDl"
      },
      "source": [
        "### Dataset creation\n",
        "\n",
        "Since this is a many to may problem, each data point will be different sentence of the corpra. Each data point will have multiple words and multiple output for example:\n",
        "\n",
        "```\n",
        "X = [Mr Vinken is chairman of Elsevier]\n",
        "Y = [NOUN NOUN VERB NOUN ADP NOUN]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfTbj8e9buNc",
        "outputId": "ff078ecf-9a37-43c8-c8b6-91f7de51608e"
      },
      "source": [
        "X, Y = [], []\n",
        "\n",
        "for sent in tagged_sentences:\n",
        "  sentence = []\n",
        "  tags = []\n",
        "  for s, t in sent:\n",
        "    sentence.append(s)\n",
        "    tags.append(t)\n",
        "\n",
        "  X.append(sentence)\n",
        "  Y.append(tags)\n",
        "\n",
        "print(\"done!\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1yTLbsI3-v-"
      },
      "source": [
        "### Saving this as a `csv` file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPitu49Gbhdg"
      },
      "source": [
        "sentences_tags_pairs = []\n",
        "\n",
        "for sents, tgs in zip(X, Y):\n",
        "  sentences_tags_pairs.append([\" \".join(sents), \" \".join(tgs)])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSI567jW34gk",
        "outputId": "ef32f986-5a90-4e3a-bbff-f94c492d6787"
      },
      "source": [
        "sentences_tags_pairs[:2]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[\"The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced `` no evidence '' that any irregularities took place .\",\n",
              "  'DET NOUN NOUN ADJ NOUN VERB NOUN DET NOUN ADP NOUN ADJ NOUN NOUN VERB . DET NOUN . ADP DET NOUN VERB NOUN .'],\n",
              " [\"The jury further said in term-end presentments that the City Executive Committee , which had over-all charge of the election , `` deserves the praise and thanks of the City of Atlanta '' for the manner in which the election was conducted .\",\n",
              "  'DET NOUN ADV VERB ADP NOUN NOUN ADP DET NOUN ADJ NOUN . DET VERB ADJ NOUN ADP DET NOUN . . VERB DET NOUN CONJ NOUN ADP DET NOUN ADP NOUN . ADP DET NOUN ADP DET DET NOUN VERB VERB .']]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XP9bH8g41TS",
        "outputId": "98333e7d-fe0d-4350-c1b1-94988a235535"
      },
      "source": [
        "dataframe = pd.DataFrame(sentences_tags_pairs, columns=[\n",
        "    \"sentence\", \"tags\"])\n",
        "\n",
        "dataframe.to_csv(\"pos.csv\", index=False)\n",
        "print(\"saved.\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4yznSIt6ke-"
      },
      "source": [
        "### Data Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc08l1pL512i"
      },
      "source": [
        "num_words = len(set([word.lower() \n",
        "for sentence in X for word in sentence]))\n",
        "\n",
        "num_tags = len(set([word.lower() \n",
        "for sentence in Y for word in sentence]))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAMPJWaX7K8W",
        "outputId": "0fb0aae0-2afa-4c29-be3a-5e4a59e84c74"
      },
      "source": [
        "print(\"Total number of tagged sentences: {}\".format(len(X)))\n",
        "print(\"Vocabulary size: {}\".format(num_words))\n",
        "print(\"Total number of tags: {}\".format(num_tags))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of tagged sentences: 72202\n",
            "Vocabulary size: 59448\n",
            "Total number of tags: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDpN_kwt7OQt"
      },
      "source": [
        "### Checking examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDzxH69N7Lbn",
        "outputId": "31d0242b-530b-4648-a2c0-a476a08073dd"
      },
      "source": [
        "print(\"Sample x: \", X[0], \"\\n\")\n",
        "print(\"Sample y: \", Y[0], \"\\n\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample x:  ['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'] \n",
            "\n",
            "Sample y:  ['DET', 'NOUN', 'NOUN', 'ADJ', 'NOUN', 'VERB', 'NOUN', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADJ', 'NOUN', 'NOUN', 'VERB', '.', 'DET', 'NOUN', '.', 'ADP', 'DET', 'NOUN', 'VERB', 'NOUN', '.'] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRzGBx8F7iPe"
      },
      "source": [
        "### Text vectorization\n",
        "\n",
        "We are going to use the `Tokenizer` class to encode text from sequences to sequence of integers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6I-rrUf7dSG"
      },
      "source": [
        "tokenizer = keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(X)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4lGE2K47dKe"
      },
      "source": [
        "tag_tokenizer = keras.preprocessing.text.Tokenizer()\n",
        "tag_tokenizer.fit_on_texts(Y)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiAZNI-A8mr7",
        "outputId": "f68c5b47-e752-4aed-ec24-24138ae7b347"
      },
      "source": [
        "tag_tokenizer.word_index"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.': 3,\n",
              " 'adj': 6,\n",
              " 'adp': 4,\n",
              " 'adv': 7,\n",
              " 'conj': 9,\n",
              " 'det': 5,\n",
              " 'noun': 1,\n",
              " 'num': 11,\n",
              " 'pron': 8,\n",
              " 'prt': 10,\n",
              " 'verb': 2,\n",
              " 'x': 12}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NQpnq4G8vpd"
      },
      "source": [
        "Now we can convert our tokens to sequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCC0iAXP7dHE"
      },
      "source": [
        "sentences_sequences = tokenizer.texts_to_sequences(X)\n",
        "tags_sequences = tag_tokenizer.texts_to_sequences(Y)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2f-IPa-9OQ5"
      },
      "source": [
        "### Checking a single example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcKCDL4W7dEH",
        "outputId": "5fa8f58e-f609-4d7f-9487-2f15210d076a"
      },
      "source": [
        "print(sentences_sequences[0])\n",
        "tags_sequences[0]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 5731, 778, 2326, 1842, 39, 853, 34, 1944, 4, 16831, 379, 1343, 1523, 1116, 12, 67, 569, 14, 9, 89, 10208, 252, 205, 3]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 1, 1, 6, 1, 2, 1, 5, 1, 4, 1, 6, 1, 1, 2, 3, 5, 1, 3, 4, 5, 1, 2, 1, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj4WRXdu9dQX"
      },
      "source": [
        "Let's convert tag tokens back to word representations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIifihSD7ZGe",
        "outputId": "92c2bbfe-7989-4b07-d574-ab5ed5ef76cf"
      },
      "source": [
        "print(\"Y[0]: \", Y[0])\n",
        "print(\"tags_sequences[0]: \", tags_sequences[0])\n",
        "print(\"sequences_to_tags[0]: \", \n",
        "      tag_tokenizer.sequences_to_texts([tags_sequences[0]]))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y[0]:  ['DET', 'NOUN', 'NOUN', 'ADJ', 'NOUN', 'VERB', 'NOUN', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADJ', 'NOUN', 'NOUN', 'VERB', '.', 'DET', 'NOUN', '.', 'ADP', 'DET', 'NOUN', 'VERB', 'NOUN', '.']\n",
            "tags_sequences[0]:  [5, 1, 1, 6, 1, 2, 1, 5, 1, 4, 1, 6, 1, 1, 2, 3, 5, 1, 3, 4, 5, 1, 2, 1, 3]\n",
            "sequences_to_tags[0]:  ['det noun noun adj noun verb noun det noun adp noun adj noun noun verb . det noun . adp det noun verb noun .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKsrBx8t-lNp"
      },
      "source": [
        "### Checking if the inputs and outputs have the same length.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aqugfsQ-lAU",
        "outputId": "a2d9c08b-93e6-413c-ec13-10d9c62d09e7"
      },
      "source": [
        "different_length = [1 if len(input) != len(output) else 0 for input, output in zip(tags_sequences, sentences_sequences)]\n",
        "print(\"{} sentences have disparate input-output lengths.\".format(sum(different_length)))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 sentences have disparate input-output lengths.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCw0Qdi1-JZ6"
      },
      "source": [
        "### Padding sequences\n",
        "\n",
        "Since the sentences has various length we are going to pad the sequences of these sentences to the longest sentence. We will make sure that these sequences are padded to have the same length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHVBiNgU9-tT",
        "outputId": "57051f94-316c-48ff-effc-cb4e7d729fea"
      },
      "source": [
        "lengths = [len(seq) for seq in tagged_sentences]\n",
        "MAX_LENGTH = max(lengths)\n",
        "print(f\"Longest sentence: {MAX_LENGTH}\")\n",
        "\n",
        "MAX_LENGTH = 100 # we are going to set the max-length to 100"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longest sentence: 271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-DrTROo_TIe"
      },
      "source": [
        "padded_sentences = keras.preprocessing.sequence.pad_sequences(\n",
        "    sentences_sequences,\n",
        "    maxlen=MAX_LENGTH,\n",
        "    padding=\"post\",\n",
        "    truncating=\"post\"\n",
        ")\n",
        "padded_tags = keras.preprocessing.sequence.pad_sequences(\n",
        "    tags_sequences,\n",
        "    maxlen=MAX_LENGTH,\n",
        "    padding=\"post\",\n",
        "    truncating=\"post\"\n",
        ")"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4MBc7WpANsM"
      },
      "source": [
        "Checking the a single example of the padded sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4KpXgTnAM12",
        "outputId": "5fc1debb-5608-4675-db5f-f37993ab9063"
      },
      "source": [
        "print(padded_sentences[0], \"\\n\"*2)\n",
        "print(padded_tags[0])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[    1  5731   778  2326  1842    39   853    34  1944     4 16831   379\n",
            "  1343  1523  1116    12    67   569    14     9    89 10208   252   205\n",
            "     3     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0] \n",
            "\n",
            "\n",
            "[5 1 1 6 1 2 1 5 1 4 1 6 1 1 2 3 5 1 3 4 5 1 2 1 3 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eftEgKviEtHA"
      },
      "source": [
        "### One-hot Encode `padded_tags` labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCVNUjAMEw5z",
        "outputId": "b95b2702-3bc4-4e55-9123-ae368965afef"
      },
      "source": [
        "padded_tags = keras.utils.to_categorical(padded_tags)\n",
        "padded_tags.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(72202, 100, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75exlRtXFY_x"
      },
      "source": [
        "### Set's spliting.\n",
        "\n",
        "We are then going to split the data into 3 sets using the `sklearn` `train_test_split` method to split our data train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h3UyVxtFNv-"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "   padded_sentences, padded_tags, random_state=42, test_size=.15\n",
        ")\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "   padded_sentences, padded_tags, random_state=42, test_size=.15\n",
        ")"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57wOZEU8GKsR"
      },
      "source": [
        "### Counting examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hq_DTy7XGMK0",
        "outputId": "94ab0b25-d9e1-40ee-e83f-84ebe1ce4cd2"
      },
      "source": [
        "print(\"training: \", len(X_train))\n",
        "print(\"testing: \", len(X_test))\n",
        "print(\"validation: \", len(X_valid))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training:  61371\n",
            "testing:  10831\n",
            "validation:  10831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTcpukkaGhxC"
      },
      "source": [
        "### A simple RNN\n",
        "\n",
        "We are going to create a simple RNN without word embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9azdoT9Ga8y",
        "outputId": "407c3561-ed99-4b5f-f672-5bab264160ee"
      },
      "source": [
        "n_classes = y_train.shape[-1]\n",
        "n_classes"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9CL_y0UHgDj",
        "outputId": "1a418c78-8520-4a87-82f8-b1737ed30d46"
      },
      "source": [
        "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
        "EMBEDDING_SIZE = 300\n",
        "MAX_SEQUENCE_LENGTH = 100\n",
        "VOCAB_SIZE"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59449"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ok0UE_ENG5fk",
        "outputId": "3378e18c-7842-4cab-c8b8-bf35dde1435f"
      },
      "source": [
        "rnn_model = keras.Sequential([\n",
        "    keras.layers.Embedding(\n",
        "      VOCAB_SIZE, EMBEDDING_SIZE, input_length=MAX_SEQUENCE_LENGTH,\n",
        "      trainable = True\n",
        "    ),\n",
        "    keras.layers.SimpleRNN(64, return_sequences=True),\n",
        "    keras.layers.TimeDistributed(\n",
        "        keras.layers.Dense(n_classes, activation=\"softmax\")\n",
        "    )\n",
        "], name=\"simple_rnn\")\n",
        "\n",
        "rnn_model.summary()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"simple_rnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 300)          17834700  \n",
            "_________________________________________________________________\n",
            "simple_rnn (SimpleRNN)       (None, 100, 64)           23360     \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 100, 13)           845       \n",
            "=================================================================\n",
            "Total params: 17,858,905\n",
            "Trainable params: 17,858,905\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Icv5RR92LzDp"
      },
      "source": [
        "### Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHsE7LdWLm5A",
        "outputId": "50baefdc-01d3-4feb-887a-b16a3de10ed3"
      },
      "source": [
        "rnn_model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['acc'])\n",
        "\n",
        "rnn_model.fit(\n",
        "    X_train, y_train, batch_size=128, \n",
        "    epochs=10, validation_data=(X_valid, y_valid)\n",
        ")"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "480/480 [==============================] - 92s 184ms/step - loss: 0.1856 - acc: 0.9584 - val_loss: 0.0370 - val_acc: 0.9887\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 87s 182ms/step - loss: 0.0270 - acc: 0.9911 - val_loss: 0.0281 - val_acc: 0.9901\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 85s 177ms/step - loss: 0.0196 - acc: 0.9930 - val_loss: 0.0266 - val_acc: 0.9904\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 86s 179ms/step - loss: 0.0164 - acc: 0.9942 - val_loss: 0.0266 - val_acc: 0.9906\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 86s 180ms/step - loss: 0.0141 - acc: 0.9950 - val_loss: 0.0272 - val_acc: 0.9904\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 85s 178ms/step - loss: 0.0121 - acc: 0.9958 - val_loss: 0.0284 - val_acc: 0.9903\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 86s 178ms/step - loss: 0.0103 - acc: 0.9965 - val_loss: 0.0301 - val_acc: 0.9901\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 87s 181ms/step - loss: 0.0087 - acc: 0.9971 - val_loss: 0.0320 - val_acc: 0.9899\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 87s 181ms/step - loss: 0.0073 - acc: 0.9977 - val_loss: 0.0343 - val_acc: 0.9897\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 87s 180ms/step - loss: 0.0062 - acc: 0.9981 - val_loss: 0.0368 - val_acc: 0.9894\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdc77ff2d90>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeXTShyfMRaC"
      },
      "source": [
        "### Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdRYYIj8MMOY",
        "outputId": "1bc78766-01e9-450d-c59c-eb74fb62d7a3"
      },
      "source": [
        "rnn_model.evaluate(X_test, y_test, verbose=1)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "339/339 [==============================] - 5s 14ms/step - loss: 0.0368 - acc: 0.9894\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.036777108907699585, 0.989393413066864]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-723LG8Map9"
      },
      "source": [
        "### Model Inference\n",
        "\n",
        "Now we are ready to make predictions of our tags. We are going to perform the following steps in the `make_prediction` function.\n",
        "1. tokenize the sentence\n",
        "2. convert the tokenized sentence to integer representation\n",
        "3. padd the tokenized sentences and pass them to the model\n",
        "4. get the predictions and we convert the predictions back to `tags`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFNNiaUlN6fN",
        "outputId": "e31da890-4f9f-4c49-8115-04dd0f42a98f"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQl5z4JlPfQ9"
      },
      "source": [
        "sent = \"The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced `` no evidence '' that any irregularities took place .\"\n",
        "tags = 'DET NOUN NOUN ADJ NOUN VERB NOUN DET NOUN ADP NOUN ADJ NOUN NOUN VERB . DET NOUN . ADP DET NOUN VERB NOUN .'.split(\" \")"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsZuVmDNMY_I"
      },
      "source": [
        "def tokenize_and_pad_sequences(sent):\n",
        "\n",
        "  if isinstance(sent, str):\n",
        "    tokens = sent.split(\" \")\n",
        "  else:\n",
        "    tokens = sent\n",
        "  tokens = [t.lower() for t in tokens]\n",
        "  sequences = tokenizer.texts_to_sequences([tokens])\n",
        "  padded_sequnces = keras.preprocessing.sequence.pad_sequences(\n",
        "    sequences,\n",
        "    maxlen=MAX_LENGTH,\n",
        "    padding=\"post\",\n",
        "    truncating=\"post\"\n",
        "  )\n",
        "  predictions = rnn_model.predict(padded_sequnces)\n",
        "  predictions = tf.argmax(predictions, axis=-1).numpy().astype(\"int32\")\n",
        "\n",
        "  return  tag_tokenizer.sequences_to_texts(predictions)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8redvXF4QVJU",
        "outputId": "f6011a26-c977-4dd1-8a01-09ce68e2d73a"
      },
      "source": [
        "pred_tags = tokenize_and_pad_sequences(sent)\n",
        "\n",
        "print(\"word\\t\\t\\ttag\\tpred-tag\\t\")\n",
        "print(\"-\"*40)\n",
        "for word, tag, pred_tag in zip(sent.split(\" \"), tags, pred_tags[0].split(\" \")):\n",
        "  print(f\"{word}\\t\\t\\t{tag}\\t{pred_tag.upper()}\\t\")"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word\t\t\ttag\tpred-tag\t\n",
            "----------------------------------------\n",
            "The\t\t\tDET\tDET\t\n",
            "Fulton\t\t\tNOUN\tNOUN\t\n",
            "County\t\t\tNOUN\tNOUN\t\n",
            "Grand\t\t\tADJ\tADJ\t\n",
            "Jury\t\t\tNOUN\tNOUN\t\n",
            "said\t\t\tVERB\tVERB\t\n",
            "Friday\t\t\tNOUN\tNOUN\t\n",
            "an\t\t\tDET\tDET\t\n",
            "investigation\t\t\tNOUN\tNOUN\t\n",
            "of\t\t\tADP\tADP\t\n",
            "Atlanta's\t\t\tNOUN\tNOUN\t\n",
            "recent\t\t\tADJ\tADJ\t\n",
            "primary\t\t\tNOUN\tNOUN\t\n",
            "election\t\t\tNOUN\tNOUN\t\n",
            "produced\t\t\tVERB\tVERB\t\n",
            "``\t\t\t.\t.\t\n",
            "no\t\t\tDET\tDET\t\n",
            "evidence\t\t\tNOUN\tNOUN\t\n",
            "''\t\t\t.\t.\t\n",
            "that\t\t\tADP\tADP\t\n",
            "any\t\t\tDET\tDET\t\n",
            "irregularities\t\t\tNOUN\tNOUN\t\n",
            "took\t\t\tVERB\tVERB\t\n",
            "place\t\t\tNOUN\tNOUN\t\n",
            ".\t\t\t.\t.\t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2aDq_jHUG5s"
      },
      "source": [
        "### Conclusion\n",
        "We have implemented our **Deep Learning** model that perform POS tagging. In the next notebook we are going to have a look at how we can make use of the `word2vec` vectors and load them in our embeding layer."
      ]
    }
  ]
}