{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_FNet_Text_Generation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEmmqsNa8xmT"
      },
      "source": [
        "### Text generation using `Fnet`.\n",
        "\n",
        "In this notebook we are going to create a model that does text generation by following [keras examples tutorial](https://keras.io/examples/nlp/text_generation_fnet/)\n",
        "based on the [FNet](https://arxiv.org/abs/2105.03824) achitecture.\n",
        "\n",
        "> The original transformer implementation (Vaswani et al., 2017) was one of the major breakthroughs in Natural Language Processing, giving rise to important architectures such BERT and GPT. However, the drawback of these architectures is that the self-attention mechanism they use is computationally expensive. The FNet architecture proposes to replace this self-attention attention with a leaner mechanism: a Fourier transformation-based linear mixer for input tokens.\n",
        "\n",
        "\n",
        "> The FNet model was able to achieve ``92-97%`` of BERT's accuracy while training ``80%`` faster on GPUs and almost ``70%`` faster on TPUs. This type of design provides an efficient and small model size, leading to faster inference times.\n",
        "\n",
        "In this notebook we will implement text generation using [Cornell_Movie-Dialogs_Corpus dataset.](https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html)\n",
        "\n",
        "\n",
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8og07xwz8gMt"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import re, os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WZDkojc2-CCY",
        "outputId": "04420818-1eef-4fdf-a15a-3b4e8f6f403d"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.6.0'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qek8syT29-tR"
      },
      "source": [
        "### Hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8mPabBA-FpP"
      },
      "source": [
        "VOCAB_SIZE = 8192\n",
        "MAX_SAMPLES = 50000\n",
        "BUFFER_SIZE = 20000\n",
        "MAX_LENGTH = 40\n",
        "EMBED_DIM = 256\n",
        "LATENT_DIM = 512\n",
        "NUM_HEADS = 8\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2PiIl4k-JiR"
      },
      "source": [
        "### Loading the data.\n",
        "\n",
        "The dataset that we will be working with is the [Cornell Dialog Corpus](https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html) which contains converstions inform of questions and answers set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMJU_u3K-Fja"
      },
      "source": [
        "path_to_zip = keras.utils.get_file(\n",
        "    \"cornell_movie_dialogs.zip\",\n",
        "    origin=\"http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\",\n",
        "    extract=True,\n",
        ")\n",
        "\n",
        "path_to_dataset = os.path.join(\n",
        "    os.path.dirname(path_to_zip), \"cornell movie-dialogs corpus\"\n",
        ")\n",
        "path_to_movie_lines = os.path.join(path_to_dataset, \"movie_lines.txt\")\n",
        "path_to_movie_conversations = os.path.join(path_to_dataset, \"movie_conversations.txt\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHiMsAEb-Fgs"
      },
      "source": [
        "def load_conversations():\n",
        "  id2line = {}\n",
        "  with open(path_to_movie_lines, errors=\"ignore\") as file:\n",
        "    lines = file.readlines()\n",
        "  for line in lines:\n",
        "    parts  = line.replace(\"\\n\", \"\").split(\" +++$+++ \")\n",
        "    id2line[parts[0]] = parts[4]\n",
        "\n",
        "  inputs, outputs = [], []\n",
        "  with open(path_to_movie_conversations, \"r\") as file:\n",
        "    lines = file.readlines()\n",
        "  \n",
        "  for line in lines:\n",
        "    parts = line.replace(\"\\n\", \"\").split(\" +++$+++ \")\n",
        "    conversation = [line[1:-1] for line in parts[3][1:-1].split(\", \")]\n",
        "    \n",
        "    for i in range(len(conversation) - 1):\n",
        "      inputs.append(id2line[conversation[i]])\n",
        "      outputs.append(id2line[conversation[i + 1]])\n",
        "      if len(inputs) >= MAX_SAMPLES:\n",
        "          return inputs, outputs\n",
        "  return inputs, outputs"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEh9Icfh-Fdo"
      },
      "source": [
        "questions, answers = load_conversations()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMEFh85DD3JX"
      },
      "source": [
        "### Splitting the data into sets\n",
        "\n",
        "We are then going to split our dataset into two sets:\n",
        "1. train\n",
        "2. validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2AcDme1EFPo"
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((questions[:40000], answers[:40000]))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((questions[40000:], answers[40000:]))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPKyUX0zEA33"
      },
      "source": [
        "### Checking 10 questions and answers pairs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9n-jSg_a-Fan",
        "outputId": "464a81a1-326e-487d-c51e-34893db07d0a"
      },
      "source": [
        "for i in range(100, 110):\n",
        "  print(\"> question: \", questions[i])\n",
        "  print(\"> answer: \", answers[i])\n",
        "  print(\"*\"*50)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> question:  You set me up.\n",
            "> answer:  I just wanted --\n",
            "**************************************************\n",
            "> question:  I just wanted --\n",
            "> answer:  What? To completely damage me?  To send me to therapy forever? What?\n",
            "**************************************************\n",
            "> question:  What? To completely damage me?  To send me to therapy forever? What?\n",
            "> answer:  No! I just wanted\n",
            "**************************************************\n",
            "> question:  Is that woman a complete fruit-loop or is it just me?\n",
            "> answer:  It's just you.\n",
            "**************************************************\n",
            "> question:  Patrick -- is that- a.\n",
            "> answer:  Perm?\n",
            "**************************************************\n",
            "> question:  Now don't get upset. Daddy, but there's this boy... and I think he might ask...\n",
            "> answer:  No! You're not dating until your sister starts dating.  End of discussion.\n",
            "**************************************************\n",
            "> question:  No! You're not dating until your sister starts dating.  End of discussion.\n",
            "> answer:  What if she never starts dating?\n",
            "**************************************************\n",
            "> question:  What if she never starts dating?\n",
            "> answer:  Then neither will you.  And I'll get to sleep at night.\n",
            "**************************************************\n",
            "> question:  Then neither will you.  And I'll get to sleep at night.\n",
            "> answer:  But it's not fair -- she's a mutant, Daddy!\n",
            "**************************************************\n",
            "> question:  But she doesn't want to date.\n",
            "> answer:  Exactly my point\n",
            "**************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyGEvVsYB51X"
      },
      "source": [
        "### Processing the text\n",
        "\n",
        "We are going to use `tf.strings` to clean our text. The function `process_text` does that for us."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEs6K-c6-FX4"
      },
      "source": [
        "def process_text(sentence):\n",
        "  sentence = tf.strings.lower(sentence)\n",
        "  sentence = tf.strings.regex_replace(sentence, r\"([?.!,])\", r\" \\1 \")\n",
        "  sentence = tf.strings.regex_replace(sentence, r\"\\s\\s+\", \" \")\n",
        "  entence = tf.strings.regex_replace(sentence, r\"[^a-z?.!,]+\", \" \")\n",
        "  sentence = tf.strings.strip(sentence)\n",
        "  sentence = tf.strings.join([\"<start>\", sentence, \"<end>\"], separator=\" \")\n",
        "  return sentence"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIIO7nWbCcs5"
      },
      "source": [
        "### Text vectorixation layer.\n",
        "\n",
        "We are going to then create a `TextVectorization` layer that will handle text vectorization for us. The text vectorization will adapt from our questions and answers coupus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzN2RZHkCx__"
      },
      "source": [
        "vectorizer = keras.layers.TextVectorization(\n",
        "    VOCAB_SIZE,\n",
        "    standardize=process_text,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=MAX_LENGTH,\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwS-CQytDFko"
      },
      "source": [
        "corpus = questions + answers\n",
        "vectorizer.adapt(\n",
        "    tf.data.Dataset.from_tensor_slices((corpus)).batch(128)\n",
        ")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj5Ox12EDbwz"
      },
      "source": [
        "### Tokenizing and padding `TextVectorization`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvSaUCksCx80"
      },
      "source": [
        "def vectorize_text(inputs, outputs):\n",
        "  inputs, outputs = vectorizer(inputs), vectorizer(outputs)\n",
        "  outputs = tf.pad(outputs, [[0, 1]])\n",
        "  return (\n",
        "        {\"encoder_inputs\": inputs, \"decoder_inputs\": outputs[:-1]},\n",
        "        {\"outputs\": outputs[1:]},\n",
        "    )\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqF5xDCiCx56"
      },
      "source": [
        "train_dataset = train_dataset.map(vectorize_text, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.map(vectorize_text, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset = (\n",
        "    train_dataset.cache()\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "val_dataset = val_dataset.cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym2zpETJEeYB"
      },
      "source": [
        "### `FNet` encoder\n",
        "\n",
        "> The ``FNet`` paper proposes a replacement for the standard attention mechanism used by the Transformer architecture (Vaswani et al., 2017).\n",
        "\n",
        "![img](https://i.imgur.com/rLg47qU.png)\n",
        "\n",
        "\n",
        "The outputs of the FFT layer are complex numbers. To avoid dealing with complex layers, only the real part (the magnitude) is extracted.\n",
        "\n",
        "The dense layers that follow the Fourier transformation act as convolutions applied on the frequency domain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7P3JXyECx2n"
      },
      "source": [
        "class FNetEncoder(keras.layers.Layer):\n",
        "  def __init__(self, embed_dim, dense_dim, **kwargs):\n",
        "    super(FNetEncoder, self).__init__(**kwargs)\n",
        "    self.embed_dim = embed_dim\n",
        "    self.dense_dim = dense_dim\n",
        "\n",
        "    self.dense_proj = keras.Sequential(\n",
        "            [\n",
        "                keras.layers.Dense(dense_dim, activation=\"relu\"),\n",
        "                keras.layers.Dense(embed_dim),\n",
        "            ]\n",
        "    )\n",
        "    self.layernorm_1 = keras.layers.LayerNormalization()\n",
        "    self.layernorm_2 = keras.layers.LayerNormalization()\n",
        "\n",
        "  def call(self, inputs):\n",
        "    inp_complex = tf.cast(inputs, tf.complex64) # Casting the inputs to complex64\n",
        "    # Projecting the inputs to the frequency domain using FFT2D and\n",
        "    # extracting the real part of the output\n",
        "    fft = tf.math.real(tf.signal.fft2d(inp_complex))\n",
        "    proj_input = self.layernorm_1(inputs + fft)\n",
        "    proj_output = self.dense_proj(proj_input)\n",
        "    return self.layernorm_2(proj_input + proj_output)\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zznTamyaFrpA"
      },
      "source": [
        "### Creating a decoder\n",
        "\n",
        "The decoder architecture remains the same as the one proposed by (Vaswani et al., 2017) in the original transformer architecture, consisting of an embedding, positional encoding, two masked multihead attention layers and finally the dense output layers. The architecture that follows is taken from Deep Learning with Python, second edition, chapter 11."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAdcNYlOGRLw"
      },
      "source": [
        "### Positional embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cw9vSlHCxzZ"
      },
      "source": [
        "class PositionalEmbedding(keras.layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
        "        self.token_embeddings = keras.layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = keras.layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6l2nRGCcGVVY"
      },
      "source": [
        "### FNet decoder layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hya5hlGoGNm4"
      },
      "source": [
        "class FNetDecoder(keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super(FNetDecoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = keras.layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = keras.layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [\n",
        "                keras.layers.Dense(latent_dim, activation=\"relu\"),\n",
        "                keras.layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm_1 = keras.layers.LayerNormalization()\n",
        "        self.layernorm_2 = keras.layers.LayerNormalization()\n",
        "        self.layernorm_3 = keras.layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
        "            axis=0,\n",
        "        )\n",
        "        return tf.tile(mask, mult)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9xaxeRIGhWS"
      },
      "source": [
        "### Creating the model\n",
        "\n",
        "we are going then to create a function `create_model()` that will create an fnet model for us."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko8GRNzTGhLA"
      },
      "source": [
        "def create_model():\n",
        "  encoder_inputs = keras.layers.Input(shape=(None,), dtype=\"int32\", name=\"encoder_inputs\")\n",
        "  x = PositionalEmbedding(MAX_LENGTH, VOCAB_SIZE, EMBED_DIM)(encoder_inputs)\n",
        "  encoder_outputs = FNetEncoder(EMBED_DIM, LATENT_DIM)(x)\n",
        "  encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "  decoder_inputs = keras.layers.Input(shape=(None,), dtype=\"int32\", name=\"decoder_inputs\")\n",
        "  encoded_seq_inputs = keras.Input(\n",
        "      shape=(None, EMBED_DIM), name=\"decoder_state_inputs\"\n",
        "  )\n",
        "  x = PositionalEmbedding(MAX_LENGTH, VOCAB_SIZE, EMBED_DIM)(decoder_inputs)\n",
        "  x = FNetDecoder(EMBED_DIM, LATENT_DIM, NUM_HEADS)(x, encoded_seq_inputs)\n",
        "  x = keras.layers.Dropout(0.5)(x)\n",
        "  decoder_outputs = keras.layers.Dense(VOCAB_SIZE, activation=\"softmax\")(x)\n",
        "  decoder = keras.Model(\n",
        "      [decoder_inputs, encoded_seq_inputs], decoder_outputs, name=\"outputs\"\n",
        "  )\n",
        "  decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "  fnet = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs, name=\"fnet\")\n",
        "  return fnet\n",
        "  "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N38Ls8a3HBtf"
      },
      "source": [
        "### Model instance and compilation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98ao49nRGg8P"
      },
      "source": [
        "fnet = create_model()\n",
        "fnet.compile(\"adam\", \n",
        "             loss=\"sparse_categorical_crossentropy\", \n",
        "             metrics=[\"accuracy\"])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEWnpAcRHZ4B"
      },
      "source": [
        "### Training\n",
        "\n",
        "We are going to train this model for a single epoch since it is for demostration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUMseJqTGg5H",
        "outputId": "a8ea0831-8f3b-4839-bfb8-01f5844c9671"
      },
      "source": [
        "fnet.fit(train_dataset, epochs=1, validation_data=val_dataset)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 2494s 4s/step - loss: 1.6285 - accuracy: 0.2648 - val_loss: 1.4496 - val_accuracy: 0.3017\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3deb3394d0>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE9e2zr8HyfP"
      },
      "source": [
        "### Model inference (making preditions).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjlOMzMUH3ov"
      },
      "source": [
        "VOCAB = vectorizer.get_vocabulary()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKZyaAmiH8Zn"
      },
      "source": [
        "def decode_sentence(input_sentence):\n",
        "    # Mapping the input sentence to tokens and adding start and end tokens\n",
        "    tokenized_input_sentence = vectorizer(\n",
        "        tf.constant(\"<start> \" + process_text(input_sentence) + \" <end>\")\n",
        "    )\n",
        "    # Initializing the initial sentence consisting of only the start token.\n",
        "    tokenized_target_sentence = tf.expand_dims(VOCAB.index(\"<start>\"), 0)\n",
        "    decoded_sentence = \"\"\n",
        "    for i in range(MAX_LENGTH):\n",
        "        # Get the predictions\n",
        "        predictions = fnet.predict(\n",
        "            {\n",
        "                \"encoder_inputs\": tf.expand_dims(tokenized_input_sentence, 0),\n",
        "                \"decoder_inputs\": tf.expand_dims(\n",
        "                    tf.pad(\n",
        "                        tokenized_target_sentence,\n",
        "                        [[0, MAX_LENGTH - tf.shape(tokenized_target_sentence)[0]]],\n",
        "                    ),\n",
        "                    0,\n",
        "                ),\n",
        "            }\n",
        "        )\n",
        "        # Calculating the token with maximum probability and getting the corresponding word\n",
        "        sampled_token_index = tf.argmax(predictions[0, i, :])\n",
        "        sampled_token = VOCAB[sampled_token_index.numpy()]\n",
        "        # If sampled token is the end token then stop generating and return the sentence\n",
        "        if tf.equal(sampled_token_index, VOCAB.index(\"<end>\")):\n",
        "            break\n",
        "        decoded_sentence += sampled_token + \" \"\n",
        "        tokenized_target_sentence = tf.concat(\n",
        "            [tokenized_target_sentence, [sampled_token_index]], 0\n",
        "        )\n",
        "\n",
        "    return decoded_sentence\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aNfYIxNsIQ1H",
        "outputId": "20189d4b-47e0-437b-a996-f8ad01a934ec"
      },
      "source": [
        "decode_sentence(\"Where have you been all this time?\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"i don't know . \""
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lTGulMv4IXMR",
        "outputId": "d372d155-4127-4d00-bfe3-af8f3687983a"
      },
      "source": [
        "decode_sentence(\"What is your name?\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"i don't know . \""
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLUAoKAj8nrh"
      },
      "source": [
        "### Ref\n",
        "\n",
        "* [keras examples](https://keras.io/examples/nlp/text_generation_fnet/)\n",
        "* [Fnet Paper](https://arxiv.org/abs/2105.03824)\n",
        "* [Deep Learning with Python, second edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras)"
      ]
    }
  ]
}